{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import model, losses, dot_prod_attention\n",
    "from data import data_generation, batch_creator, gp_kernels\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from helpers import helpers, masks\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/omernivron/Downloads/GPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr, pad_pos_te, pad_y_fren_tr, pad_y_fren_te, _, df_te = data_generation.data_generator_for_gp_mimick_gpt(50000, gp_kernels.rbf_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = masks.position_mask(pad_pos_tr)\n",
    "pp_te = masks.position_mask(pad_pos_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(pos, tar, pos_mask):\n",
    "    '''\n",
    "    A typical train step function for TF2. Elements which we wish to track their gradient\n",
    "    has to be inside the GradientTape() clause. see (1) https://www.tensorflow.org/guide/migrate \n",
    "    (2) https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask (np array): see description in position_mask function\n",
    "    ------------------    \n",
    "    '''\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    combined_mask_tar = masks.create_masks(tar_inp)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        pred = decoder(pos, tar_inp, True, pos_mask, combined_mask_tar)\n",
    "#         print('pred: ')\n",
    "#         tf.print(pred)\n",
    "\n",
    "        loss = losses.loss_function(tar_real, pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "#     tf.print(gradients)\n",
    "# Ask the optimizer to apply the processed gradients.\n",
    "    optimizer_c.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    train_loss(loss)\n",
    "#     b = decoder.trainable_weights[0]\n",
    "#     tf.print(tf.reduce_mean(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(pos_te, tar_te, pos_mask_te):\n",
    "    '''\n",
    "    \n",
    "    ---------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask_te (np array): see description in position_mask function\n",
    "    ---------------\n",
    "    \n",
    "    '''\n",
    "    tar_inp_te = tar_te[:, :-1]\n",
    "    tar_real_te = tar_te[:, 1:]\n",
    "    combined_mask_tar_te = masks.create_masks(tar_inp_te)\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "    pred = decoder(pos_te, tar_inp_te, False, pos_mask_te, combined_mask_tar_te)\n",
    "    t_loss = losses.loss_function(tar_real_te, pred)\n",
    "    test_loss(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists\n",
      "Epoch 0 batch 0 train Loss 0.0108 test Loss 0.2201\n",
      "Epoch 0 batch 1 train Loss 0.1044 test Loss 0.1249\n",
      "Epoch 0 batch 2 train Loss 0.0800 test Loss 0.0943\n",
      "Epoch 0 batch 3 train Loss 0.0669 test Loss 0.1000\n",
      "Epoch 0 batch 4 train Loss 0.0763 test Loss 0.1000\n",
      "Epoch 0 batch 5 train Loss 0.0794 test Loss 0.0875\n",
      "Epoch 0 batch 6 train Loss 0.0715 test Loss 0.0771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-81e3998336c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mbatch_pos_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tar_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pos_mask_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch_gp_mim_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_pos_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_y_fren_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pos_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tar_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pos_mask_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studies/Cambridge/Damon/attention/data/batch_creator.py\u001b[0m in \u001b[0;36mcreate_batch_gp_mim_2\u001b[0;34m(pos, tar, pos_mask, batch_s)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbatch_tar_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mbatch_pos_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mbatch_pos_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tar_tr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_pos_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = tf.summary.create_file_writer(save_dir + '/logs/')\n",
    "    optimizer_c = tf.keras.optimizers.Adam()\n",
    "    decoder = model.Decoder(16)\n",
    "    EPOCHS = 50\n",
    "    batch_s  = 128\n",
    "    run = 0; step = 0\n",
    "    num_batches = int(pad_y_fren_tr.shape[0] / batch_s)\n",
    "    tf.random.set_seed(1)    \n",
    "    checkpoint = tf.train.Checkpoint(optimizer = optimizer_c, model = decoder)\n",
    "    main_folder = \"/Users/omernivron/Downloads/GPT/ckpt/check_\"\n",
    "    folder = main_folder + str(run); helpers.mkdir(folder)\n",
    "\n",
    "    with writer.as_default():\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "\n",
    "            for batch_n in range(num_batches):\n",
    "                batch_pos_tr, batch_tar_tr, batch_pos_mask, _ = batch_creator.create_batch_gp_mim_2(pad_pos_tr, pad_y_fren_tr, pp)\n",
    "                # batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                # batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                train_step(batch_pos_tr, batch_tar_tr, batch_pos_mask)\n",
    "\n",
    "                if batch % 50 == 0:\n",
    "                    batch_pos_te, batch_tar_te, batch_pos_mask_te, _ = batch_creator.create_batch_gp_mim_2(pad_pos_te, pad_y_fren_te, pp_te)\n",
    "                    test_step(batch_pos_te, batch_tar_te, batch_pos_mask_te)\n",
    "                    helpers.print_progress(epoch, batch_n, train_loss.result(), test_loss.result())\n",
    "                    helpers.tf_summaries(run, step, train_loss.result(), test_loss.result())\n",
    "                    checkpoint.save(folder + '/')\n",
    "                step += 1\n",
    "\n",
    "            print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df_te[560, :].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = df_te[561, :39].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79421483, 0.82273214, 0.78303935, 0.78081123, 0.84008443,\n",
       "       0.93063795, 0.75938485, 0.78951207, 0.85226032, 0.82714972,\n",
       "       0.83747097, 0.82860228, 0.81902547, 0.83490666, 0.8305321 ,\n",
       "       0.83953733, 0.78421542, 0.82523238, 0.81893981, 0.7845124 ,\n",
       "       0.79444966, 0.82777025, 0.8737039 , 0.84331259, 0.77790632,\n",
       "       0.72681742, 0.83917158, 0.8450379 , 0.87636089, 0.89078672,\n",
       "       0.83436773, 0.81889668, 0.82095995, 0.8350107 , 0.75424744,\n",
       "       0.87638343, 0.8746333 , 0.78314555, 0.77521238, 0.83750439,\n",
       "       0.88058447, 0.81881745, 0.91279156, 0.78103321, 0.82639293,\n",
       "       0.7769952 , 0.81967033, 0.82250717, 0.84540936, 0.74881181,\n",
       "       0.84004019, 0.79126806, 0.81754296, 0.86202801, 0.80911221,\n",
       "       0.87486705, 0.71336508, 0.8125778 , 0.76446845])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te[561, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pos, tar, pos_mask):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    combined_mask_tar = create_masks(tar)\n",
    "    out = decoder(pos, tar, False, pos_mask, combined_mask_tar)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pos, tar, num_steps = 1):\n",
    "    '''\n",
    "    \n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (2D np array): (n + num_steps) positions \n",
    "    tar (2D np array): n targets \n",
    "    num_steps (int): how many inference steps are required\n",
    "    ------------------\n",
    "    Returns:\n",
    "    out (tf.tensor float64): the predictions for all timestamps up to n + num_steps  \n",
    "    \n",
    "    '''\n",
    "    n = tar.shape[1]\n",
    "    temp_pos = pos[:, :(n + 1)]\n",
    "    pos_mask = position_mask(temp_pos)\n",
    "    \n",
    "    out = evaluate(temp_pos, tar, pos_mask)\n",
    "#     print(out[n - 1])\n",
    "    tar = tf.concat((tar, tf.reshape(out[n - 1], [1, 1])), axis = 1)\n",
    "    if num_steps > 1:\n",
    "        out = inference(pos, tar, num_steps - 1)\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.8241398577782234, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8241979832058564, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8242541256248841, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243043343657172, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243582809798264, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243396267129595, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243726973824703, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8234560203767337, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8234830424281215, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8235090683135358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8235348383079335, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8237256968841214, shape=(), dtype=float64)\n",
      "tf.Tensor(0.823977861619993, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8240096644136029, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8241489526617438, shape=(), dtype=float64)\n",
      "tf.Tensor(0.824299003452675, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243331891052343, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8243667639624348, shape=(), dtype=float64)\n",
      "tf.Tensor(0.824399612523655, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8244320292727092, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = inference(pos, tar, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with matplotlib.rc_context({'figure.figsize': [10,2.5]}):\n",
    "    plt.scatter(pos[:, :39], tar[:, :39], c='black')\n",
    "    plt.scatter(pos[:, 39:58], a[39:])\n",
    "    plt.scatter(pos[:, 39:58], df_te[561, 39:58], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset(tf.Tensor(pad_pos_tr, value_index = 0 , dtype = tf.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
