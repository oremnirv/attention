{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "import sklearn.gaussian_process as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import time\n",
    "import keras\n",
    "import os\n",
    "from data_generation import *\n",
    "from batch_creator import *\n",
    "from gp_kernels import *\n",
    "from gp_priors import *\n",
    "from gp_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gp_prior(4, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_gp_mim_2(pos, tar, pos_mask, batch_s=128):\n",
    "    '''\n",
    "    Get a batch of positions, targets and position mask from data generated \n",
    "    by data_generator_for_gp_mimick_gpt function and from position_mask function \n",
    "    -------------------------\n",
    "    Parameters:\n",
    "    pos (2D np array): 1st/2nd output from data_generator_for_gp_mimick_gpt function \n",
    "    tar (2D np array): 3rd/4th output from data_generator_for_gp_mimick_gpt function  \n",
    "    pos_mask (4D np.array): output from position_mask function \n",
    "    batch_s (int): deafult 128\n",
    "    -------------------------\n",
    "    Returns:\n",
    "    batch_tar_tr (2D np array)\n",
    "    batch_pos_tr (2D np array)\n",
    "    batch_pos_mask (4D np array)\n",
    "    batch_idx_tr (1D np array): indices (=row numbers) chosen for current batch\n",
    "    \n",
    "    '''\n",
    "    shape = tar.shape[0]\n",
    "    batch_idx_tr = np.random.choice(list(range(shape)), batch_s)\n",
    "    batch_tar_tr = tar[batch_idx_tr, :]\n",
    "    batch_pos_tr = pos[batch_idx_tr, :]\n",
    "    batch_pos_mask = pos_mask[batch_idx_tr, :, :, :]\n",
    "    return batch_tar_tr, batch_pos_tr, batch_pos_mask, batch_idx_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_for_gp_mimick_gpt(num_obs, kernel, tr_percent=0.8):\n",
    "    '''\n",
    "    Generator for training a GPT inspired netowrk. Make sure x is drawn in a range that \n",
    "    Doesn't include 0 --> 0 is used for padding.\n",
    "    -----------------------\n",
    "    Parameters:\n",
    "    num_obs (int): how many observation to generate\n",
    "    kernel (function of am SKlearn kernel object): e.g. rbf_kernel which comes from gp_kernels file\n",
    "    tr_percent (float): daefult 0.8\n",
    "    -----------------------\n",
    "    Returns:\n",
    "    pad_pos_tr (np array): the first rows * tr_percent from the x generated values padded by zeros according to obs_per_sample  \n",
    "    pad_pos_te (np array): all rows of x not chosen for training \n",
    "    pad_y_fren_tr (np array): the first rows * tr_percent from the f_prior generated values padded by zeros according to obs_per_sample  \n",
    "    pad_y_fren_te (np array): all rows of f_prior not chosen for training \n",
    "    '''\n",
    "    df = np.zeros((num_obs * 2, 59))\n",
    "    for i in range(0, num_obs * 2, 2):\n",
    "        x = np.random.uniform(5, 15, size=(1, 59))\n",
    "        k = kernel(x)\n",
    "        f_prior = generate_priors(k, 59, 1)\n",
    "\n",
    "        df[i, :x.shape[1]] = x\n",
    "        df[i + 1, :x.shape[1]] = f_prior\n",
    "\n",
    "    rows = df.shape[0]\n",
    "    cols = df.shape[1]\n",
    "    tr_rows = int(tr_percent * rows)\n",
    "    tr_rows = tr_rows if tr_rows % 2 == 0 else tr_rows + 1\n",
    "    df_tr = df[:tr_rows, :]\n",
    "    df_te = df[tr_rows:, :]\n",
    "    \n",
    "    # get all even rows\n",
    "    pad_pos_tr = df_tr[::2, :]\n",
    "    pad_pos_te = df_te[::2, :]\n",
    "    # get all odd rows\n",
    "    pad_y_fren_tr = df_tr[1::2, :]\n",
    "    pad_y_fren_te = df_te[1::2, :]\n",
    "\n",
    "    return pad_pos_tr, pad_pos_te, pad_y_fren_tr, pad_y_fren_te, df_tr, df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_mask(arr):\n",
    "    '''\n",
    "    This tries to emulate the kernel matrix. \n",
    "    In the first stage we have a 2X2 matrix of zeros, next\n",
    "    3X3 matrix of zeros, etc.\n",
    "    -------------------------\n",
    "    Parameters:\n",
    "    arr (np array): the 1st/2nd output from data_generator_for_gp_mimick_gpt function\n",
    "    -------------------------\n",
    "    Returns:\n",
    "    mask (4D np array): if there are 100 rows and 50 cols in arr then this will \n",
    "    return [100, 49, 50, 50] array -- where the first dim is observation number \n",
    "    second dim is timestamp and third+fourth dim are the mask matrix.\n",
    "    '''\n",
    "    rows = arr.shape[0]\n",
    "    cols = arr.shape[1]\n",
    "    mask = np.ones((rows, cols - 1, cols, cols))\n",
    "    specific = np.sum(np.equal(arr, 0), 1)\n",
    "    for i in range(2, cols + 1):\n",
    "        mask[:, i - 2, :i, :i] = np.zeros((i, i))\n",
    "    for j in range(rows):\n",
    "        k  = specific[j]\n",
    "        mask[j, k:, :, :] = 1\n",
    "            \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    '''\n",
    "    Used to pad sequences that have zeros where there was no event.\n",
    "    Typically this will be combined with create_look_ahead_mask function.\n",
    "    This function is used inside an open session of tensorflow. \n",
    "    To try it out create a tf.constant tensor.\n",
    "    -------------------\n",
    "    Parameters:\n",
    "    seq (tensor): shape is (batch_size, seq_len)\n",
    "    \n",
    "    -------------------\n",
    "    Returns:\n",
    "    A binary tensor  (batch_size, 1, seq_len): 1 where there was no event and 0 otherwise.\n",
    "    \n",
    "    '''\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention. Extra dimension is used in create_masks function\n",
    "    return seq[:, tf.newaxis, :]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tar_mask(size):\n",
    "    '''\n",
    "    '''\n",
    "    mask = tf.linalg.diag(tf.ones(size, size))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_tar_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    '''\n",
    "    Hide future outputs from a decoder style network.\n",
    "    Used typically together with create_padding_mask function\n",
    "    -----------------------\n",
    "    Parameters:\n",
    "    size (int): max sequnce length \n",
    "    \n",
    "    -----------------------\n",
    "    Returns:\n",
    "    mask (tensor): shape is (seq_len X seq_len). Example: if size is 4, returns\n",
    "    0 1 1 1\n",
    "    0 0 1 1\n",
    "    0 0 0 1\n",
    "    0 0 0 0 \n",
    "    where 1 signifies what to hide.\n",
    "    '''\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(tar):\n",
    "    '''\n",
    "    Create unified masking hiding future from current timestamps and hiding paddings. \n",
    "    -------------------\n",
    "    Parameters: \n",
    "    tar (tensor): batch of padded target sequences \n",
    "    -------------------\n",
    "    Returns: \n",
    "    combined_mask_tar  (tensor): shape is batch_size X max_seq_len X max_seq_len\n",
    "    '''\n",
    "    \n",
    "    tar_padding_mask = create_padding_mask(tar)\n",
    "    ## this will be batch_size X 1 X 40\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    # if max seq length is 40 -- > this will be 40X40 \n",
    "    \n",
    "    \n",
    "    ## This will also be (64, 40, 40)\n",
    "    combined_mask_tar = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
    "    \n",
    "    \n",
    "    return combined_mask_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr, pad_pos_te, pad_y_fren_tr, pad_y_fren_te, _, df_te = data_generator_for_gp_mimick_gpt(10000, rbf_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = position_mask(pad_pos_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate= 0.1)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    '''\n",
    "    Masked MSE. Since the target sequences are padded, \n",
    "    it is important to apply a padding mask when calculating the loss.\n",
    "    ----------------\n",
    "    Parameters:\n",
    "    real (tf.tensor float64): shape batch_size X max_seq_len. True values of sequences.\n",
    "    pred (tf.tensor float64): shape batch_size X max_seq_len. Predictions from GPT network. \n",
    "    \n",
    "    ----------------\n",
    "    Returns: \n",
    "    loss value (tf.float64)\n",
    "    '''\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "#     print('loss_ :', loss_)\n",
    "#     shape= (128X58)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_prod_position(q, k, v, mask):\n",
    "    '''\n",
    "    Used to create a pseudo XX^T covariance matrix for each \n",
    "    positional sequence in the batch.\n",
    "    ------------------\n",
    "    Parameters: \n",
    "    q : shape (batch_size X max_seq_len X 1). Position outptut from create_batch_gp_mim_2 function (or after another Dense layer) \n",
    "    k : shape (batch_size X max_seq_len X 1). Position outptut from create_batch_gp_mim_2 function (or after another Dense layer) \n",
    "    mask: shape (batch_size X max_seq_len X max_seq_len X max_seq_len). The positional mask created by position_mask function and selected in batch indices \n",
    "    \n",
    "    ------------------\n",
    "    Returns:\n",
    "    nl_qk (tf.tensor float64): shape (batch_size X max_seq_len X max_seq_len X max_seq_len).\n",
    "    Each observation (1st dim) has seq_len timestamps (2nd dim) and each timestamp has an associated\n",
    "    seq_len X seq_len pseudo covariance matrix (3rd & 4th dims) masked according to the timestamp.\n",
    "    \n",
    "    '''\n",
    "    qk = tf.matmul(q, k, transpose_b = True)\n",
    "    qk = tf.cast(qk[:, tf.newaxis, :, :], tf.float64)\n",
    "    print('qk1: ', qk)\n",
    "#     shape=(128, 1, 59, 59)\n",
    "\n",
    "    print('pos_mask: ', mask)\n",
    "#     shape=(128, 58, 59, 59)\n",
    "    if mask is not None:\n",
    "        qk +=  ((tf.cast(mask, tf.float64)) * -1e9)\n",
    "        \n",
    "    print('qk2: ', qk)\n",
    "\n",
    "\n",
    "    qk = tf.reshape(qk, shape = [tf.shape(mask)[0], tf.shape(mask)[1], -1])\n",
    "    \n",
    "    print('qk3: ', qk)\n",
    "    \n",
    "    qk = tf.reshape(tf.nn.softmax(qk, axis = -1), shape = [tf.shape(mask)[0], tf.shape(mask)[1], tf.shape(mask)[2], tf.shape(mask)[3]])\n",
    "    \n",
    "    print('qk4: ', qk)\n",
    "    #shape=(128, 58, 59, 59)\n",
    "    \n",
    "    v = v[:, tf.newaxis, :, :]\n",
    "    \n",
    "    u = tf.transpose(tf.matmul(qk, v), perm = [0, 1, 3 ,2])\n",
    "    \n",
    "    print('u: ', u)\n",
    "    \n",
    "    u2 = tf.matmul(u, v)\n",
    "    \n",
    "    \n",
    "    return u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_attention(q, k, v, mask):\n",
    "    '''\n",
    "    Attention inspired by Transformer (but not the same). The Transformer embeds the \n",
    "    target words to q (query), k (key), v (value). So if we have a batch of 128 sequences \n",
    "    with max length 40 and embedding layer is 20, we will get shape q = shape k = shape v\n",
    "    = (128 X  max sequence length X 20). The Transformer then transposes k \n",
    "    to get after matmul (128 X max seq X max seq) matrix. We then apply relu layer (unlike in Transformer)\n",
    "    ---------------------\n",
    "    Parameters:\n",
    "    q (tf.tensor float64): shape (batch_size, max_seq_len, 1)\n",
    "    k (tf.tensor float64): shape (batch_size, max_seq_len, 1)\n",
    "    v (tf.tensor float64): shape (batch_size, max_seq_len, 1)\n",
    "    mask (tf.tensor float64): shape (batch_size, max_seq_len, max_seq_len)\n",
    "    ---------------------\n",
    "    Returns:\n",
    "    out_tar: shape (batch_size, max_seq_len, max_seq_len). The sequences after embedding (or Dense layer) weighted by attention_weights. \n",
    "    attention_weights : shape (batch_size, max_seq_len, max_seq_len). Weights to assign for each sequence member at each timestamp (2nd dim).\n",
    "    matmul_qk: shape (batch_size, max_seq_len, max_seq_len)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # similarity\n",
    "    # q = k = v  shape := (batch_size, max_seq_len - 1, max_seq_len -1)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True, name = 'qk')\n",
    "#     print('matmul_qk: ', matmul_qk)\n",
    "#     shape=(128, 58, 58)\n",
    "    \n",
    "    nl_qk = tf.cast(tf.nn.relu(matmul_qk, name = 'nl_qk'), tf.float64) \n",
    "#     print('nl_qk: ', nl_qk)\n",
    "#     shape=(128, 58, 58)\n",
    "#     nl_qk shape := (batch_size, max_seq_len - 1, max_seq_len - 1)\n",
    "\n",
    "    # -1e9 will turn the softmax output in this locations to zero\n",
    "    # this is a good mask as an input for softmax -- we need also masking when \n",
    "    # want to use matmul as is \n",
    "    \n",
    "    if mask is not None:\n",
    "        nl_qk +=  ((tf.cast(mask, tf.float64)) * -1e9)\n",
    "    \n",
    "        \n",
    "#     print('nl_qk after mask: ', nl_qk)\n",
    "#     shape=(128, 58, 58)\n",
    "        \n",
    "     # turn simialrity to scores\n",
    "    attention_weights = tf.nn.softmax(nl_qk, axis = -1, name = 'attention_weights')\n",
    "    # Notice that for all the rows where \n",
    "    # everything is 0, the masking will turn everything to -inf\n",
    "    # and the output from the softmax would be 1/num_cols \n",
    "    # (try a = tf.constant([-1e9, -1e9, -1e9]), tf.nn.softmax(a))\n",
    "    # So we can expect an output from these rows which we want to ignore\n",
    "    # this will be enforced in the masking of the loss function \n",
    "    \n",
    "#     print('attention_weights: ', attention_weights)\n",
    "#     shape=(128, 58, 58)\n",
    "   \n",
    "    # weight values \n",
    "    # attention_weights shape := (batch_size, max_seq_len - 1, max_seq_len - 1), \n",
    "    # v shape := batch_size X max_seq_len X l\n",
    "    out_tar = tf.matmul(attention_weights, v)\n",
    "    \n",
    "#   print('out_tar: ', out_tar)\n",
    "#   shape=(128, 58, tar_d_model)\n",
    "    \n",
    "    return out_tar, attention_weights, matmul_qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, l):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.l = l\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(l, name = 'wq')\n",
    "        self.wk = tf.keras.layers.Dense(l, name = 'wk')\n",
    "        self.wv = tf.keras.layers.Dense(l, name = 'wk')                    \n",
    "        \n",
    "        self.hq = tf.keras.layers.Dense(l, name = 'hq')\n",
    "        self.hk = tf.keras.layers.Dense(l, name = 'hk')\n",
    "        self.hv = tf.keras.layers.Dense(l, name = 'hv')\n",
    "        \n",
    "        self.B = tf.keras.layers.Dense(l, name = 'B')\n",
    "        self.A = tf.keras.layers.Dense(1, name = 'A')\n",
    "\n",
    "    #a call method, the layer's forward pass\n",
    "    def call(self, tar_position, tar_inp, training, pos_mask, tar_mask):\n",
    "        \n",
    "        # Adding extra dimension to allow multiplication of \n",
    "        # a sequnce with itself. \n",
    "        tar_position = tar_position[:, :, tf.newaxis]\n",
    "        \n",
    "        q_p = self.wq(tar_position) \n",
    "        k_p = self.wk(tar_position)\n",
    "        v_p = self.wk(tar_position)\n",
    "\n",
    "\n",
    "        print('v_p: ', v_p)\n",
    "        #shape=(128, 59, 16)\n",
    "        \n",
    "        pos_attn1 = dot_prod_position(q_p, k_p, v_p, mask = pos_mask)\n",
    "        print('pos_attn1 :', pos_attn1)\n",
    "#       shape=(128, 58, 59, 59)\n",
    "    \n",
    "        tar_inp = tar_inp[:, :, tf.newaxis]\n",
    "\n",
    "        \n",
    "        q = self.hq(tar_inp) \n",
    "        k = self.hk(tar_inp)\n",
    "        v = self.hv(tar_inp)\n",
    "        \n",
    "        print('q :', q)\n",
    "#       shape=(128, 58, 58)\n",
    "\n",
    "        tar_attn1, _, _ = dot_product_attention(q, k, v, tar_mask)\n",
    "        # tar_attn1 is (batch_size, max_seq_len - 1, tar_d_model)\n",
    "\n",
    "        print('tar_attn1 :', tar_attn1)\n",
    "#       shape=(128, 58, l)\n",
    "#       shape=(128, 58, 16)\n",
    "        tar_attn1 = tar_attn1[:, :, :, tf.newaxis]\n",
    "        \n",
    "        tar1 = self.B(tar_attn1)\n",
    "        \n",
    "        print('tar1 :', tar1)\n",
    "        # shape=(128, 58, 16, 16)\n",
    "\n",
    "        L = tf.matmul(tar1, pos_attn1)\n",
    "        \n",
    "        print('L :', L)\n",
    "        # shape=(128, 58, 16, 16)\n",
    "        \n",
    "        L2 = self.A(tf.reshape(L, shape = [tf.shape(L)[0], tf.shape(L)[1] ,self.l ** 2])) \n",
    "        \n",
    "        print('L2 :', L2)\n",
    "        \n",
    "        return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(pos, tar, pos_mask):\n",
    "    '''\n",
    "    A typical train step function for TF2. Elements which we wish to track their gradient\n",
    "    has to be inside the GradientTape() clause. see (1) https://www.tensorflow.org/guide/migrate \n",
    "    (2) https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask (np array): see description in position_mask function\n",
    "    ------------------    \n",
    "    '''\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    combined_mask_tar = create_masks(tar_inp)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        pred = decoder(pos, tar_inp, True, pos_mask, combined_mask_tar)\n",
    "#         print('pred: ')\n",
    "#         tf.print(pred)\n",
    "\n",
    "        loss = loss_function(tar_real, pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "#     tf.print(gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    b = decoder.trainable_weights[0]\n",
    "    tf.print(tf.reduce_mean(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_p:  Tensor(\"decoder_8/wk_1/BiasAdd:0\", shape=(128, 59, 16), dtype=float64)\n",
      "qk1:  Tensor(\"decoder_8/strided_slice_1:0\", shape=(128, 1, 59, 59), dtype=float64)\n",
      "pos_mask:  Tensor(\"pos_mask:0\", shape=(128, 58, 59, 59), dtype=float64)\n",
      "qk2:  Tensor(\"decoder_8/add:0\", shape=(128, 58, 59, 59), dtype=float64)\n",
      "qk3:  Tensor(\"decoder_8/Reshape:0\", shape=(128, 58, 3481), dtype=float64)\n",
      "qk4:  Tensor(\"decoder_8/Reshape_1:0\", shape=(128, 58, 59, 59), dtype=float64)\n",
      "u:  Tensor(\"decoder_8/transpose:0\", shape=(128, 58, 16, 59), dtype=float64)\n",
      "pos_attn1 : Tensor(\"decoder_8/MatMul_2:0\", shape=(128, 58, 16, 16), dtype=float64)\n",
      "q : Tensor(\"decoder_8/hq/BiasAdd:0\", shape=(128, 58, 16), dtype=float64)\n",
      "tar_attn1 : Tensor(\"decoder_8/MatMul_3:0\", shape=(128, 58, 16), dtype=float64)\n",
      "tar1 : Tensor(\"decoder_8/B/BiasAdd:0\", shape=(128, 58, 16, 16), dtype=float64)\n",
      "L : Tensor(\"decoder_8/MatMul_4:0\", shape=(128, 58, 16, 16), dtype=float64)\n",
      "L2 : Tensor(\"decoder_8/A/BiasAdd:0\", shape=(7424, 1), dtype=float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-52-994304711f81>:22 train_step  *\n        loss = loss_function(tar_real, pred)\n    <ipython-input-27-6df2cbecf3d5>:15 loss_function  *\n        loss_ = loss_object(real, pred)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:143 __call__  **\n        losses = self.call(y_true, y_pred)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10038 squared_difference\n        \"SquaredDifference\", x=x, y=y, name=name)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 7424 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_DOUBLE](decoder_8/A/BiasAdd, strided_slice_1)' with input shapes: [7424,1], [128,58].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-0aa32a22ac14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tar_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pos_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-52-994304711f81>:22 train_step  *\n        loss = loss_function(tar_real, pred)\n    <ipython-input-27-6df2cbecf3d5>:15 loss_function  *\n        loss_ = loss_object(real, pred)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:143 __call__  **\n        losses = self.call(y_true, y_pred)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10038 squared_difference\n        \"SquaredDifference\", x=x, y=y, name=name)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 7424 and 128 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_DOUBLE](decoder_8/A/BiasAdd, strided_slice_1)' with input shapes: [7424,1], [128,58].\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    EPOCHS = 20\n",
    "    batch_s  = 128\n",
    "    num_batches = int(pad_y_fren_tr.shape[0] / batch_s)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "#         train_loss.reset_states()\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            batch_tar_tr, batch_pos_tr, batch_pos_mask, _ = create_batch_gp_mim_2(pad_pos_tr, pad_y_fren_tr, pp)\n",
    "            # batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "            # batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "            train_step(batch_pos_tr, batch_tar_tr, batch_pos_mask)\n",
    "\n",
    "            if batch % 50 == 0:\n",
    "                print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                  epoch + 1, batch, train_loss.result()))\n",
    "\n",
    "        print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_te[0, 54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = df_te[0, :].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = df_te[1, :].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(pos, tar, pos_mask):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    combined_mask_tar = create_masks(tar)\n",
    "    out = decoder(pos, tar, False, pos_mask, combined_mask_tar)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pos, tar, max_seq_len, num_steps = 1):\n",
    "    '''\n",
    "    \n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (2D np array): (n + num_steps) positions \n",
    "    tar (2D np array): n targets \n",
    "    max_seq_len (int): this has to be the same max seq length as the trained model\n",
    "    num_steps (int): how many inference steps are required\n",
    "    ------------------\n",
    "    Returns:\n",
    "    tar \n",
    "    \n",
    "    '''\n",
    "    pos_mask = position_mask(pos)\n",
    "    current_idx = np.where(pos != 0)[1][-1]  \n",
    "    \n",
    "    out = infer(pos, tar[:, :-1], pos_mask)\n",
    "    print(out)\n",
    "#     tar = tf.concat((tar, tf.reshape(out[:, current_idx], [1, 1])), axis = 1)\n",
    "#     if num_steps > 1:\n",
    "#         inference(pos, tar, max_seq_len, num_steps - 1)\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = inference(pos, tar, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset(tf.Tensor(pad_pos_tr, value_index = 0 , dtype = tf.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
