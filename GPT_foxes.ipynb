{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import fox_model, losses, dot_prod_attention\n",
    "from data import data_generation, batch_creator, gp_kernels\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from helpers import helpers, masks\n",
    "from inference import infer\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/omernivron/Downloads/GPT_fox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('/Users/omernivron/Downloads/fnr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = foxes\n",
    "# 1 = rabbits\n",
    "# 2 = time\n",
    "# 3 = foxes_tokens\n",
    "# 4 = rabbits_tokens (token id 3 means rabbit_ode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df[2::5]\n",
    "f = df[0::5]; r = df[1::5]\n",
    "f_token = df[3::5]; r_token = df[4::5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr = t[:800000]; f_tr = f[:800000]; r_tr = r[:800000]; f_token_tr = f_token[:800000]; r_token_tr = r_token[:800000]\n",
    "pad_pos_te = t[800000:]; f_te = f[800000:]; r_te = r[800000:]; f_token_te = f_token[800000:]; r_token_te = r_token[800000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr = np.repeat(pad_pos_tr, 2, axis = 0)\n",
    "pad_pos_te = np.repeat(pad_pos_te, 2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tr = np.concatenate((f_tr, r_tr), axis = 0); tar_te = np.concatenate((f_te, r_te), axis = 0)\n",
    "token_tr = np.concatenate((f_token_tr, r_token_tr), axis = 0); token_te = np.concatenate((f_token_te, r_token_te), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = masks.position_mask(pad_pos_tr)\n",
    "pp_te = masks.position_mask(pad_pos_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "m_tr = tf.keras.metrics.Mean()\n",
    "m_te = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(token_pos, time_pos, tar, pos_mask):\n",
    "    '''\n",
    "    A typical train step function for TF2. Elements which we wish to track their gradient\n",
    "    has to be inside the GradientTape() clause. see (1) https://www.tensorflow.org/guide/migrate \n",
    "    (2) https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask (np array): see description in position_mask function\n",
    "    ------------------    \n",
    "    '''\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    combined_mask_tar = masks.create_masks(tar_inp)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        pred, pred_sig = decoder(token_pos, time_pos, tar_inp, True, pos_mask, combined_mask_tar)\n",
    "#         print('pred: ')\n",
    "#         tf.print(pred_sig)\n",
    "\n",
    "        loss, mse, mask = losses.loss_function(tar_real, pred, pred_sig)\n",
    "\n",
    "\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "#     tf.print(gradients)\n",
    "# Ask the optimizer to apply the processed gradients.\n",
    "    optimizer_c.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    m_tr.update_state(mse, mask)\n",
    "#     b = decoder.trainable_weights[0]\n",
    "#     tf.print(tf.reduce_mean(b))\n",
    "    return tar_inp, tar_real, pred, pred_sig, combined_mask_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(token_pos_te, time_pos_te, tar_te, pos_mask_te):\n",
    "    '''\n",
    "    \n",
    "    ---------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask_te (np array): see description in position_mask function\n",
    "    ---------------\n",
    "    \n",
    "    '''\n",
    "    tar_inp_te = tar_te[:, :-1]\n",
    "    tar_real_te = tar_te[:, 1:]\n",
    "    combined_mask_tar_te = masks.create_masks(tar_inp_te)\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "    pred, pred_sig = decoder(token_pos_te, time_pos_te, tar_inp_te, False, pos_mask_te, combined_mask_tar_te)\n",
    "#     tf.print(tf.math.reduce_max(pred_sig))\n",
    "    t_loss, t_mse, t_mask = losses.loss_function(tar_real_te, pred, pred_sig)\n",
    "    tf.print(t_loss)\n",
    "    test_loss(t_loss)\n",
    "    m_te.update_state(t_mse, t_mask)\n",
    "    return tar_real_te, pred, pred_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists\n",
      "Epoch 0 batch 0 train Loss 9778.1563 test Loss 0.0000 with MSE metric 9730.3418\n",
      "Time taken for 1 epoch: 3.241412878036499 secs\n",
      "\n",
      "Epoch 1 batch 0 train Loss 7238.7994 test Loss 0.0000 with MSE metric 7495.8036\n",
      "Time taken for 1 epoch: 2.1934361457824707 secs\n",
      "\n",
      "Epoch 2 batch 0 train Loss 6139.8840 test Loss 0.0000 with MSE metric 6620.6549\n",
      "Time taken for 1 epoch: 2.17579984664917 secs\n",
      "\n",
      "Epoch 3 batch 0 train Loss 5615.7915 test Loss 0.0000 with MSE metric 6848.3023\n",
      "Time taken for 1 epoch: 2.213737964630127 secs\n",
      "\n",
      "Epoch 4 batch 0 train Loss 5035.6222 test Loss 0.0000 with MSE metric 7232.3076\n",
      "Time taken for 1 epoch: 2.173903226852417 secs\n",
      "\n",
      "Epoch 5 batch 0 train Loss 4400.4060 test Loss 0.0000 with MSE metric 7260.6828\n",
      "Time taken for 1 epoch: 2.1973352432250977 secs\n",
      "\n",
      "Epoch 6 batch 0 train Loss 3818.8771 test Loss 0.0000 with MSE metric 7139.3505\n",
      "Time taken for 1 epoch: 2.173475980758667 secs\n",
      "\n",
      "Epoch 7 batch 0 train Loss 3377.3323 test Loss 0.0000 with MSE metric 7320.3442\n",
      "Time taken for 1 epoch: 2.193161964416504 secs\n",
      "\n",
      "Epoch 8 batch 0 train Loss 3016.0315 test Loss 0.0000 with MSE metric 7183.2540\n",
      "Time taken for 1 epoch: 2.188526153564453 secs\n",
      "\n",
      "Epoch 9 batch 0 train Loss 2718.7706 test Loss 0.0000 with MSE metric 7131.7028\n",
      "Time taken for 1 epoch: 2.1595449447631836 secs\n",
      "\n",
      "Epoch 10 batch 0 train Loss 2473.2044 test Loss 0.0000 with MSE metric 6785.6508\n",
      "Time taken for 1 epoch: 2.185100793838501 secs\n",
      "\n",
      "Epoch 11 batch 0 train Loss 2269.1207 test Loss 0.0000 with MSE metric 6728.2597\n",
      "Time taken for 1 epoch: 2.209686040878296 secs\n",
      "\n",
      "Epoch 12 batch 0 train Loss 2096.3661 test Loss 0.0000 with MSE metric 6665.9730\n",
      "Time taken for 1 epoch: 2.173264980316162 secs\n",
      "\n",
      "Epoch 13 batch 0 train Loss 1948.6210 test Loss 0.0000 with MSE metric 6557.9725\n",
      "Time taken for 1 epoch: 2.175689935684204 secs\n",
      "\n",
      "Epoch 14 batch 0 train Loss 1821.1763 test Loss 0.0000 with MSE metric 6511.1752\n",
      "Time taken for 1 epoch: 2.2135379314422607 secs\n",
      "\n",
      "Epoch 15 batch 0 train Loss 1709.9681 test Loss 0.0000 with MSE metric 6397.4747\n",
      "Time taken for 1 epoch: 2.198988676071167 secs\n",
      "\n",
      "Epoch 16 batch 0 train Loss 1612.5843 test Loss 0.0000 with MSE metric 6371.8968\n",
      "Time taken for 1 epoch: 2.185091257095337 secs\n",
      "\n",
      "Epoch 17 batch 0 train Loss 1525.6567 test Loss 0.0000 with MSE metric 6243.6675\n",
      "Time taken for 1 epoch: 2.2171630859375 secs\n",
      "\n",
      "Epoch 18 batch 0 train Loss 1447.8614 test Loss 0.0000 with MSE metric 6116.4922\n",
      "Time taken for 1 epoch: 2.1821389198303223 secs\n",
      "\n",
      "Epoch 19 batch 0 train Loss 1378.7314 test Loss 0.0000 with MSE metric 6036.6100\n",
      "Time taken for 1 epoch: 2.190852165222168 secs\n",
      "\n",
      "Epoch 20 batch 0 train Loss 1316.2235 test Loss 0.0000 with MSE metric 5958.1579\n",
      "Time taken for 1 epoch: 2.1913416385650635 secs\n",
      "\n",
      "Epoch 21 batch 0 train Loss 1259.2366 test Loss 0.0000 with MSE metric 5855.5647\n",
      "Time taken for 1 epoch: 2.1716620922088623 secs\n",
      "\n",
      "Epoch 22 batch 0 train Loss 1208.5244 test Loss 0.0000 with MSE metric 5829.4521\n",
      "Time taken for 1 epoch: 2.189894914627075 secs\n",
      "\n",
      "Epoch 23 batch 0 train Loss 1161.4564 test Loss 0.0000 with MSE metric 5760.9211\n",
      "Time taken for 1 epoch: 2.1865999698638916 secs\n",
      "\n",
      "Epoch 24 batch 0 train Loss 1117.9662 test Loss 0.0000 with MSE metric 5680.5714\n",
      "Time taken for 1 epoch: 2.202049970626831 secs\n",
      "\n",
      "Epoch 25 batch 0 train Loss 1077.8242 test Loss 0.0000 with MSE metric 5606.5749\n",
      "Time taken for 1 epoch: 2.18499493598938 secs\n",
      "\n",
      "Epoch 26 batch 0 train Loss 1040.5357 test Loss 0.0000 with MSE metric 5527.0946\n",
      "Time taken for 1 epoch: 2.1735129356384277 secs\n",
      "\n",
      "Epoch 27 batch 0 train Loss 1005.9431 test Loss 0.0000 with MSE metric 5473.3301\n",
      "Time taken for 1 epoch: 2.187445640563965 secs\n",
      "\n",
      "Epoch 28 batch 0 train Loss 974.5117 test Loss 0.0000 with MSE metric 5420.7810\n",
      "Time taken for 1 epoch: 2.199190855026245 secs\n",
      "\n",
      "Epoch 29 batch 0 train Loss 945.1384 test Loss 0.0000 with MSE metric 5386.9382\n",
      "Time taken for 1 epoch: 2.1689021587371826 secs\n",
      "\n",
      "Epoch 30 batch 0 train Loss 917.9658 test Loss 0.0000 with MSE metric 5360.5651\n",
      "Time taken for 1 epoch: 2.176231861114502 secs\n",
      "\n",
      "Epoch 31 batch 0 train Loss 892.3563 test Loss 0.0000 with MSE metric 5337.1753\n",
      "Time taken for 1 epoch: 2.2145349979400635 secs\n",
      "\n",
      "Epoch 32 batch 0 train Loss 868.0492 test Loss 0.0000 with MSE metric 5302.5223\n",
      "Time taken for 1 epoch: 2.1840169429779053 secs\n",
      "\n",
      "Epoch 33 batch 0 train Loss 845.3023 test Loss 0.0000 with MSE metric 5317.8918\n",
      "Time taken for 1 epoch: 2.207641124725342 secs\n",
      "\n",
      "Epoch 34 batch 0 train Loss 822.9033 test Loss 0.0000 with MSE metric 5267.3339\n",
      "Time taken for 1 epoch: 2.192945718765259 secs\n",
      "\n",
      "Epoch 35 batch 0 train Loss 801.9199 test Loss 0.0000 with MSE metric 5224.2887\n",
      "Time taken for 1 epoch: 2.180145740509033 secs\n",
      "\n",
      "Epoch 36 batch 0 train Loss 782.6988 test Loss 0.0000 with MSE metric 5215.7835\n",
      "Time taken for 1 epoch: 2.1885199546813965 secs\n",
      "\n",
      "Epoch 37 batch 0 train Loss 763.9641 test Loss 0.0000 with MSE metric 5183.5119\n",
      "Time taken for 1 epoch: 2.221982002258301 secs\n",
      "\n",
      "Epoch 38 batch 0 train Loss 746.3824 test Loss 0.0000 with MSE metric 5165.7017\n",
      "Time taken for 1 epoch: 2.251955986022949 secs\n",
      "\n",
      "Epoch 39 batch 0 train Loss 728.9658 test Loss 0.0000 with MSE metric 5076.8300\n",
      "Time taken for 1 epoch: 2.229091167449951 secs\n",
      "\n",
      "Epoch 40 batch 0 train Loss 712.7839 test Loss 0.0000 with MSE metric 5047.2101\n",
      "Time taken for 1 epoch: 2.3212711811065674 secs\n",
      "\n",
      "Epoch 41 batch 0 train Loss 697.2365 test Loss 0.0000 with MSE metric 5023.2863\n",
      "Time taken for 1 epoch: 2.315661668777466 secs\n",
      "\n",
      "Epoch 42 batch 0 train Loss 682.5610 test Loss 0.0000 with MSE metric 5014.5719\n",
      "Time taken for 1 epoch: 2.455993175506592 secs\n",
      "\n",
      "Epoch 43 batch 0 train Loss 668.4237 test Loss 0.0000 with MSE metric 4979.6781\n",
      "Time taken for 1 epoch: 2.3091368675231934 secs\n",
      "\n",
      "Epoch 44 batch 0 train Loss 654.8139 test Loss 0.0000 with MSE metric 4957.5647\n",
      "Time taken for 1 epoch: 2.275862693786621 secs\n",
      "\n",
      "Epoch 45 batch 0 train Loss 641.7452 test Loss 0.0000 with MSE metric 4921.1148\n",
      "Time taken for 1 epoch: 2.240450143814087 secs\n",
      "\n",
      "Epoch 46 batch 0 train Loss 629.4580 test Loss 0.0000 with MSE metric 4912.2671\n",
      "Time taken for 1 epoch: 2.1758999824523926 secs\n",
      "\n",
      "Epoch 47 batch 0 train Loss 617.3705 test Loss 0.0000 with MSE metric 4881.8237\n",
      "Time taken for 1 epoch: 2.2103469371795654 secs\n",
      "\n",
      "Epoch 48 batch 0 train Loss 605.8621 test Loss 0.0000 with MSE metric 4869.3778\n",
      "Time taken for 1 epoch: 2.3315351009368896 secs\n",
      "\n",
      "Epoch 49 batch 0 train Loss 594.5689 test Loss 0.0000 with MSE metric 4826.3710\n",
      "Time taken for 1 epoch: 2.2460880279541016 secs\n",
      "\n",
      "Epoch 50 batch 0 train Loss 583.9219 test Loss 0.0000 with MSE metric 4803.9594\n",
      "Time taken for 1 epoch: 2.2639498710632324 secs\n",
      "\n",
      "Epoch 51 batch 0 train Loss 573.4628 test Loss 0.0000 with MSE metric 4786.2511\n",
      "Time taken for 1 epoch: 2.271764039993286 secs\n",
      "\n",
      "Epoch 52 batch 0 train Loss 563.5427 test Loss 0.0000 with MSE metric 4770.9325\n",
      "Time taken for 1 epoch: 2.2513222694396973 secs\n",
      "\n",
      "Epoch 53 batch 0 train Loss 553.8362 test Loss 0.0000 with MSE metric 4744.7926\n",
      "Time taken for 1 epoch: 2.2049100399017334 secs\n",
      "\n",
      "Epoch 54 batch 0 train Loss 544.4172 test Loss 0.0000 with MSE metric 4716.0572\n",
      "Time taken for 1 epoch: 2.2624170780181885 secs\n",
      "\n",
      "Epoch 55 batch 0 train Loss 535.4712 test Loss 0.0000 with MSE metric 4708.7811\n",
      "Time taken for 1 epoch: 2.235982656478882 secs\n",
      "\n",
      "Epoch 56 batch 0 train Loss 526.7667 test Loss 0.0000 with MSE metric 4698.2296\n",
      "Time taken for 1 epoch: 2.2253570556640625 secs\n",
      "\n",
      "Epoch 57 batch 0 train Loss 518.4136 test Loss 0.0000 with MSE metric 4692.9232\n",
      "Time taken for 1 epoch: 2.3116517066955566 secs\n",
      "\n",
      "Epoch 58 batch 0 train Loss 510.3926 test Loss 0.0000 with MSE metric 4716.6025\n",
      "Time taken for 1 epoch: 2.226047992706299 secs\n",
      "\n",
      "Epoch 59 batch 0 train Loss 502.4755 test Loss 0.0000 with MSE metric 4694.8545\n",
      "Time taken for 1 epoch: 2.207200050354004 secs\n",
      "\n",
      "Epoch 60 batch 0 train Loss 494.8862 test Loss 0.0000 with MSE metric 4698.0619\n",
      "Time taken for 1 epoch: 2.2182631492614746 secs\n",
      "\n",
      "Epoch 61 batch 0 train Loss 487.5192 test Loss 0.0000 with MSE metric 4710.7638\n",
      "Time taken for 1 epoch: 2.1849238872528076 secs\n",
      "\n",
      "Epoch 62 batch 0 train Loss 480.3095 test Loss 0.0000 with MSE metric 4704.9859\n",
      "Time taken for 1 epoch: 2.1728477478027344 secs\n",
      "\n",
      "Epoch 63 batch 0 train Loss 473.3731 test Loss 0.0000 with MSE metric 4714.8152\n",
      "Time taken for 1 epoch: 2.1898412704467773 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 batch 0 train Loss 466.4996 test Loss 0.0000 with MSE metric 4694.6869\n",
      "Time taken for 1 epoch: 2.1731910705566406 secs\n",
      "\n",
      "Epoch 65 batch 0 train Loss 459.9390 test Loss 0.0000 with MSE metric 4719.5069\n",
      "Time taken for 1 epoch: 2.1990132331848145 secs\n",
      "\n",
      "Epoch 66 batch 0 train Loss 453.5481 test Loss 0.0000 with MSE metric 4721.3711\n",
      "Time taken for 1 epoch: 2.1838648319244385 secs\n",
      "\n",
      "Epoch 67 batch 0 train Loss 447.2627 test Loss 0.0000 with MSE metric 4711.5311\n",
      "Time taken for 1 epoch: 2.1827070713043213 secs\n",
      "\n",
      "Epoch 68 batch 0 train Loss 441.1226 test Loss 0.0000 with MSE metric 4690.5008\n",
      "Time taken for 1 epoch: 2.195844888687134 secs\n",
      "\n",
      "Epoch 69 batch 0 train Loss 435.1559 test Loss 0.0000 with MSE metric 4703.4478\n",
      "Time taken for 1 epoch: 2.1923351287841797 secs\n",
      "\n",
      "Epoch 70 batch 0 train Loss 429.3686 test Loss 0.0000 with MSE metric 4700.4374\n",
      "Time taken for 1 epoch: 2.2219629287719727 secs\n",
      "\n",
      "Epoch 71 batch 0 train Loss 423.7252 test Loss 0.0000 with MSE metric 4704.2592\n",
      "Time taken for 1 epoch: 2.345412015914917 secs\n",
      "\n",
      "Epoch 72 batch 0 train Loss 418.1684 test Loss 0.0000 with MSE metric 4679.5749\n",
      "Time taken for 1 epoch: 2.2555830478668213 secs\n",
      "\n",
      "Epoch 73 batch 0 train Loss 412.8035 test Loss 0.0000 with MSE metric 4691.9564\n",
      "Time taken for 1 epoch: 2.279513120651245 secs\n",
      "\n",
      "Epoch 74 batch 0 train Loss 407.5669 test Loss 0.0000 with MSE metric 4689.1086\n",
      "Time taken for 1 epoch: 2.26600980758667 secs\n",
      "\n",
      "Epoch 75 batch 0 train Loss 402.4343 test Loss 0.0000 with MSE metric 4670.4585\n",
      "Time taken for 1 epoch: 2.237015724182129 secs\n",
      "\n",
      "Epoch 76 batch 0 train Loss 397.4527 test Loss 0.0000 with MSE metric 4680.2583\n",
      "Time taken for 1 epoch: 2.246438980102539 secs\n",
      "\n",
      "Epoch 77 batch 0 train Loss 392.5194 test Loss 0.0000 with MSE metric 4642.1587\n",
      "Time taken for 1 epoch: 2.3354740142822266 secs\n",
      "\n",
      "Epoch 78 batch 0 train Loss 387.7336 test Loss 0.0000 with MSE metric 4629.0810\n",
      "Time taken for 1 epoch: 2.19726300239563 secs\n",
      "\n",
      "Epoch 79 batch 0 train Loss 383.0734 test Loss 0.0000 with MSE metric 4616.7369\n",
      "Time taken for 1 epoch: 2.2589340209960938 secs\n",
      "\n",
      "Epoch 80 batch 0 train Loss 378.5071 test Loss 0.0000 with MSE metric 4600.2502\n",
      "Time taken for 1 epoch: 2.2331128120422363 secs\n",
      "\n",
      "Epoch 81 batch 0 train Loss 374.1042 test Loss 0.0000 with MSE metric 4617.0487\n",
      "Time taken for 1 epoch: 2.3030052185058594 secs\n",
      "\n",
      "Epoch 82 batch 0 train Loss 369.8045 test Loss 0.0000 with MSE metric 4653.9139\n",
      "Time taken for 1 epoch: 2.2395007610321045 secs\n",
      "\n",
      "Epoch 83 batch 0 train Loss 365.5684 test Loss 0.0000 with MSE metric 4652.5361\n",
      "Time taken for 1 epoch: 2.292722225189209 secs\n",
      "\n",
      "Epoch 84 batch 0 train Loss 361.4273 test Loss 0.0000 with MSE metric 4655.5484\n",
      "Time taken for 1 epoch: 2.2551767826080322 secs\n",
      "\n",
      "Epoch 85 batch 0 train Loss 357.3859 test Loss 0.0000 with MSE metric 4664.6660\n",
      "Time taken for 1 epoch: 2.2581052780151367 secs\n",
      "\n",
      "Epoch 86 batch 0 train Loss 353.4288 test Loss 0.0000 with MSE metric 4670.5071\n",
      "Time taken for 1 epoch: 2.2875850200653076 secs\n",
      "\n",
      "Epoch 87 batch 0 train Loss 349.5578 test Loss 0.0000 with MSE metric 4659.5039\n",
      "Time taken for 1 epoch: 2.236358880996704 secs\n",
      "\n",
      "Epoch 88 batch 0 train Loss 345.7621 test Loss 0.0000 with MSE metric 4649.6605\n",
      "Time taken for 1 epoch: 2.2816600799560547 secs\n",
      "\n",
      "Epoch 89 batch 0 train Loss 342.0804 test Loss 0.0000 with MSE metric 4652.4669\n",
      "Time taken for 1 epoch: 2.372373104095459 secs\n",
      "\n",
      "Epoch 90 batch 0 train Loss 338.4869 test Loss 0.0000 with MSE metric 4668.8449\n",
      "Time taken for 1 epoch: 2.18493390083313 secs\n",
      "\n",
      "Epoch 91 batch 0 train Loss 334.9460 test Loss 0.0000 with MSE metric 4676.3402\n",
      "Time taken for 1 epoch: 2.2080421447753906 secs\n",
      "\n",
      "Epoch 92 batch 0 train Loss 331.5094 test Loss 0.0000 with MSE metric 4705.2062\n",
      "Time taken for 1 epoch: 2.187211036682129 secs\n",
      "\n",
      "Epoch 93 batch 0 train Loss 328.1414 test Loss 0.0000 with MSE metric 4742.5662\n",
      "Time taken for 1 epoch: 2.1851909160614014 secs\n",
      "\n",
      "Epoch 94 batch 0 train Loss 324.8055 test Loss 0.0000 with MSE metric 4750.7594\n",
      "Time taken for 1 epoch: 2.1989691257476807 secs\n",
      "\n",
      "Epoch 95 batch 0 train Loss 321.5519 test Loss 0.0000 with MSE metric 4752.7651\n",
      "Time taken for 1 epoch: 2.1943109035491943 secs\n",
      "\n",
      "Epoch 96 batch 0 train Loss 318.3672 test Loss 0.0000 with MSE metric 4747.6703\n",
      "Time taken for 1 epoch: 2.1790611743927 secs\n",
      "\n",
      "Epoch 97 batch 0 train Loss 315.2322 test Loss 0.0000 with MSE metric 4737.0803\n",
      "Time taken for 1 epoch: 2.199597120285034 secs\n",
      "\n",
      "Epoch 98 batch 0 train Loss 312.1460 test Loss 0.0000 with MSE metric 4730.3582\n",
      "Time taken for 1 epoch: 2.2060041427612305 secs\n",
      "\n",
      "Epoch 99 batch 0 train Loss 309.1352 test Loss 0.0000 with MSE metric 4719.8944\n",
      "Time taken for 1 epoch: 2.1771790981292725 secs\n",
      "\n",
      "Epoch 100 batch 0 train Loss 306.1869 test Loss 0.0000 with MSE metric 4737.7996\n",
      "Time taken for 1 epoch: 2.192389965057373 secs\n",
      "\n",
      "Epoch 101 batch 0 train Loss 303.2873 test Loss 0.0000 with MSE metric 4731.4630\n",
      "Time taken for 1 epoch: 2.1915810108184814 secs\n",
      "\n",
      "Epoch 102 batch 0 train Loss 300.4515 test Loss 0.0000 with MSE metric 4732.9355\n",
      "Time taken for 1 epoch: 2.1935880184173584 secs\n",
      "\n",
      "Epoch 103 batch 0 train Loss 297.6897 test Loss 0.0000 with MSE metric 4764.7986\n",
      "Time taken for 1 epoch: 2.2104578018188477 secs\n",
      "\n",
      "Epoch 104 batch 0 train Loss 294.9445 test Loss 0.0000 with MSE metric 4749.6355\n",
      "Time taken for 1 epoch: 2.1949551105499268 secs\n",
      "\n",
      "Epoch 105 batch 0 train Loss 292.2693 test Loss 0.0000 with MSE metric 4773.8898\n",
      "Time taken for 1 epoch: 2.185493230819702 secs\n",
      "\n",
      "Epoch 106 batch 0 train Loss 289.6323 test Loss 0.0000 with MSE metric 4773.2300\n",
      "Time taken for 1 epoch: 2.1631500720977783 secs\n",
      "\n",
      "Epoch 107 batch 0 train Loss 287.0644 test Loss 0.0000 with MSE metric 4798.2175\n",
      "Time taken for 1 epoch: 2.1901450157165527 secs\n",
      "\n",
      "Epoch 108 batch 0 train Loss 284.5225 test Loss 0.0000 with MSE metric 4785.1733\n",
      "Time taken for 1 epoch: 2.204035997390747 secs\n",
      "\n",
      "Epoch 109 batch 0 train Loss 282.0470 test Loss 0.0000 with MSE metric 4806.3316\n",
      "Time taken for 1 epoch: 2.181623935699463 secs\n",
      "\n",
      "Epoch 110 batch 0 train Loss 279.6041 test Loss 0.0000 with MSE metric 4817.2351\n",
      "Time taken for 1 epoch: 2.1741440296173096 secs\n",
      "\n",
      "Epoch 111 batch 0 train Loss 277.1964 test Loss 0.0000 with MSE metric 4812.7027\n",
      "Time taken for 1 epoch: 2.1677229404449463 secs\n",
      "\n",
      "Epoch 112 batch 0 train Loss 274.8351 test Loss 0.0000 with MSE metric 4802.2161\n",
      "Time taken for 1 epoch: 2.1852827072143555 secs\n",
      "\n",
      "Epoch 113 batch 0 train Loss 272.5097 test Loss 0.0000 with MSE metric 4788.7404\n",
      "Time taken for 1 epoch: 2.1839072704315186 secs\n",
      "\n",
      "Epoch 114 batch 0 train Loss 270.2316 test Loss 0.0000 with MSE metric 4805.9870\n",
      "Time taken for 1 epoch: 2.174021005630493 secs\n",
      "\n",
      "Epoch 115 batch 0 train Loss 267.9861 test Loss 0.0000 with MSE metric 4798.1218\n",
      "Time taken for 1 epoch: 2.177680730819702 secs\n",
      "\n",
      "Epoch 116 batch 0 train Loss 265.7809 test Loss 0.0000 with MSE metric 4800.7623\n",
      "Time taken for 1 epoch: 2.1585490703582764 secs\n",
      "\n",
      "Epoch 117 batch 0 train Loss 263.6070 test Loss 0.0000 with MSE metric 4785.6528\n",
      "Time taken for 1 epoch: 2.1832211017608643 secs\n",
      "\n",
      "Epoch 118 batch 0 train Loss 261.4843 test Loss 0.0000 with MSE metric 4787.6173\n",
      "Time taken for 1 epoch: 2.1671102046966553 secs\n",
      "\n",
      "Epoch 119 batch 0 train Loss 259.3785 test Loss 0.0000 with MSE metric 4769.6381\n",
      "Time taken for 1 epoch: 2.1972970962524414 secs\n",
      "\n",
      "Epoch 120 batch 0 train Loss 257.3268 test Loss 0.0000 with MSE metric 4782.1797\n",
      "Time taken for 1 epoch: 2.193859815597534 secs\n",
      "\n",
      "Epoch 121 batch 0 train Loss 255.2973 test Loss 0.0000 with MSE metric 4770.6499\n",
      "Time taken for 1 epoch: 2.1916539669036865 secs\n",
      "\n",
      "Epoch 122 batch 0 train Loss 253.3011 test Loss 0.0000 with MSE metric 4767.2491\n",
      "Time taken for 1 epoch: 2.2069339752197266 secs\n",
      "\n",
      "Epoch 123 batch 0 train Loss 251.3417 test Loss 0.0000 with MSE metric 4782.5483\n",
      "Time taken for 1 epoch: 2.19236421585083 secs\n",
      "\n",
      "Epoch 124 batch 0 train Loss 249.4159 test Loss 0.0000 with MSE metric 4786.9517\n",
      "Time taken for 1 epoch: 2.213747024536133 secs\n",
      "\n",
      "Epoch 125 batch 0 train Loss 247.5192 test Loss 0.0000 with MSE metric 4808.9319\n",
      "Time taken for 1 epoch: 2.194040060043335 secs\n",
      "\n",
      "Epoch 126 batch 0 train Loss 245.6479 test Loss 0.0000 with MSE metric 4814.8034\n",
      "Time taken for 1 epoch: 2.1800131797790527 secs\n",
      "\n",
      "Epoch 127 batch 0 train Loss 243.8018 test Loss 0.0000 with MSE metric 4815.7469\n",
      "Time taken for 1 epoch: 2.1902718544006348 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 batch 0 train Loss 241.9888 test Loss 0.0000 with MSE metric 4813.6963\n",
      "Time taken for 1 epoch: 2.2110350131988525 secs\n",
      "\n",
      "Epoch 129 batch 0 train Loss 240.2025 test Loss 0.0000 with MSE metric 4812.0421\n",
      "Time taken for 1 epoch: 2.1772427558898926 secs\n",
      "\n",
      "Epoch 130 batch 0 train Loss 238.4435 test Loss 0.0000 with MSE metric 4810.4142\n",
      "Time taken for 1 epoch: 2.187378168106079 secs\n",
      "\n",
      "Epoch 131 batch 0 train Loss 236.7071 test Loss 0.0000 with MSE metric 4806.8122\n",
      "Time taken for 1 epoch: 2.1795690059661865 secs\n",
      "\n",
      "Epoch 132 batch 0 train Loss 234.9964 test Loss 0.0000 with MSE metric 4786.6990\n",
      "Time taken for 1 epoch: 2.1698381900787354 secs\n",
      "\n",
      "Epoch 133 batch 0 train Loss 233.3169 test Loss 0.0000 with MSE metric 4798.1238\n",
      "Time taken for 1 epoch: 2.190953016281128 secs\n",
      "\n",
      "Epoch 134 batch 0 train Loss 231.6607 test Loss 0.0000 with MSE metric 4815.2159\n",
      "Time taken for 1 epoch: 2.164705991744995 secs\n",
      "\n",
      "Epoch 135 batch 0 train Loss 230.0235 test Loss 0.0000 with MSE metric 4800.0179\n",
      "Time taken for 1 epoch: 2.1766819953918457 secs\n",
      "\n",
      "Epoch 136 batch 0 train Loss 228.4215 test Loss 0.0000 with MSE metric 4788.4764\n",
      "Time taken for 1 epoch: 2.1694650650024414 secs\n",
      "\n",
      "Epoch 137 batch 0 train Loss 226.8308 test Loss 0.0000 with MSE metric 4775.1635\n",
      "Time taken for 1 epoch: 2.176689863204956 secs\n",
      "\n",
      "Epoch 138 batch 0 train Loss 225.2720 test Loss 0.0000 with MSE metric 4770.7660\n",
      "Time taken for 1 epoch: 2.173261880874634 secs\n",
      "\n",
      "Epoch 139 batch 0 train Loss 223.7270 test Loss 0.0000 with MSE metric 4751.7167\n",
      "Time taken for 1 epoch: 2.177945852279663 secs\n",
      "\n",
      "Epoch 140 batch 0 train Loss 222.2108 test Loss 0.0000 with MSE metric 4769.2131\n",
      "Time taken for 1 epoch: 2.193542003631592 secs\n",
      "\n",
      "Epoch 141 batch 0 train Loss 220.7125 test Loss 0.0000 with MSE metric 4763.3221\n",
      "Time taken for 1 epoch: 2.1978609561920166 secs\n",
      "\n",
      "Epoch 142 batch 0 train Loss 219.2355 test Loss 0.0000 with MSE metric 4763.0125\n",
      "Time taken for 1 epoch: 2.1544482707977295 secs\n",
      "\n",
      "Epoch 143 batch 0 train Loss 217.7777 test Loss 0.0000 with MSE metric 4757.3523\n",
      "Time taken for 1 epoch: 2.177560806274414 secs\n",
      "\n",
      "Epoch 144 batch 0 train Loss 216.3378 test Loss 0.0000 with MSE metric 4763.8331\n",
      "Time taken for 1 epoch: 2.1560850143432617 secs\n",
      "\n",
      "Epoch 145 batch 0 train Loss 214.9205 test Loss 0.0000 with MSE metric 4769.5679\n",
      "Time taken for 1 epoch: 2.268765926361084 secs\n",
      "\n",
      "Epoch 146 batch 0 train Loss 213.5236 test Loss 0.0000 with MSE metric 4767.4354\n",
      "Time taken for 1 epoch: 2.2409839630126953 secs\n",
      "\n",
      "Epoch 147 batch 0 train Loss 212.1427 test Loss 0.0000 with MSE metric 4761.6285\n",
      "Time taken for 1 epoch: 2.1617772579193115 secs\n",
      "\n",
      "Epoch 148 batch 0 train Loss 210.7811 test Loss 0.0000 with MSE metric 4756.7769\n",
      "Time taken for 1 epoch: 2.178133010864258 secs\n",
      "\n",
      "Epoch 149 batch 0 train Loss 209.4365 test Loss 0.0000 with MSE metric 4762.9836\n",
      "Time taken for 1 epoch: 2.2159430980682373 secs\n",
      "\n",
      "Epoch 150 batch 0 train Loss 208.1135 test Loss 0.0000 with MSE metric 4780.0559\n",
      "Time taken for 1 epoch: 2.181030035018921 secs\n",
      "\n",
      "Epoch 151 batch 0 train Loss 206.8018 test Loss 0.0000 with MSE metric 4778.8855\n",
      "Time taken for 1 epoch: 2.2071070671081543 secs\n",
      "\n",
      "Epoch 152 batch 0 train Loss 205.5093 test Loss 0.0000 with MSE metric 4780.6605\n",
      "Time taken for 1 epoch: 2.17405104637146 secs\n",
      "\n",
      "Epoch 153 batch 0 train Loss 204.2354 test Loss 0.0000 with MSE metric 4776.1194\n",
      "Time taken for 1 epoch: 2.1937267780303955 secs\n",
      "\n",
      "Epoch 154 batch 0 train Loss 202.9741 test Loss 0.0000 with MSE metric 4770.9959\n",
      "Time taken for 1 epoch: 2.1667208671569824 secs\n",
      "\n",
      "Epoch 155 batch 0 train Loss 201.7310 test Loss 0.0000 with MSE metric 4774.1224\n",
      "Time taken for 1 epoch: 2.1809210777282715 secs\n",
      "\n",
      "Epoch 156 batch 0 train Loss 200.4976 test Loss 0.0000 with MSE metric 4760.5811\n",
      "Time taken for 1 epoch: 2.1966781616210938 secs\n",
      "\n",
      "Epoch 157 batch 0 train Loss 199.2934 test Loss 0.0000 with MSE metric 4761.4732\n",
      "Time taken for 1 epoch: 2.173225164413452 secs\n",
      "\n",
      "Epoch 158 batch 0 train Loss 198.1021 test Loss 0.0000 with MSE metric 4767.3913\n",
      "Time taken for 1 epoch: 2.1805639266967773 secs\n",
      "\n",
      "Epoch 159 batch 0 train Loss 196.9226 test Loss 0.0000 with MSE metric 4768.5664\n",
      "Time taken for 1 epoch: 2.163940906524658 secs\n",
      "\n",
      "Epoch 160 batch 0 train Loss 195.7524 test Loss 0.0000 with MSE metric 4759.8225\n",
      "Time taken for 1 epoch: 2.166264057159424 secs\n",
      "\n",
      "Epoch 161 batch 0 train Loss 194.6007 test Loss 0.0000 with MSE metric 4748.0008\n",
      "Time taken for 1 epoch: 2.198568105697632 secs\n",
      "\n",
      "Epoch 162 batch 0 train Loss 193.4607 test Loss 0.0000 with MSE metric 4743.3147\n",
      "Time taken for 1 epoch: 2.1684789657592773 secs\n",
      "\n",
      "Epoch 163 batch 0 train Loss 192.3380 test Loss 0.0000 with MSE metric 4763.2815\n",
      "Time taken for 1 epoch: 2.1874518394470215 secs\n",
      "\n",
      "Epoch 164 batch 0 train Loss 191.2265 test Loss 0.0000 with MSE metric 4758.5464\n",
      "Time taken for 1 epoch: 2.165564775466919 secs\n",
      "\n",
      "Epoch 165 batch 0 train Loss 190.1265 test Loss 0.0000 with MSE metric 4756.3562\n",
      "Time taken for 1 epoch: 2.168147087097168 secs\n",
      "\n",
      "Epoch 166 batch 0 train Loss 189.0420 test Loss 0.0000 with MSE metric 4759.5076\n",
      "Time taken for 1 epoch: 2.1358699798583984 secs\n",
      "\n",
      "Epoch 167 batch 0 train Loss 187.9729 test Loss 0.0000 with MSE metric 4770.0764\n",
      "Time taken for 1 epoch: 2.1636481285095215 secs\n",
      "\n",
      "Epoch 168 batch 0 train Loss 186.9126 test Loss 0.0000 with MSE metric 4768.0296\n",
      "Time taken for 1 epoch: 2.2380809783935547 secs\n",
      "\n",
      "Epoch 169 batch 0 train Loss 185.8611 test Loss 0.0000 with MSE metric 4759.5496\n",
      "Time taken for 1 epoch: 2.2144339084625244 secs\n",
      "\n",
      "Epoch 170 batch 0 train Loss 184.8293 test Loss 0.0000 with MSE metric 4772.8629\n",
      "Time taken for 1 epoch: 2.1471688747406006 secs\n",
      "\n",
      "Epoch 171 batch 0 train Loss 183.8069 test Loss 0.0000 with MSE metric 4767.0818\n",
      "Time taken for 1 epoch: 2.329267978668213 secs\n",
      "\n",
      "Epoch 172 batch 0 train Loss 182.7983 test Loss 0.0000 with MSE metric 4780.6677\n",
      "Time taken for 1 epoch: 2.2388718128204346 secs\n",
      "\n",
      "Epoch 173 batch 0 train Loss 181.7929 test Loss 0.0000 with MSE metric 4768.2234\n",
      "Time taken for 1 epoch: 2.3273818492889404 secs\n",
      "\n",
      "Epoch 174 batch 0 train Loss 180.8038 test Loss 0.0000 with MSE metric 4767.5342\n",
      "Time taken for 1 epoch: 2.303128957748413 secs\n",
      "\n",
      "Epoch 175 batch 0 train Loss 179.8282 test Loss 0.0000 with MSE metric 4775.8334\n",
      "Time taken for 1 epoch: 2.3257899284362793 secs\n",
      "\n",
      "Epoch 176 batch 0 train Loss 178.8639 test Loss 0.0000 with MSE metric 4780.2873\n",
      "Time taken for 1 epoch: 2.3721258640289307 secs\n",
      "\n",
      "Epoch 177 batch 0 train Loss 177.9100 test Loss 0.0000 with MSE metric 4783.9747\n",
      "Time taken for 1 epoch: 2.4490671157836914 secs\n",
      "\n",
      "Epoch 178 batch 0 train Loss 176.9659 test Loss 0.0000 with MSE metric 4780.7995\n",
      "Time taken for 1 epoch: 2.4046878814697266 secs\n",
      "\n",
      "Epoch 179 batch 0 train Loss 176.0312 test Loss 0.0000 with MSE metric 4779.3211\n",
      "Time taken for 1 epoch: 2.180803060531616 secs\n",
      "\n",
      "Epoch 180 batch 0 train Loss 175.1072 test Loss 0.0000 with MSE metric 4781.5492\n",
      "Time taken for 1 epoch: 2.207653760910034 secs\n",
      "\n",
      "Epoch 181 batch 0 train Loss 174.1934 test Loss 0.0000 with MSE metric 4791.4352\n",
      "Time taken for 1 epoch: 2.2010700702667236 secs\n",
      "\n",
      "Epoch 182 batch 0 train Loss 173.2866 test Loss 0.0000 with MSE metric 4781.6546\n",
      "Time taken for 1 epoch: 2.1520278453826904 secs\n",
      "\n",
      "Epoch 183 batch 0 train Loss 172.3907 test Loss 0.0000 with MSE metric 4775.0291\n",
      "Time taken for 1 epoch: 2.33413028717041 secs\n",
      "\n",
      "Epoch 184 batch 0 train Loss 171.5031 test Loss 0.0000 with MSE metric 4766.3130\n",
      "Time taken for 1 epoch: 2.427968978881836 secs\n",
      "\n",
      "Epoch 185 batch 0 train Loss 170.6261 test Loss 0.0000 with MSE metric 4760.4691\n",
      "Time taken for 1 epoch: 2.336284875869751 secs\n",
      "\n",
      "Epoch 186 batch 0 train Loss 169.7603 test Loss 0.0000 with MSE metric 4763.9025\n",
      "Time taken for 1 epoch: 2.221036911010742 secs\n",
      "\n",
      "Epoch 187 batch 0 train Loss 168.9044 test Loss 0.0000 with MSE metric 4760.6829\n",
      "Time taken for 1 epoch: 2.2437291145324707 secs\n",
      "\n",
      "Epoch 188 batch 0 train Loss 168.0504 test Loss 0.0000 with MSE metric 4745.9364\n",
      "Time taken for 1 epoch: 2.2511110305786133 secs\n",
      "\n",
      "Epoch 189 batch 0 train Loss 167.2107 test Loss 0.0000 with MSE metric 4743.8320\n",
      "Time taken for 1 epoch: 2.3328471183776855 secs\n",
      "\n",
      "Epoch 190 batch 0 train Loss 166.3803 test Loss 0.0000 with MSE metric 4745.6154\n",
      "Time taken for 1 epoch: 2.3467557430267334 secs\n",
      "\n",
      "Epoch 191 batch 0 train Loss 165.5555 test Loss 0.0000 with MSE metric 4736.4339\n",
      "Time taken for 1 epoch: 2.330643892288208 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 batch 0 train Loss 164.7428 test Loss 0.0000 with MSE metric 4742.2826\n",
      "Time taken for 1 epoch: 2.2510969638824463 secs\n",
      "\n",
      "Epoch 193 batch 0 train Loss 163.9398 test Loss 0.0000 with MSE metric 4752.6094\n",
      "Time taken for 1 epoch: 2.34002685546875 secs\n",
      "\n",
      "Epoch 194 batch 0 train Loss 163.1388 test Loss 0.0000 with MSE metric 4741.7842\n",
      "Time taken for 1 epoch: 2.359250783920288 secs\n",
      "\n",
      "Epoch 195 batch 0 train Loss 162.3478 test Loss 0.0000 with MSE metric 4735.2095\n",
      "Time taken for 1 epoch: 2.54773211479187 secs\n",
      "\n",
      "Epoch 196 batch 0 train Loss 161.5628 test Loss 0.0000 with MSE metric 4730.7143\n",
      "Time taken for 1 epoch: 2.5318751335144043 secs\n",
      "\n",
      "Epoch 197 batch 0 train Loss 160.7925 test Loss 0.0000 with MSE metric 4734.9205\n",
      "Time taken for 1 epoch: 2.4583370685577393 secs\n",
      "\n",
      "Epoch 198 batch 0 train Loss 160.0208 test Loss 0.0000 with MSE metric 4722.9138\n",
      "Time taken for 1 epoch: 2.4237418174743652 secs\n",
      "\n",
      "Epoch 199 batch 0 train Loss 159.2588 test Loss 0.0000 with MSE metric 4714.9137\n",
      "Time taken for 1 epoch: 2.2363522052764893 secs\n",
      "\n",
      "Epoch 200 batch 0 train Loss 158.5033 test Loss 0.0000 with MSE metric 4705.4107\n",
      "Time taken for 1 epoch: 2.4457740783691406 secs\n",
      "\n",
      "Epoch 201 batch 0 train Loss 157.7564 test Loss 0.0000 with MSE metric 4697.6002\n",
      "Time taken for 1 epoch: 2.2483489513397217 secs\n",
      "\n",
      "Epoch 202 batch 0 train Loss 157.0175 test Loss 0.0000 with MSE metric 4690.7283\n",
      "Time taken for 1 epoch: 2.2640902996063232 secs\n",
      "\n",
      "Epoch 203 batch 0 train Loss 156.2862 test Loss 0.0000 with MSE metric 4691.9188\n",
      "Time taken for 1 epoch: 2.2738327980041504 secs\n",
      "\n",
      "Epoch 204 batch 0 train Loss 155.5677 test Loss 0.0000 with MSE metric 4701.1685\n",
      "Time taken for 1 epoch: 2.2789440155029297 secs\n",
      "\n",
      "Epoch 205 batch 0 train Loss 154.8465 test Loss 0.0000 with MSE metric 4687.6652\n",
      "Time taken for 1 epoch: 2.301054000854492 secs\n",
      "\n",
      "Epoch 206 batch 0 train Loss 154.1340 test Loss 0.0000 with MSE metric 4685.5039\n",
      "Time taken for 1 epoch: 2.286022901535034 secs\n",
      "\n",
      "Epoch 207 batch 0 train Loss 153.4316 test Loss 0.0000 with MSE metric 4686.7972\n",
      "Time taken for 1 epoch: 2.3330891132354736 secs\n",
      "\n",
      "Epoch 208 batch 0 train Loss 152.7373 test Loss 0.0000 with MSE metric 4692.2799\n",
      "Time taken for 1 epoch: 2.255927085876465 secs\n",
      "\n",
      "Epoch 209 batch 0 train Loss 152.0495 test Loss 0.0000 with MSE metric 4693.4490\n",
      "Time taken for 1 epoch: 2.3255269527435303 secs\n",
      "\n",
      "Epoch 210 batch 0 train Loss 151.3665 test Loss 0.0000 with MSE metric 4697.2713\n",
      "Time taken for 1 epoch: 2.239315986633301 secs\n",
      "\n",
      "Epoch 211 batch 0 train Loss 150.6910 test Loss 0.0000 with MSE metric 4699.1611\n",
      "Time taken for 1 epoch: 2.2848618030548096 secs\n",
      "\n",
      "Epoch 212 batch 0 train Loss 150.0197 test Loss 0.0000 with MSE metric 4701.0478\n",
      "Time taken for 1 epoch: 2.303420066833496 secs\n",
      "\n",
      "Epoch 213 batch 0 train Loss 149.3524 test Loss 0.0000 with MSE metric 4692.6649\n",
      "Time taken for 1 epoch: 2.2003350257873535 secs\n",
      "\n",
      "Epoch 214 batch 0 train Loss 148.6929 test Loss 0.0000 with MSE metric 4690.3674\n",
      "Time taken for 1 epoch: 2.177852153778076 secs\n",
      "\n",
      "Epoch 215 batch 0 train Loss 148.0375 test Loss 0.0000 with MSE metric 4679.7927\n",
      "Time taken for 1 epoch: 2.1982409954071045 secs\n",
      "\n",
      "Epoch 216 batch 0 train Loss 147.3929 test Loss 0.0000 with MSE metric 4684.4070\n",
      "Time taken for 1 epoch: 2.2102410793304443 secs\n",
      "\n",
      "Epoch 217 batch 0 train Loss 146.7511 test Loss 0.0000 with MSE metric 4678.4175\n",
      "Time taken for 1 epoch: 2.217371940612793 secs\n",
      "\n",
      "Epoch 218 batch 0 train Loss 146.1174 test Loss 0.0000 with MSE metric 4687.1125\n",
      "Time taken for 1 epoch: 2.1974270343780518 secs\n",
      "\n",
      "Epoch 219 batch 0 train Loss 145.4860 test Loss 0.0000 with MSE metric 4675.8537\n",
      "Time taken for 1 epoch: 2.2267651557922363 secs\n",
      "\n",
      "Epoch 220 batch 0 train Loss 144.8615 test Loss 0.0000 with MSE metric 4667.1152\n",
      "Time taken for 1 epoch: 2.230642795562744 secs\n",
      "\n",
      "Epoch 221 batch 0 train Loss 144.2440 test Loss 0.0000 with MSE metric 4670.5078\n",
      "Time taken for 1 epoch: 2.262674331665039 secs\n",
      "\n",
      "Epoch 222 batch 0 train Loss 143.6331 test Loss 0.0000 with MSE metric 4670.1292\n",
      "Time taken for 1 epoch: 2.309861898422241 secs\n",
      "\n",
      "Epoch 223 batch 0 train Loss 143.0276 test Loss 0.0000 with MSE metric 4671.7797\n",
      "Time taken for 1 epoch: 2.2356631755828857 secs\n",
      "\n",
      "Epoch 224 batch 0 train Loss 142.4268 test Loss 0.0000 with MSE metric 4676.4657\n",
      "Time taken for 1 epoch: 2.3251028060913086 secs\n",
      "\n",
      "Epoch 225 batch 0 train Loss 141.8320 test Loss 0.0000 with MSE metric 4686.6851\n",
      "Time taken for 1 epoch: 2.364799976348877 secs\n",
      "\n",
      "Epoch 226 batch 0 train Loss 141.2433 test Loss 0.0000 with MSE metric 4699.4492\n",
      "Time taken for 1 epoch: 2.231083869934082 secs\n",
      "\n",
      "Epoch 227 batch 0 train Loss 140.6549 test Loss 0.0000 with MSE metric 4691.3934\n",
      "Time taken for 1 epoch: 2.263087272644043 secs\n",
      "\n",
      "Epoch 228 batch 0 train Loss 140.0754 test Loss 0.0000 with MSE metric 4694.4625\n",
      "Time taken for 1 epoch: 2.2626988887786865 secs\n",
      "\n",
      "Epoch 229 batch 0 train Loss 139.4970 test Loss 0.0000 with MSE metric 4686.0412\n",
      "Time taken for 1 epoch: 2.255458116531372 secs\n",
      "\n",
      "Epoch 230 batch 0 train Loss 138.9268 test Loss 0.0000 with MSE metric 4686.4955\n",
      "Time taken for 1 epoch: 2.207385778427124 secs\n",
      "\n",
      "Epoch 231 batch 0 train Loss 138.3613 test Loss 0.0000 with MSE metric 4684.9987\n",
      "Time taken for 1 epoch: 2.215014934539795 secs\n",
      "\n",
      "Epoch 232 batch 0 train Loss 137.7974 test Loss 0.0000 with MSE metric 4679.2304\n",
      "Time taken for 1 epoch: 2.2769808769226074 secs\n",
      "\n",
      "Epoch 233 batch 0 train Loss 137.2390 test Loss 0.0000 with MSE metric 4674.1911\n",
      "Time taken for 1 epoch: 2.200455904006958 secs\n",
      "\n",
      "Epoch 234 batch 0 train Loss 136.6849 test Loss 0.0000 with MSE metric 4670.4173\n",
      "Time taken for 1 epoch: 2.3905577659606934 secs\n",
      "\n",
      "Epoch 235 batch 0 train Loss 136.1365 test Loss 0.0000 with MSE metric 4668.7643\n",
      "Time taken for 1 epoch: 2.225733995437622 secs\n",
      "\n",
      "Epoch 236 batch 0 train Loss 135.5943 test Loss 0.0000 with MSE metric 4672.7162\n",
      "Time taken for 1 epoch: 2.24719500541687 secs\n",
      "\n",
      "Epoch 237 batch 0 train Loss 135.0580 test Loss 0.0000 with MSE metric 4676.0657\n",
      "Time taken for 1 epoch: 2.2181448936462402 secs\n",
      "\n",
      "Epoch 238 batch 0 train Loss 134.5230 test Loss 0.0000 with MSE metric 4672.2075\n",
      "Time taken for 1 epoch: 2.2601799964904785 secs\n",
      "\n",
      "Epoch 239 batch 0 train Loss 133.9928 test Loss 0.0000 with MSE metric 4671.2168\n",
      "Time taken for 1 epoch: 2.310326099395752 secs\n",
      "\n",
      "Epoch 240 batch 0 train Loss 133.4657 test Loss 0.0000 with MSE metric 4667.3080\n",
      "Time taken for 1 epoch: 2.2178590297698975 secs\n",
      "\n",
      "Epoch 241 batch 0 train Loss 132.9448 test Loss 0.0000 with MSE metric 4673.8050\n",
      "Time taken for 1 epoch: 2.280954122543335 secs\n",
      "\n",
      "Epoch 242 batch 0 train Loss 132.4268 test Loss 0.0000 with MSE metric 4669.1930\n",
      "Time taken for 1 epoch: 2.2274270057678223 secs\n",
      "\n",
      "Epoch 243 batch 0 train Loss 131.9156 test Loss 0.0000 with MSE metric 4671.7844\n",
      "Time taken for 1 epoch: 2.2934579849243164 secs\n",
      "\n",
      "Epoch 244 batch 0 train Loss 131.4035 test Loss 0.0000 with MSE metric 4660.5962\n",
      "Time taken for 1 epoch: 2.208225965499878 secs\n",
      "\n",
      "Epoch 245 batch 0 train Loss 130.8982 test Loss 0.0000 with MSE metric 4659.9110\n",
      "Time taken for 1 epoch: 2.219802141189575 secs\n",
      "\n",
      "Epoch 246 batch 0 train Loss 130.3964 test Loss 0.0000 with MSE metric 4657.9715\n",
      "Time taken for 1 epoch: 2.2124850749969482 secs\n",
      "\n",
      "Epoch 247 batch 0 train Loss 129.9001 test Loss 0.0000 with MSE metric 4662.2644\n",
      "Time taken for 1 epoch: 2.216118097305298 secs\n",
      "\n",
      "Epoch 248 batch 0 train Loss 129.4041 test Loss 0.0000 with MSE metric 4654.1510\n",
      "Time taken for 1 epoch: 2.2441301345825195 secs\n",
      "\n",
      "Epoch 249 batch 0 train Loss 128.9121 test Loss 0.0000 with MSE metric 4656.9789\n",
      "Time taken for 1 epoch: 2.1936657428741455 secs\n",
      "\n",
      "Epoch 250 batch 0 train Loss 128.4249 test Loss 0.0000 with MSE metric 4650.2150\n",
      "Time taken for 1 epoch: 2.222882032394409 secs\n",
      "\n",
      "Epoch 251 batch 0 train Loss 127.9451 test Loss 0.0000 with MSE metric 4651.1933\n",
      "Time taken for 1 epoch: 2.20131516456604 secs\n",
      "\n",
      "Epoch 252 batch 0 train Loss 127.4663 test Loss 0.0000 with MSE metric 4644.4511\n",
      "Time taken for 1 epoch: 2.221764087677002 secs\n",
      "\n",
      "Epoch 253 batch 0 train Loss 126.9908 test Loss 0.0000 with MSE metric 4641.9440\n",
      "Time taken for 1 epoch: 2.180638074874878 secs\n",
      "\n",
      "Epoch 254 batch 0 train Loss 126.5213 test Loss 0.0000 with MSE metric 4643.1685\n",
      "Time taken for 1 epoch: 2.167409896850586 secs\n",
      "\n",
      "Epoch 255 batch 0 train Loss 126.0557 test Loss 0.0000 with MSE metric 4643.7175\n",
      "Time taken for 1 epoch: 2.1928160190582275 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 batch 0 train Loss 125.5917 test Loss 0.0000 with MSE metric 4640.9786\n",
      "Time taken for 1 epoch: 2.380682945251465 secs\n",
      "\n",
      "Epoch 257 batch 0 train Loss 125.1326 test Loss 0.0000 with MSE metric 4639.7861\n",
      "Time taken for 1 epoch: 2.351369857788086 secs\n",
      "\n",
      "Epoch 258 batch 0 train Loss 124.6765 test Loss 0.0000 with MSE metric 4640.1807\n",
      "Time taken for 1 epoch: 2.2309062480926514 secs\n",
      "\n",
      "Epoch 259 batch 0 train Loss 124.2224 test Loss 0.0000 with MSE metric 4635.9967\n",
      "Time taken for 1 epoch: 2.2347140312194824 secs\n",
      "\n",
      "Epoch 260 batch 0 train Loss 123.7740 test Loss 0.0000 with MSE metric 4637.5249\n",
      "Time taken for 1 epoch: 2.195651054382324 secs\n",
      "\n",
      "Epoch 261 batch 0 train Loss 123.3256 test Loss 0.0000 with MSE metric 4631.6629\n",
      "Time taken for 1 epoch: 2.245823860168457 secs\n",
      "\n",
      "Epoch 262 batch 0 train Loss 122.8812 test Loss 0.0000 with MSE metric 4627.0031\n",
      "Time taken for 1 epoch: 2.1795856952667236 secs\n",
      "\n",
      "Epoch 263 batch 0 train Loss 122.4407 test Loss 0.0000 with MSE metric 4622.5440\n",
      "Time taken for 1 epoch: 2.1325621604919434 secs\n",
      "\n",
      "Epoch 264 batch 0 train Loss 122.0033 test Loss 0.0000 with MSE metric 4622.4295\n",
      "Time taken for 1 epoch: 2.0835840702056885 secs\n",
      "\n",
      "Epoch 265 batch 0 train Loss 121.5668 test Loss 0.0000 with MSE metric 4614.6393\n",
      "Time taken for 1 epoch: 2.1499180793762207 secs\n",
      "\n",
      "Epoch 266 batch 0 train Loss 121.1382 test Loss 0.0000 with MSE metric 4615.8680\n",
      "Time taken for 1 epoch: 2.2729930877685547 secs\n",
      "\n",
      "Epoch 267 batch 0 train Loss 120.7118 test Loss 0.0000 with MSE metric 4617.0105\n",
      "Time taken for 1 epoch: 2.2339351177215576 secs\n",
      "\n",
      "Epoch 268 batch 0 train Loss 120.2880 test Loss 0.0000 with MSE metric 4616.3820\n",
      "Time taken for 1 epoch: 2.267112970352173 secs\n",
      "\n",
      "Epoch 269 batch 0 train Loss 119.8671 test Loss 0.0000 with MSE metric 4613.5762\n",
      "Time taken for 1 epoch: 2.172027111053467 secs\n",
      "\n",
      "Epoch 270 batch 0 train Loss 119.4487 test Loss 0.0000 with MSE metric 4610.1235\n",
      "Time taken for 1 epoch: 2.200300931930542 secs\n",
      "\n",
      "Epoch 271 batch 0 train Loss 119.0341 test Loss 0.0000 with MSE metric 4612.5821\n",
      "Time taken for 1 epoch: 2.1491382122039795 secs\n",
      "\n",
      "Epoch 272 batch 0 train Loss 118.6235 test Loss 0.0000 with MSE metric 4618.6452\n",
      "Time taken for 1 epoch: 2.222187042236328 secs\n",
      "\n",
      "Epoch 273 batch 0 train Loss 118.2157 test Loss 0.0000 with MSE metric 4620.7073\n",
      "Time taken for 1 epoch: 2.1435041427612305 secs\n",
      "\n",
      "Epoch 274 batch 0 train Loss 117.8093 test Loss 0.0000 with MSE metric 4620.4415\n",
      "Time taken for 1 epoch: 2.112006187438965 secs\n",
      "\n",
      "Epoch 275 batch 0 train Loss 117.4055 test Loss 0.0000 with MSE metric 4620.5968\n",
      "Time taken for 1 epoch: 2.168635845184326 secs\n",
      "\n",
      "Epoch 276 batch 0 train Loss 117.0028 test Loss 0.0000 with MSE metric 4611.1944\n",
      "Time taken for 1 epoch: 2.1093380451202393 secs\n",
      "\n",
      "Epoch 277 batch 0 train Loss 116.6019 test Loss 0.0000 with MSE metric 4602.4753\n",
      "Time taken for 1 epoch: 2.1651101112365723 secs\n",
      "\n",
      "Epoch 278 batch 0 train Loss 116.2048 test Loss 0.0000 with MSE metric 4594.6141\n",
      "Time taken for 1 epoch: 2.1429319381713867 secs\n",
      "\n",
      "Epoch 279 batch 0 train Loss 115.8125 test Loss 0.0000 with MSE metric 4595.8656\n",
      "Time taken for 1 epoch: 2.102484941482544 secs\n",
      "\n",
      "Epoch 280 batch 0 train Loss 115.4231 test Loss 0.0000 with MSE metric 4594.9663\n",
      "Time taken for 1 epoch: 2.127401351928711 secs\n",
      "\n",
      "Epoch 281 batch 0 train Loss 115.0364 test Loss 0.0000 with MSE metric 4599.7800\n",
      "Time taken for 1 epoch: 2.1011016368865967 secs\n",
      "\n",
      "Epoch 282 batch 0 train Loss 114.6516 test Loss 0.0000 with MSE metric 4596.4708\n",
      "Time taken for 1 epoch: 2.0890443325042725 secs\n",
      "\n",
      "Epoch 283 batch 0 train Loss 114.2708 test Loss 0.0000 with MSE metric 4600.0688\n",
      "Time taken for 1 epoch: 2.088947057723999 secs\n",
      "\n",
      "Epoch 284 batch 0 train Loss 113.8913 test Loss 0.0000 with MSE metric 4598.7301\n",
      "Time taken for 1 epoch: 2.086946964263916 secs\n",
      "\n",
      "Epoch 285 batch 0 train Loss 113.5157 test Loss 0.0000 with MSE metric 4603.0388\n",
      "Time taken for 1 epoch: 2.2583937644958496 secs\n",
      "\n",
      "Epoch 286 batch 0 train Loss 113.1412 test Loss 0.0000 with MSE metric 4602.8743\n",
      "Time taken for 1 epoch: 2.4082069396972656 secs\n",
      "\n",
      "Epoch 287 batch 0 train Loss 112.7704 test Loss 0.0000 with MSE metric 4603.0751\n",
      "Time taken for 1 epoch: 2.175361156463623 secs\n",
      "\n",
      "Epoch 288 batch 0 train Loss 112.4034 test Loss 0.0000 with MSE metric 4609.1263\n",
      "Time taken for 1 epoch: 2.0878148078918457 secs\n",
      "\n",
      "Epoch 289 batch 0 train Loss 112.0358 test Loss 0.0000 with MSE metric 4602.9345\n",
      "Time taken for 1 epoch: 2.0741682052612305 secs\n",
      "\n",
      "Epoch 290 batch 0 train Loss 111.6708 test Loss 0.0000 with MSE metric 4597.0417\n",
      "Time taken for 1 epoch: 2.075963020324707 secs\n",
      "\n",
      "Epoch 291 batch 0 train Loss 111.3093 test Loss 0.0000 with MSE metric 4594.0567\n",
      "Time taken for 1 epoch: 2.0737268924713135 secs\n",
      "\n",
      "Epoch 292 batch 0 train Loss 110.9503 test Loss 0.0000 with MSE metric 4594.8750\n",
      "Time taken for 1 epoch: 2.086820125579834 secs\n",
      "\n",
      "Epoch 293 batch 0 train Loss 110.5920 test Loss 0.0000 with MSE metric 4588.9022\n",
      "Time taken for 1 epoch: 2.0896620750427246 secs\n",
      "\n",
      "Epoch 294 batch 0 train Loss 110.2371 test Loss 0.0000 with MSE metric 4584.5959\n",
      "Time taken for 1 epoch: 2.0912888050079346 secs\n",
      "\n",
      "Epoch 295 batch 0 train Loss 109.8849 test Loss 0.0000 with MSE metric 4581.2352\n",
      "Time taken for 1 epoch: 2.0854110717773438 secs\n",
      "\n",
      "Epoch 296 batch 0 train Loss 109.5345 test Loss 0.0000 with MSE metric 4578.3473\n",
      "Time taken for 1 epoch: 2.1357948780059814 secs\n",
      "\n",
      "Epoch 297 batch 0 train Loss 109.1861 test Loss 0.0000 with MSE metric 4573.7984\n",
      "Time taken for 1 epoch: 2.1074979305267334 secs\n",
      "\n",
      "Epoch 298 batch 0 train Loss 108.8410 test Loss 0.0000 with MSE metric 4571.8498\n",
      "Time taken for 1 epoch: 2.445427894592285 secs\n",
      "\n",
      "Epoch 299 batch 0 train Loss 108.4969 test Loss 0.0000 with MSE metric 4564.7636\n",
      "Time taken for 1 epoch: 2.358494997024536 secs\n",
      "\n",
      "Epoch 300 batch 0 train Loss 108.1565 test Loss 0.0000 with MSE metric 4561.0169\n",
      "Time taken for 1 epoch: 2.4219610691070557 secs\n",
      "\n",
      "Epoch 301 batch 0 train Loss 107.8178 test Loss 0.0000 with MSE metric 4559.1422\n",
      "Time taken for 1 epoch: 2.4001049995422363 secs\n",
      "\n",
      "Epoch 302 batch 0 train Loss 107.4816 test Loss 0.0000 with MSE metric 4558.1728\n",
      "Time taken for 1 epoch: 2.1519758701324463 secs\n",
      "\n",
      "Epoch 303 batch 0 train Loss 107.1471 test Loss 0.0000 with MSE metric 4556.9987\n",
      "Time taken for 1 epoch: 2.4083871841430664 secs\n",
      "\n",
      "Epoch 304 batch 0 train Loss 106.8147 test Loss 0.0000 with MSE metric 4556.1837\n",
      "Time taken for 1 epoch: 2.4399287700653076 secs\n",
      "\n",
      "Epoch 305 batch 0 train Loss 106.4851 test Loss 0.0000 with MSE metric 4553.1152\n",
      "Time taken for 1 epoch: 2.165870189666748 secs\n",
      "\n",
      "Epoch 306 batch 0 train Loss 106.1567 test Loss 0.0000 with MSE metric 4549.4613\n",
      "Time taken for 1 epoch: 2.2301430702209473 secs\n",
      "\n",
      "Epoch 307 batch 0 train Loss 105.8314 test Loss 0.0000 with MSE metric 4555.4255\n",
      "Time taken for 1 epoch: 2.1581151485443115 secs\n",
      "\n",
      "Epoch 308 batch 0 train Loss 105.5077 test Loss 0.0000 with MSE metric 4555.6260\n",
      "Time taken for 1 epoch: 2.1711819171905518 secs\n",
      "\n",
      "Epoch 309 batch 0 train Loss 105.1858 test Loss 0.0000 with MSE metric 4551.9026\n",
      "Time taken for 1 epoch: 2.1310338973999023 secs\n",
      "\n",
      "Epoch 310 batch 0 train Loss 104.8669 test Loss 0.0000 with MSE metric 4554.7500\n",
      "Time taken for 1 epoch: 2.1165919303894043 secs\n",
      "\n",
      "Epoch 311 batch 0 train Loss 104.5497 test Loss 0.0000 with MSE metric 4557.6096\n",
      "Time taken for 1 epoch: 2.1521153450012207 secs\n",
      "\n",
      "Epoch 312 batch 0 train Loss 104.2343 test Loss 0.0000 with MSE metric 4560.4833\n",
      "Time taken for 1 epoch: 2.142930030822754 secs\n",
      "\n",
      "Epoch 313 batch 0 train Loss 103.9225 test Loss 0.0000 with MSE metric 4562.0618\n",
      "Time taken for 1 epoch: 2.161579132080078 secs\n",
      "\n",
      "Epoch 314 batch 0 train Loss 103.6107 test Loss 0.0000 with MSE metric 4562.3648\n",
      "Time taken for 1 epoch: 2.183151960372925 secs\n",
      "\n",
      "Epoch 315 batch 0 train Loss 103.3013 test Loss 0.0000 with MSE metric 4561.1615\n",
      "Time taken for 1 epoch: 2.128676176071167 secs\n",
      "\n",
      "Epoch 316 batch 0 train Loss 102.9940 test Loss 0.0000 with MSE metric 4562.2976\n",
      "Time taken for 1 epoch: 2.151812791824341 secs\n",
      "\n",
      "Epoch 317 batch 0 train Loss 102.6879 test Loss 0.0000 with MSE metric 4559.6647\n",
      "Time taken for 1 epoch: 2.1140129566192627 secs\n",
      "\n",
      "Epoch 318 batch 0 train Loss 102.3844 test Loss 0.0000 with MSE metric 4559.9036\n",
      "Time taken for 1 epoch: 2.1191859245300293 secs\n",
      "\n",
      "Epoch 319 batch 0 train Loss 102.0816 test Loss 0.0000 with MSE metric 4555.9859\n",
      "Time taken for 1 epoch: 2.0811946392059326 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320 batch 0 train Loss 101.7816 test Loss 0.0000 with MSE metric 4556.4266\n",
      "Time taken for 1 epoch: 2.1179027557373047 secs\n",
      "\n",
      "Epoch 321 batch 0 train Loss 101.4832 test Loss 0.0000 with MSE metric 4557.9267\n",
      "Time taken for 1 epoch: 2.097100019454956 secs\n",
      "\n",
      "Epoch 322 batch 0 train Loss 101.1863 test Loss 0.0000 with MSE metric 4558.1357\n",
      "Time taken for 1 epoch: 2.090707302093506 secs\n",
      "\n",
      "Epoch 323 batch 0 train Loss 100.8910 test Loss 0.0000 with MSE metric 4554.8647\n",
      "Time taken for 1 epoch: 2.097384214401245 secs\n",
      "\n",
      "Epoch 324 batch 0 train Loss 100.5967 test Loss 0.0000 with MSE metric 4549.5707\n",
      "Time taken for 1 epoch: 2.1591339111328125 secs\n",
      "\n",
      "Epoch 325 batch 0 train Loss 100.3051 test Loss 0.0000 with MSE metric 4547.9801\n",
      "Time taken for 1 epoch: 2.1055281162261963 secs\n",
      "\n",
      "Epoch 326 batch 0 train Loss 100.0156 test Loss 0.0000 with MSE metric 4547.1328\n",
      "Time taken for 1 epoch: 2.082562208175659 secs\n",
      "\n",
      "Epoch 327 batch 0 train Loss 99.7271 test Loss 0.0000 with MSE metric 4543.4950\n",
      "Time taken for 1 epoch: 2.107508897781372 secs\n",
      "\n",
      "Epoch 328 batch 0 train Loss 99.4411 test Loss 0.0000 with MSE metric 4544.0741\n",
      "Time taken for 1 epoch: 2.0896170139312744 secs\n",
      "\n",
      "Epoch 329 batch 0 train Loss 99.1559 test Loss 0.0000 with MSE metric 4539.7225\n",
      "Time taken for 1 epoch: 2.082785129547119 secs\n",
      "\n",
      "Epoch 330 batch 0 train Loss 98.8730 test Loss 0.0000 with MSE metric 4539.0141\n",
      "Time taken for 1 epoch: 2.0729422569274902 secs\n",
      "\n",
      "Epoch 331 batch 0 train Loss 98.5917 test Loss 0.0000 with MSE metric 4535.7621\n",
      "Time taken for 1 epoch: 2.093966007232666 secs\n",
      "\n",
      "Epoch 332 batch 0 train Loss 98.3119 test Loss 0.0000 with MSE metric 4533.1102\n",
      "Time taken for 1 epoch: 2.0757699012756348 secs\n",
      "\n",
      "Epoch 333 batch 0 train Loss 98.0343 test Loss 0.0000 with MSE metric 4532.6715\n",
      "Time taken for 1 epoch: 2.098051071166992 secs\n",
      "\n",
      "Epoch 334 batch 0 train Loss 97.7581 test Loss 0.0000 with MSE metric 4533.1324\n",
      "Time taken for 1 epoch: 2.096662998199463 secs\n",
      "\n",
      "Epoch 335 batch 0 train Loss 97.4832 test Loss 0.0000 with MSE metric 4529.8939\n",
      "Time taken for 1 epoch: 2.1272010803222656 secs\n",
      "\n",
      "Epoch 336 batch 0 train Loss 97.2099 test Loss 0.0000 with MSE metric 4527.0335\n",
      "Time taken for 1 epoch: 2.0870721340179443 secs\n",
      "\n",
      "Epoch 337 batch 0 train Loss 96.9375 test Loss 0.0000 with MSE metric 4520.6359\n",
      "Time taken for 1 epoch: 2.099571943283081 secs\n",
      "\n",
      "Epoch 338 batch 0 train Loss 96.6672 test Loss 0.0000 with MSE metric 4516.7561\n",
      "Time taken for 1 epoch: 2.0846750736236572 secs\n",
      "\n",
      "Epoch 339 batch 0 train Loss 96.3986 test Loss 0.0000 with MSE metric 4514.3420\n",
      "Time taken for 1 epoch: 2.061922073364258 secs\n",
      "\n",
      "Epoch 340 batch 0 train Loss 96.1320 test Loss 0.0000 with MSE metric 4514.2814\n",
      "Time taken for 1 epoch: 2.084501028060913 secs\n",
      "\n",
      "Epoch 341 batch 0 train Loss 95.8656 test Loss 0.0000 with MSE metric 4507.9822\n",
      "Time taken for 1 epoch: 2.0669021606445312 secs\n",
      "\n",
      "Epoch 342 batch 0 train Loss 95.6021 test Loss 0.0000 with MSE metric 4507.1985\n",
      "Time taken for 1 epoch: 2.0600030422210693 secs\n",
      "\n",
      "Epoch 343 batch 0 train Loss 95.3400 test Loss 0.0000 with MSE metric 4507.1799\n",
      "Time taken for 1 epoch: 2.1028449535369873 secs\n",
      "\n",
      "Epoch 344 batch 0 train Loss 95.0793 test Loss 0.0000 with MSE metric 4506.4216\n",
      "Time taken for 1 epoch: 2.090029001235962 secs\n",
      "\n",
      "Epoch 345 batch 0 train Loss 94.8196 test Loss 0.0000 with MSE metric 4502.6824\n",
      "Time taken for 1 epoch: 2.1000988483428955 secs\n",
      "\n",
      "Epoch 346 batch 0 train Loss 94.5611 test Loss 0.0000 with MSE metric 4497.9144\n",
      "Time taken for 1 epoch: 2.068798303604126 secs\n",
      "\n",
      "Epoch 347 batch 0 train Loss 94.3052 test Loss 0.0000 with MSE metric 4500.3288\n",
      "Time taken for 1 epoch: 2.1150259971618652 secs\n",
      "\n",
      "Epoch 348 batch 0 train Loss 94.0504 test Loss 0.0000 with MSE metric 4499.6104\n",
      "Time taken for 1 epoch: 2.0790882110595703 secs\n",
      "\n",
      "Epoch 349 batch 0 train Loss 93.7969 test Loss 0.0000 with MSE metric 4498.2732\n",
      "Time taken for 1 epoch: 2.1062912940979004 secs\n",
      "\n",
      "Epoch 350 batch 0 train Loss 93.5441 test Loss 0.0000 with MSE metric 4492.7170\n",
      "Time taken for 1 epoch: 2.3989109992980957 secs\n",
      "\n",
      "Epoch 351 batch 0 train Loss 93.2928 test Loss 0.0000 with MSE metric 4487.2517\n",
      "Time taken for 1 epoch: 2.327523946762085 secs\n",
      "\n",
      "Epoch 352 batch 0 train Loss 93.0429 test Loss 0.0000 with MSE metric 4482.9462\n",
      "Time taken for 1 epoch: 2.228692054748535 secs\n",
      "\n",
      "Epoch 353 batch 0 train Loss 92.7953 test Loss 0.0000 with MSE metric 4480.7777\n",
      "Time taken for 1 epoch: 2.2394039630889893 secs\n",
      "\n",
      "Epoch 354 batch 0 train Loss 92.5487 test Loss 0.0000 with MSE metric 4478.6453\n",
      "Time taken for 1 epoch: 2.1846048831939697 secs\n",
      "\n",
      "Epoch 355 batch 0 train Loss 92.3038 test Loss 0.0000 with MSE metric 4478.1943\n",
      "Time taken for 1 epoch: 2.105991840362549 secs\n",
      "\n",
      "Epoch 356 batch 0 train Loss 92.0605 test Loss 0.0000 with MSE metric 4476.2277\n",
      "Time taken for 1 epoch: 2.090440034866333 secs\n",
      "\n",
      "Epoch 357 batch 0 train Loss 91.8182 test Loss 0.0000 with MSE metric 4474.1243\n",
      "Time taken for 1 epoch: 2.2788498401641846 secs\n",
      "\n",
      "Epoch 358 batch 0 train Loss 91.5773 test Loss 0.0000 with MSE metric 4473.7535\n",
      "Time taken for 1 epoch: 2.2717089653015137 secs\n",
      "\n",
      "Epoch 359 batch 0 train Loss 91.3376 test Loss 0.0000 with MSE metric 4472.6588\n",
      "Time taken for 1 epoch: 2.360323190689087 secs\n",
      "\n",
      "Epoch 360 batch 0 train Loss 91.0992 test Loss 0.0000 with MSE metric 4470.4271\n",
      "Time taken for 1 epoch: 2.201641082763672 secs\n",
      "\n",
      "Epoch 361 batch 0 train Loss 90.8614 test Loss 0.0000 with MSE metric 4465.6592\n",
      "Time taken for 1 epoch: 2.188586950302124 secs\n",
      "\n",
      "Epoch 362 batch 0 train Loss 90.6255 test Loss 0.0000 with MSE metric 4463.7689\n",
      "Time taken for 1 epoch: 2.1724750995635986 secs\n",
      "\n",
      "Epoch 363 batch 0 train Loss 90.3908 test Loss 0.0000 with MSE metric 4461.6027\n",
      "Time taken for 1 epoch: 2.2162580490112305 secs\n",
      "\n",
      "Epoch 364 batch 0 train Loss 90.1575 test Loss 0.0000 with MSE metric 4460.2699\n",
      "Time taken for 1 epoch: 2.136913776397705 secs\n",
      "\n",
      "Epoch 365 batch 0 train Loss 89.9245 test Loss 0.0000 with MSE metric 4454.4488\n",
      "Time taken for 1 epoch: 2.1098549365997314 secs\n",
      "\n",
      "Epoch 366 batch 0 train Loss 89.6937 test Loss 0.0000 with MSE metric 4451.8409\n",
      "Time taken for 1 epoch: 2.1044201850891113 secs\n",
      "\n",
      "Epoch 367 batch 0 train Loss 89.4647 test Loss 0.0000 with MSE metric 4451.8693\n",
      "Time taken for 1 epoch: 2.186537027359009 secs\n",
      "\n",
      "Epoch 368 batch 0 train Loss 89.2367 test Loss 0.0000 with MSE metric 4452.1471\n",
      "Time taken for 1 epoch: 2.2282400131225586 secs\n",
      "\n",
      "Epoch 369 batch 0 train Loss 89.0095 test Loss 0.0000 with MSE metric 4448.5174\n",
      "Time taken for 1 epoch: 2.220705986022949 secs\n",
      "\n",
      "Epoch 370 batch 0 train Loss 88.7835 test Loss 0.0000 with MSE metric 4445.7798\n",
      "Time taken for 1 epoch: 2.1398367881774902 secs\n",
      "\n",
      "Epoch 371 batch 0 train Loss 88.5593 test Loss 0.0000 with MSE metric 4447.5362\n",
      "Time taken for 1 epoch: 2.256010055541992 secs\n",
      "\n",
      "Epoch 372 batch 0 train Loss 88.3361 test Loss 0.0000 with MSE metric 4447.1154\n",
      "Time taken for 1 epoch: 2.21039080619812 secs\n",
      "\n",
      "Epoch 373 batch 0 train Loss 88.1130 test Loss 0.0000 with MSE metric 4442.2160\n",
      "Time taken for 1 epoch: 2.0888400077819824 secs\n",
      "\n",
      "Epoch 374 batch 0 train Loss 87.8921 test Loss 0.0000 with MSE metric 4441.8211\n",
      "Time taken for 1 epoch: 2.087070941925049 secs\n",
      "\n",
      "Epoch 375 batch 0 train Loss 87.6722 test Loss 0.0000 with MSE metric 4441.5063\n",
      "Time taken for 1 epoch: 2.1167709827423096 secs\n",
      "\n",
      "Epoch 376 batch 0 train Loss 87.4533 test Loss 0.0000 with MSE metric 4438.8070\n",
      "Time taken for 1 epoch: 2.1200950145721436 secs\n",
      "\n",
      "Epoch 377 batch 0 train Loss 87.2356 test Loss 0.0000 with MSE metric 4436.5496\n",
      "Time taken for 1 epoch: 2.114623785018921 secs\n",
      "\n",
      "Epoch 378 batch 0 train Loss 87.0188 test Loss 0.0000 with MSE metric 4433.4883\n",
      "Time taken for 1 epoch: 2.0850307941436768 secs\n",
      "\n",
      "Epoch 379 batch 0 train Loss 86.8039 test Loss 0.0000 with MSE metric 4434.7403\n",
      "Time taken for 1 epoch: 2.0632269382476807 secs\n",
      "\n",
      "Epoch 380 batch 0 train Loss 86.5904 test Loss 0.0000 with MSE metric 4440.1550\n",
      "Time taken for 1 epoch: 2.0752360820770264 secs\n",
      "\n",
      "Epoch 381 batch 0 train Loss 86.3776 test Loss 0.0000 with MSE metric 4438.4600\n",
      "Time taken for 1 epoch: 2.0893568992614746 secs\n",
      "\n",
      "Epoch 382 batch 0 train Loss 86.1650 test Loss 0.0000 with MSE metric 4431.7281\n",
      "Time taken for 1 epoch: 2.072126865386963 secs\n",
      "\n",
      "Epoch 383 batch 0 train Loss 85.9541 test Loss 0.0000 with MSE metric 4429.3780\n",
      "Time taken for 1 epoch: 2.08123517036438 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384 batch 0 train Loss 85.7445 test Loss 0.0000 with MSE metric 4430.0921\n",
      "Time taken for 1 epoch: 2.09932017326355 secs\n",
      "\n",
      "Epoch 385 batch 0 train Loss 85.5367 test Loss 0.0000 with MSE metric 4432.9507\n",
      "Time taken for 1 epoch: 2.0879459381103516 secs\n",
      "\n",
      "Epoch 386 batch 0 train Loss 85.3289 test Loss 0.0000 with MSE metric 4430.5888\n",
      "Time taken for 1 epoch: 2.07283616065979 secs\n",
      "\n",
      "Epoch 387 batch 0 train Loss 85.1230 test Loss 0.0000 with MSE metric 4432.2023\n",
      "Time taken for 1 epoch: 2.094473361968994 secs\n",
      "\n",
      "Epoch 388 batch 0 train Loss 84.9178 test Loss 0.0000 with MSE metric 4432.3165\n",
      "Time taken for 1 epoch: 2.0779871940612793 secs\n",
      "\n",
      "Epoch 389 batch 0 train Loss 84.7126 test Loss 0.0000 with MSE metric 4426.2870\n",
      "Time taken for 1 epoch: 2.0440289974212646 secs\n",
      "\n",
      "Epoch 390 batch 0 train Loss 84.5084 test Loss 0.0000 with MSE metric 4421.7598\n",
      "Time taken for 1 epoch: 2.059885025024414 secs\n",
      "\n",
      "Epoch 391 batch 0 train Loss 84.3085 test Loss 0.0000 with MSE metric 4422.5824\n",
      "Time taken for 1 epoch: 2.0936927795410156 secs\n",
      "\n",
      "Epoch 392 batch 0 train Loss 84.1076 test Loss 0.0000 with MSE metric 4418.3431\n",
      "Time taken for 1 epoch: 2.080239772796631 secs\n",
      "\n",
      "Epoch 393 batch 0 train Loss 83.9114 test Loss 0.0000 with MSE metric 4418.7531\n",
      "Time taken for 1 epoch: 2.0715219974517822 secs\n",
      "\n",
      "Epoch 394 batch 0 train Loss 83.7171 test Loss 0.0000 with MSE metric 4420.0355\n",
      "Time taken for 1 epoch: 2.0982918739318848 secs\n",
      "\n",
      "Epoch 395 batch 0 train Loss 83.5233 test Loss 0.0000 with MSE metric 4417.8323\n",
      "Time taken for 1 epoch: 2.098114013671875 secs\n",
      "\n",
      "Epoch 396 batch 0 train Loss 83.3318 test Loss 0.0000 with MSE metric 4418.8583\n",
      "Time taken for 1 epoch: 2.091949939727783 secs\n",
      "\n",
      "Epoch 397 batch 0 train Loss 83.1389 test Loss 0.0000 with MSE metric 4416.7831\n",
      "Time taken for 1 epoch: 2.0847010612487793 secs\n",
      "\n",
      "Epoch 398 batch 0 train Loss 82.9450 test Loss 0.0000 with MSE metric 4415.2768\n",
      "Time taken for 1 epoch: 2.091383934020996 secs\n",
      "\n",
      "Epoch 399 batch 0 train Loss 82.7507 test Loss 0.0000 with MSE metric 4413.7537\n",
      "Time taken for 1 epoch: 2.072739839553833 secs\n",
      "\n",
      "Epoch 400 batch 0 train Loss 82.5612 test Loss 0.0000 with MSE metric 4410.2296\n",
      "Time taken for 1 epoch: 2.074981927871704 secs\n",
      "\n",
      "Epoch 401 batch 0 train Loss 82.3683 test Loss 0.0000 with MSE metric 4405.9868\n",
      "Time taken for 1 epoch: 2.0623559951782227 secs\n",
      "\n",
      "Epoch 402 batch 0 train Loss 82.1780 test Loss 0.0000 with MSE metric 4403.0625\n",
      "Time taken for 1 epoch: 2.0967187881469727 secs\n",
      "\n",
      "Epoch 403 batch 0 train Loss 81.9886 test Loss 0.0000 with MSE metric 4397.6444\n",
      "Time taken for 1 epoch: 2.064345121383667 secs\n",
      "\n",
      "Epoch 404 batch 0 train Loss 81.8034 test Loss 0.0000 with MSE metric 4399.1485\n",
      "Time taken for 1 epoch: 2.0567290782928467 secs\n",
      "\n",
      "Epoch 405 batch 0 train Loss 81.6168 test Loss 0.0000 with MSE metric 4395.3060\n",
      "Time taken for 1 epoch: 2.0991411209106445 secs\n",
      "\n",
      "Epoch 406 batch 0 train Loss 81.4319 test Loss 0.0000 with MSE metric 4395.9148\n",
      "Time taken for 1 epoch: 2.0880279541015625 secs\n",
      "\n",
      "Epoch 407 batch 0 train Loss 81.2457 test Loss 0.0000 with MSE metric 4392.1413\n",
      "Time taken for 1 epoch: 2.0724339485168457 secs\n",
      "\n",
      "Epoch 408 batch 0 train Loss 81.0603 test Loss 0.0000 with MSE metric 4390.0724\n",
      "Time taken for 1 epoch: 2.078810930252075 secs\n",
      "\n",
      "Epoch 409 batch 0 train Loss 80.8750 test Loss 0.0000 with MSE metric 4386.7517\n",
      "Time taken for 1 epoch: 2.0888798236846924 secs\n",
      "\n",
      "Epoch 410 batch 0 train Loss 80.6930 test Loss 0.0000 with MSE metric 4384.6770\n",
      "Time taken for 1 epoch: 2.083885669708252 secs\n",
      "\n",
      "Epoch 411 batch 0 train Loss 80.5095 test Loss 0.0000 with MSE metric 4381.7364\n",
      "Time taken for 1 epoch: 2.0837512016296387 secs\n",
      "\n",
      "Epoch 412 batch 0 train Loss 80.3274 test Loss 0.0000 with MSE metric 4380.4011\n",
      "Time taken for 1 epoch: 2.077648878097534 secs\n",
      "\n",
      "Epoch 413 batch 0 train Loss 80.1468 test Loss 0.0000 with MSE metric 4379.7103\n",
      "Time taken for 1 epoch: 2.0938198566436768 secs\n",
      "\n",
      "Epoch 414 batch 0 train Loss 79.9678 test Loss 0.0000 with MSE metric 4380.8075\n",
      "Time taken for 1 epoch: 2.0665299892425537 secs\n",
      "\n",
      "Epoch 415 batch 0 train Loss 79.7897 test Loss 0.0000 with MSE metric 4382.3476\n",
      "Time taken for 1 epoch: 2.0966410636901855 secs\n",
      "\n",
      "Epoch 416 batch 0 train Loss 79.6113 test Loss 0.0000 with MSE metric 4380.7751\n",
      "Time taken for 1 epoch: 2.052830219268799 secs\n",
      "\n",
      "Epoch 417 batch 0 train Loss 79.4331 test Loss 0.0000 with MSE metric 4379.0845\n",
      "Time taken for 1 epoch: 2.0926947593688965 secs\n",
      "\n",
      "Epoch 418 batch 0 train Loss 79.2553 test Loss 0.0000 with MSE metric 4375.0525\n",
      "Time taken for 1 epoch: 2.0870659351348877 secs\n",
      "\n",
      "Epoch 419 batch 0 train Loss 79.0851 test Loss 0.0000 with MSE metric 4375.4774\n",
      "Time taken for 1 epoch: 2.073521137237549 secs\n",
      "\n",
      "Epoch 420 batch 0 train Loss 78.9119 test Loss 0.0000 with MSE metric 4374.4923\n",
      "Time taken for 1 epoch: 2.092013120651245 secs\n",
      "\n",
      "Epoch 421 batch 0 train Loss 78.7427 test Loss 0.0000 with MSE metric 4372.1990\n",
      "Time taken for 1 epoch: 2.085425853729248 secs\n",
      "\n",
      "Epoch 422 batch 0 train Loss 78.5766 test Loss 0.0000 with MSE metric 4369.5547\n",
      "Time taken for 1 epoch: 2.0936009883880615 secs\n",
      "\n",
      "Epoch 423 batch 0 train Loss 78.4151 test Loss 0.0000 with MSE metric 4367.5929\n",
      "Time taken for 1 epoch: 2.07524037361145 secs\n",
      "\n",
      "Epoch 424 batch 0 train Loss 78.2533 test Loss 0.0000 with MSE metric 4365.7500\n",
      "Time taken for 1 epoch: 2.0981409549713135 secs\n",
      "\n",
      "Epoch 425 batch 0 train Loss 78.0979 test Loss 0.0000 with MSE metric 4365.8033\n",
      "Time taken for 1 epoch: 2.0755081176757812 secs\n",
      "\n",
      "Epoch 426 batch 0 train Loss 77.9354 test Loss 0.0000 with MSE metric 4361.5174\n",
      "Time taken for 1 epoch: 2.08317494392395 secs\n",
      "\n",
      "Epoch 427 batch 0 train Loss 77.7810 test Loss 0.0000 with MSE metric 4365.5325\n",
      "Time taken for 1 epoch: 2.090398073196411 secs\n",
      "\n",
      "Epoch 428 batch 0 train Loss 77.6235 test Loss 0.0000 with MSE metric 4364.7002\n",
      "Time taken for 1 epoch: 2.087252140045166 secs\n",
      "\n",
      "Epoch 429 batch 0 train Loss 77.4647 test Loss 0.0000 with MSE metric 4362.2699\n",
      "Time taken for 1 epoch: 2.0772809982299805 secs\n",
      "\n",
      "Epoch 430 batch 0 train Loss 77.3055 test Loss 0.0000 with MSE metric 4361.7188\n",
      "Time taken for 1 epoch: 2.0823447704315186 secs\n",
      "\n",
      "Epoch 431 batch 0 train Loss 77.1477 test Loss 0.0000 with MSE metric 4363.5088\n",
      "Time taken for 1 epoch: 2.085139036178589 secs\n",
      "\n",
      "Epoch 432 batch 0 train Loss 76.9867 test Loss 0.0000 with MSE metric 4361.0323\n",
      "Time taken for 1 epoch: 2.0879228115081787 secs\n",
      "\n",
      "Epoch 433 batch 0 train Loss 76.8265 test Loss 0.0000 with MSE metric 4363.8750\n",
      "Time taken for 1 epoch: 2.0783791542053223 secs\n",
      "\n",
      "Epoch 434 batch 0 train Loss 76.6653 test Loss 0.0000 with MSE metric 4366.3944\n",
      "Time taken for 1 epoch: 2.1008121967315674 secs\n",
      "\n",
      "Epoch 435 batch 0 train Loss 76.5031 test Loss 0.0000 with MSE metric 4365.0702\n",
      "Time taken for 1 epoch: 2.203892946243286 secs\n",
      "\n",
      "Epoch 436 batch 0 train Loss 76.3424 test Loss 0.0000 with MSE metric 4362.2632\n",
      "Time taken for 1 epoch: 2.2158210277557373 secs\n",
      "\n",
      "Epoch 437 batch 0 train Loss 76.1852 test Loss 0.0000 with MSE metric 4361.2456\n",
      "Time taken for 1 epoch: 2.1999969482421875 secs\n",
      "\n",
      "Epoch 438 batch 0 train Loss 76.0256 test Loss 0.0000 with MSE metric 4360.8956\n",
      "Time taken for 1 epoch: 2.194477081298828 secs\n",
      "\n",
      "Epoch 439 batch 0 train Loss 75.8657 test Loss 0.0000 with MSE metric 4359.6926\n",
      "Time taken for 1 epoch: 2.279985189437866 secs\n",
      "\n",
      "Epoch 440 batch 0 train Loss 75.7070 test Loss 0.0000 with MSE metric 4359.2462\n",
      "Time taken for 1 epoch: 2.2030580043792725 secs\n",
      "\n",
      "Epoch 441 batch 0 train Loss 75.5496 test Loss 0.0000 with MSE metric 4358.7062\n",
      "Time taken for 1 epoch: 2.207474946975708 secs\n",
      "\n",
      "Epoch 442 batch 0 train Loss 75.3940 test Loss 0.0000 with MSE metric 4361.5172\n",
      "Time taken for 1 epoch: 2.3105831146240234 secs\n",
      "\n",
      "Epoch 443 batch 0 train Loss 75.2390 test Loss 0.0000 with MSE metric 4361.0925\n",
      "Time taken for 1 epoch: 2.2415809631347656 secs\n",
      "\n",
      "Epoch 444 batch 0 train Loss 75.0842 test Loss 0.0000 with MSE metric 4358.2221\n",
      "Time taken for 1 epoch: 2.152163028717041 secs\n",
      "\n",
      "Epoch 445 batch 0 train Loss 74.9312 test Loss 0.0000 with MSE metric 4360.1666\n",
      "Time taken for 1 epoch: 2.4888648986816406 secs\n",
      "\n",
      "Epoch 446 batch 0 train Loss 74.7782 test Loss 0.0000 with MSE metric 4370.2800\n",
      "Time taken for 1 epoch: 2.2595162391662598 secs\n",
      "\n",
      "Epoch 447 batch 0 train Loss 74.6243 test Loss 0.0000 with MSE metric 4371.2494\n",
      "Time taken for 1 epoch: 2.203230857849121 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448 batch 0 train Loss 74.4692 test Loss 0.0000 with MSE metric 4366.6950\n",
      "Time taken for 1 epoch: 2.2143821716308594 secs\n",
      "\n",
      "Epoch 449 batch 0 train Loss 74.3159 test Loss 0.0000 with MSE metric 4366.8722\n",
      "Time taken for 1 epoch: 2.3053297996520996 secs\n",
      "\n",
      "Epoch 450 batch 0 train Loss 74.1651 test Loss 0.0000 with MSE metric 4367.7258\n",
      "Time taken for 1 epoch: 2.431140184402466 secs\n",
      "\n",
      "Epoch 451 batch 0 train Loss 74.0138 test Loss 0.0000 with MSE metric 4373.1165\n",
      "Time taken for 1 epoch: 2.3329808712005615 secs\n",
      "\n",
      "Epoch 452 batch 0 train Loss 73.8625 test Loss 0.0000 with MSE metric 4373.5946\n",
      "Time taken for 1 epoch: 2.116121768951416 secs\n",
      "\n",
      "Epoch 453 batch 0 train Loss 73.7128 test Loss 0.0000 with MSE metric 4372.7648\n",
      "Time taken for 1 epoch: 2.145453929901123 secs\n",
      "\n",
      "Epoch 454 batch 0 train Loss 73.5630 test Loss 0.0000 with MSE metric 4366.7246\n",
      "Time taken for 1 epoch: 2.1397459506988525 secs\n",
      "\n",
      "Epoch 455 batch 0 train Loss 73.4157 test Loss 0.0000 with MSE metric 4367.6265\n",
      "Time taken for 1 epoch: 2.2238662242889404 secs\n",
      "\n",
      "Epoch 456 batch 0 train Loss 73.2692 test Loss 0.0000 with MSE metric 4367.9848\n",
      "Time taken for 1 epoch: 2.2794487476348877 secs\n",
      "\n",
      "Epoch 457 batch 0 train Loss 73.1228 test Loss 0.0000 with MSE metric 4369.2053\n",
      "Time taken for 1 epoch: 2.2133631706237793 secs\n",
      "\n",
      "Epoch 458 batch 0 train Loss 72.9764 test Loss 0.0000 with MSE metric 4367.9105\n",
      "Time taken for 1 epoch: 2.2094979286193848 secs\n",
      "\n",
      "Epoch 459 batch 0 train Loss 72.8297 test Loss 0.0000 with MSE metric 4367.3919\n",
      "Time taken for 1 epoch: 2.0924441814422607 secs\n",
      "\n",
      "Epoch 460 batch 0 train Loss 72.6839 test Loss 0.0000 with MSE metric 4368.4938\n",
      "Time taken for 1 epoch: 2.153022050857544 secs\n",
      "\n",
      "Epoch 461 batch 0 train Loss 72.5382 test Loss 0.0000 with MSE metric 4369.7024\n",
      "Time taken for 1 epoch: 2.20892596244812 secs\n",
      "\n",
      "Epoch 462 batch 0 train Loss 72.3929 test Loss 0.0000 with MSE metric 4368.8541\n",
      "Time taken for 1 epoch: 2.1445682048797607 secs\n",
      "\n",
      "Epoch 463 batch 0 train Loss 72.2497 test Loss 0.0000 with MSE metric 4369.8126\n",
      "Time taken for 1 epoch: 2.12024188041687 secs\n",
      "\n",
      "Epoch 464 batch 0 train Loss 72.1056 test Loss 0.0000 with MSE metric 4370.3683\n",
      "Time taken for 1 epoch: 2.091430187225342 secs\n",
      "\n",
      "Epoch 465 batch 0 train Loss 71.9617 test Loss 0.0000 with MSE metric 4367.4156\n",
      "Time taken for 1 epoch: 2.0742509365081787 secs\n",
      "\n",
      "Epoch 466 batch 0 train Loss 71.8182 test Loss 0.0000 with MSE metric 4362.0455\n",
      "Time taken for 1 epoch: 2.083839178085327 secs\n",
      "\n",
      "Epoch 467 batch 0 train Loss 71.6764 test Loss 0.0000 with MSE metric 4360.3713\n",
      "Time taken for 1 epoch: 2.3336148262023926 secs\n",
      "\n",
      "Epoch 468 batch 0 train Loss 71.5346 test Loss 0.0000 with MSE metric 4356.8355\n",
      "Time taken for 1 epoch: 2.1704909801483154 secs\n",
      "\n",
      "Epoch 469 batch 0 train Loss 71.3937 test Loss 0.0000 with MSE metric 4353.7367\n",
      "Time taken for 1 epoch: 2.133991003036499 secs\n",
      "\n",
      "Epoch 470 batch 0 train Loss 71.2526 test Loss 0.0000 with MSE metric 4348.0195\n",
      "Time taken for 1 epoch: 2.155172109603882 secs\n",
      "\n",
      "Epoch 471 batch 0 train Loss 71.1138 test Loss 0.0000 with MSE metric 4352.3293\n",
      "Time taken for 1 epoch: 2.1197938919067383 secs\n",
      "\n",
      "Epoch 472 batch 0 train Loss 70.9741 test Loss 0.0000 with MSE metric 4348.5884\n",
      "Time taken for 1 epoch: 2.189894914627075 secs\n",
      "\n",
      "Epoch 473 batch 0 train Loss 70.8348 test Loss 0.0000 with MSE metric 4345.2407\n",
      "Time taken for 1 epoch: 2.1244559288024902 secs\n",
      "\n",
      "Epoch 474 batch 0 train Loss 70.6961 test Loss 0.0000 with MSE metric 4342.1943\n",
      "Time taken for 1 epoch: 2.1489620208740234 secs\n",
      "\n",
      "Epoch 475 batch 0 train Loss 70.5588 test Loss 0.0000 with MSE metric 4340.5908\n",
      "Time taken for 1 epoch: 2.1514248847961426 secs\n",
      "\n",
      "Epoch 476 batch 0 train Loss 70.4231 test Loss 0.0000 with MSE metric 4343.3364\n",
      "Time taken for 1 epoch: 2.103144884109497 secs\n",
      "\n",
      "Epoch 477 batch 0 train Loss 70.2862 test Loss 0.0000 with MSE metric 4340.3924\n",
      "Time taken for 1 epoch: 2.0740559101104736 secs\n",
      "\n",
      "Epoch 478 batch 0 train Loss 70.1500 test Loss 0.0000 with MSE metric 4337.3373\n",
      "Time taken for 1 epoch: 2.063627004623413 secs\n",
      "\n",
      "Epoch 479 batch 0 train Loss 70.0154 test Loss 0.0000 with MSE metric 4341.9601\n",
      "Time taken for 1 epoch: 2.0723140239715576 secs\n",
      "\n",
      "Epoch 480 batch 0 train Loss 69.8810 test Loss 0.0000 with MSE metric 4342.3562\n",
      "Time taken for 1 epoch: 2.0776498317718506 secs\n",
      "\n",
      "Epoch 481 batch 0 train Loss 69.7475 test Loss 0.0000 with MSE metric 4344.1844\n",
      "Time taken for 1 epoch: 2.080465793609619 secs\n",
      "\n",
      "Epoch 482 batch 0 train Loss 69.6142 test Loss 0.0000 with MSE metric 4344.7950\n",
      "Time taken for 1 epoch: 2.089653730392456 secs\n",
      "\n",
      "Epoch 483 batch 0 train Loss 69.4807 test Loss 0.0000 with MSE metric 4342.0048\n",
      "Time taken for 1 epoch: 2.155407667160034 secs\n",
      "\n",
      "Epoch 484 batch 0 train Loss 69.3482 test Loss 0.0000 with MSE metric 4342.5354\n",
      "Time taken for 1 epoch: 2.1157140731811523 secs\n",
      "\n",
      "Epoch 485 batch 0 train Loss 69.2161 test Loss 0.0000 with MSE metric 4341.9559\n",
      "Time taken for 1 epoch: 2.0858943462371826 secs\n",
      "\n",
      "Epoch 486 batch 0 train Loss 69.0847 test Loss 0.0000 with MSE metric 4341.5221\n",
      "Time taken for 1 epoch: 2.0670430660247803 secs\n",
      "\n",
      "Epoch 487 batch 0 train Loss 68.9534 test Loss 0.0000 with MSE metric 4339.4594\n",
      "Time taken for 1 epoch: 2.0810320377349854 secs\n",
      "\n",
      "Epoch 488 batch 0 train Loss 68.8233 test Loss 0.0000 with MSE metric 4342.1139\n",
      "Time taken for 1 epoch: 2.112888813018799 secs\n",
      "\n",
      "Epoch 489 batch 0 train Loss 68.6927 test Loss 0.0000 with MSE metric 4338.0616\n",
      "Time taken for 1 epoch: 2.103923797607422 secs\n",
      "\n",
      "Epoch 490 batch 0 train Loss 68.5630 test Loss 0.0000 with MSE metric 4335.3464\n",
      "Time taken for 1 epoch: 2.093967914581299 secs\n",
      "\n",
      "Epoch 491 batch 0 train Loss 68.4340 test Loss 0.0000 with MSE metric 4334.0185\n",
      "Time taken for 1 epoch: 2.0784780979156494 secs\n",
      "\n",
      "Epoch 492 batch 0 train Loss 68.3056 test Loss 0.0000 with MSE metric 4333.3263\n",
      "Time taken for 1 epoch: 2.063504934310913 secs\n",
      "\n",
      "Epoch 493 batch 0 train Loss 68.1777 test Loss 0.0000 with MSE metric 4333.1610\n",
      "Time taken for 1 epoch: 2.0837647914886475 secs\n",
      "\n",
      "Epoch 494 batch 0 train Loss 68.0508 test Loss 0.0000 with MSE metric 4335.6800\n",
      "Time taken for 1 epoch: 2.121190071105957 secs\n",
      "\n",
      "Epoch 495 batch 0 train Loss 67.9238 test Loss 0.0000 with MSE metric 4334.4592\n",
      "Time taken for 1 epoch: 2.098830223083496 secs\n",
      "\n",
      "Epoch 496 batch 0 train Loss 67.7974 test Loss 0.0000 with MSE metric 4333.8101\n",
      "Time taken for 1 epoch: 2.096323013305664 secs\n",
      "\n",
      "Epoch 497 batch 0 train Loss 67.6719 test Loss 0.0000 with MSE metric 4336.5580\n",
      "Time taken for 1 epoch: 2.1061131954193115 secs\n",
      "\n",
      "Epoch 498 batch 0 train Loss 67.5464 test Loss 0.0000 with MSE metric 4335.2664\n",
      "Time taken for 1 epoch: 2.068998098373413 secs\n",
      "\n",
      "Epoch 499 batch 0 train Loss 67.4211 test Loss 0.0000 with MSE metric 4332.5727\n",
      "Time taken for 1 epoch: 2.1131410598754883 secs\n",
      "\n",
      "Epoch 500 batch 0 train Loss 67.2970 test Loss 0.0000 with MSE metric 4334.0819\n",
      "Time taken for 1 epoch: 2.198603868484497 secs\n",
      "\n",
      "Epoch 501 batch 0 train Loss 67.1729 test Loss 0.0000 with MSE metric 4331.9631\n",
      "Time taken for 1 epoch: 2.4154040813446045 secs\n",
      "\n",
      "Epoch 502 batch 0 train Loss 67.0495 test Loss 0.0000 with MSE metric 4331.4164\n",
      "Time taken for 1 epoch: 2.2716081142425537 secs\n",
      "\n",
      "Epoch 503 batch 0 train Loss 66.9264 test Loss 0.0000 with MSE metric 4330.3859\n",
      "Time taken for 1 epoch: 2.1834769248962402 secs\n",
      "\n",
      "Epoch 504 batch 0 train Loss 66.8048 test Loss 0.0000 with MSE metric 4335.4861\n",
      "Time taken for 1 epoch: 2.089172124862671 secs\n",
      "\n",
      "Epoch 505 batch 0 train Loss 66.6830 test Loss 0.0000 with MSE metric 4336.3516\n",
      "Time taken for 1 epoch: 2.0874791145324707 secs\n",
      "\n",
      "Epoch 506 batch 0 train Loss 66.5614 test Loss 0.0000 with MSE metric 4334.1727\n",
      "Time taken for 1 epoch: 2.192451238632202 secs\n",
      "\n",
      "Epoch 507 batch 0 train Loss 66.4404 test Loss 0.0000 with MSE metric 4332.3564\n",
      "Time taken for 1 epoch: 2.1588380336761475 secs\n",
      "\n",
      "Epoch 508 batch 0 train Loss 66.3200 test Loss 0.0000 with MSE metric 4332.9062\n",
      "Time taken for 1 epoch: 2.109018087387085 secs\n",
      "\n",
      "Epoch 509 batch 0 train Loss 66.1996 test Loss 0.0000 with MSE metric 4330.7264\n",
      "Time taken for 1 epoch: 2.0951218605041504 secs\n",
      "\n",
      "Epoch 510 batch 0 train Loss 66.0796 test Loss 0.0000 with MSE metric 4328.0464\n",
      "Time taken for 1 epoch: 2.189811944961548 secs\n",
      "\n",
      "Epoch 511 batch 0 train Loss 65.9605 test Loss 0.0000 with MSE metric 4326.8197\n",
      "Time taken for 1 epoch: 2.118795871734619 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512 batch 0 train Loss 65.8410 test Loss 0.0000 with MSE metric 4322.4747\n",
      "Time taken for 1 epoch: 2.0990610122680664 secs\n",
      "\n",
      "Epoch 513 batch 0 train Loss 65.7239 test Loss 0.0000 with MSE metric 4324.0972\n",
      "Time taken for 1 epoch: 2.1070730686187744 secs\n",
      "\n",
      "Epoch 514 batch 0 train Loss 65.6060 test Loss 0.0000 with MSE metric 4323.0146\n",
      "Time taken for 1 epoch: 2.072208881378174 secs\n",
      "\n",
      "Epoch 515 batch 0 train Loss 65.4887 test Loss 0.0000 with MSE metric 4319.9809\n",
      "Time taken for 1 epoch: 2.083885908126831 secs\n",
      "\n",
      "Epoch 516 batch 0 train Loss 65.3727 test Loss 0.0000 with MSE metric 4320.8481\n",
      "Time taken for 1 epoch: 2.091214179992676 secs\n",
      "\n",
      "Epoch 517 batch 0 train Loss 65.2578 test Loss 0.0000 with MSE metric 4327.0547\n",
      "Time taken for 1 epoch: 2.0823071002960205 secs\n",
      "\n",
      "Epoch 518 batch 0 train Loss 65.1421 test Loss 0.0000 with MSE metric 4324.5169\n",
      "Time taken for 1 epoch: 2.0886600017547607 secs\n",
      "\n",
      "Epoch 519 batch 0 train Loss 65.0272 test Loss 0.0000 with MSE metric 4326.6644\n",
      "Time taken for 1 epoch: 2.0725820064544678 secs\n",
      "\n",
      "Epoch 520 batch 0 train Loss 64.9123 test Loss 0.0000 with MSE metric 4327.7122\n",
      "Time taken for 1 epoch: 2.0685770511627197 secs\n",
      "\n",
      "Epoch 521 batch 0 train Loss 64.7980 test Loss 0.0000 with MSE metric 4327.8911\n",
      "Time taken for 1 epoch: 2.168642044067383 secs\n",
      "\n",
      "Epoch 522 batch 0 train Loss 64.6842 test Loss 0.0000 with MSE metric 4327.6259\n",
      "Time taken for 1 epoch: 2.1658260822296143 secs\n",
      "\n",
      "Epoch 523 batch 0 train Loss 64.5699 test Loss 0.0000 with MSE metric 4323.8161\n",
      "Time taken for 1 epoch: 2.2537851333618164 secs\n",
      "\n",
      "Epoch 524 batch 0 train Loss 64.4571 test Loss 0.0000 with MSE metric 4326.9550\n",
      "Time taken for 1 epoch: 2.159069776535034 secs\n",
      "\n",
      "Epoch 525 batch 0 train Loss 64.3439 test Loss 0.0000 with MSE metric 4324.5097\n",
      "Time taken for 1 epoch: 2.1566617488861084 secs\n",
      "\n",
      "Epoch 526 batch 0 train Loss 64.2319 test Loss 0.0000 with MSE metric 4326.8408\n",
      "Time taken for 1 epoch: 2.292171001434326 secs\n",
      "\n",
      "Epoch 527 batch 0 train Loss 64.1199 test Loss 0.0000 with MSE metric 4325.3634\n",
      "Time taken for 1 epoch: 2.2161030769348145 secs\n",
      "\n",
      "Epoch 528 batch 0 train Loss 64.0083 test Loss 0.0000 with MSE metric 4324.6458\n",
      "Time taken for 1 epoch: 2.2297229766845703 secs\n",
      "\n",
      "Epoch 529 batch 0 train Loss 63.8971 test Loss 0.0000 with MSE metric 4323.8551\n",
      "Time taken for 1 epoch: 2.132244825363159 secs\n",
      "\n",
      "Epoch 530 batch 0 train Loss 63.7861 test Loss 0.0000 with MSE metric 4322.5320\n",
      "Time taken for 1 epoch: 2.1959691047668457 secs\n",
      "\n",
      "Epoch 531 batch 0 train Loss 63.6762 test Loss 0.0000 with MSE metric 4323.2708\n",
      "Time taken for 1 epoch: 2.4103620052337646 secs\n",
      "\n",
      "Epoch 532 batch 0 train Loss 63.5660 test Loss 0.0000 with MSE metric 4321.4193\n",
      "Time taken for 1 epoch: 2.2361278533935547 secs\n",
      "\n",
      "Epoch 533 batch 0 train Loss 63.4560 test Loss 0.0000 with MSE metric 4318.2687\n",
      "Time taken for 1 epoch: 2.2106969356536865 secs\n",
      "\n",
      "Epoch 534 batch 0 train Loss 63.3468 test Loss 0.0000 with MSE metric 4317.6851\n",
      "Time taken for 1 epoch: 2.1830248832702637 secs\n",
      "\n",
      "Epoch 535 batch 0 train Loss 63.2375 test Loss 0.0000 with MSE metric 4313.2729\n",
      "Time taken for 1 epoch: 2.1597561836242676 secs\n",
      "\n",
      "Epoch 536 batch 0 train Loss 63.1286 test Loss 0.0000 with MSE metric 4309.2952\n",
      "Time taken for 1 epoch: 2.1643450260162354 secs\n",
      "\n",
      "Epoch 537 batch 0 train Loss 63.0202 test Loss 0.0000 with MSE metric 4305.4630\n",
      "Time taken for 1 epoch: 2.1594951152801514 secs\n",
      "\n",
      "Epoch 538 batch 0 train Loss 62.9127 test Loss 0.0000 with MSE metric 4304.4883\n",
      "Time taken for 1 epoch: 2.1884469985961914 secs\n",
      "\n",
      "Epoch 539 batch 0 train Loss 62.8055 test Loss 0.0000 with MSE metric 4303.6828\n",
      "Time taken for 1 epoch: 2.1436710357666016 secs\n",
      "\n",
      "Epoch 540 batch 0 train Loss 62.6987 test Loss 0.0000 with MSE metric 4302.7489\n",
      "Time taken for 1 epoch: 2.1678929328918457 secs\n",
      "\n",
      "Epoch 541 batch 0 train Loss 62.5926 test Loss 0.0000 with MSE metric 4304.4187\n",
      "Time taken for 1 epoch: 2.148176908493042 secs\n",
      "\n",
      "Epoch 542 batch 0 train Loss 62.4865 test Loss 0.0000 with MSE metric 4302.9241\n",
      "Time taken for 1 epoch: 2.0857200622558594 secs\n",
      "\n",
      "Epoch 543 batch 0 train Loss 62.3811 test Loss 0.0000 with MSE metric 4302.6242\n",
      "Time taken for 1 epoch: 2.1549487113952637 secs\n",
      "\n",
      "Epoch 544 batch 0 train Loss 62.2763 test Loss 0.0000 with MSE metric 4305.6715\n",
      "Time taken for 1 epoch: 2.1710848808288574 secs\n",
      "\n",
      "Epoch 545 batch 0 train Loss 62.1714 test Loss 0.0000 with MSE metric 4304.8963\n",
      "Time taken for 1 epoch: 2.0833511352539062 secs\n",
      "\n",
      "Epoch 546 batch 0 train Loss 62.0667 test Loss 0.0000 with MSE metric 4302.7851\n",
      "Time taken for 1 epoch: 2.097425937652588 secs\n",
      "\n",
      "Epoch 547 batch 0 train Loss 61.9630 test Loss 0.0000 with MSE metric 4304.2350\n",
      "Time taken for 1 epoch: 2.134288787841797 secs\n",
      "\n",
      "Epoch 548 batch 0 train Loss 61.8589 test Loss 0.0000 with MSE metric 4301.1273\n",
      "Time taken for 1 epoch: 2.1528830528259277 secs\n",
      "\n",
      "Epoch 549 batch 0 train Loss 61.7557 test Loss 0.0000 with MSE metric 4302.0164\n",
      "Time taken for 1 epoch: 2.1265618801116943 secs\n",
      "\n",
      "Epoch 550 batch 0 train Loss 61.6529 test Loss 0.0000 with MSE metric 4302.2618\n",
      "Time taken for 1 epoch: 2.1331698894500732 secs\n",
      "\n",
      "Epoch 551 batch 0 train Loss 61.5502 test Loss 0.0000 with MSE metric 4300.5390\n",
      "Time taken for 1 epoch: 2.1368367671966553 secs\n",
      "\n",
      "Epoch 552 batch 0 train Loss 61.4481 test Loss 0.0000 with MSE metric 4301.3375\n",
      "Time taken for 1 epoch: 2.1592981815338135 secs\n",
      "\n",
      "Epoch 553 batch 0 train Loss 61.3462 test Loss 0.0000 with MSE metric 4300.0077\n",
      "Time taken for 1 epoch: 2.2383248805999756 secs\n",
      "\n",
      "Epoch 554 batch 0 train Loss 61.2447 test Loss 0.0000 with MSE metric 4299.2881\n",
      "Time taken for 1 epoch: 2.1465229988098145 secs\n",
      "\n",
      "Epoch 555 batch 0 train Loss 61.1436 test Loss 0.0000 with MSE metric 4298.5622\n",
      "Time taken for 1 epoch: 2.175448179244995 secs\n",
      "\n",
      "Epoch 556 batch 0 train Loss 61.0425 test Loss 0.0000 with MSE metric 4296.2820\n",
      "Time taken for 1 epoch: 2.2426817417144775 secs\n",
      "\n",
      "Epoch 557 batch 0 train Loss 60.9421 test Loss 0.0000 with MSE metric 4295.2729\n",
      "Time taken for 1 epoch: 2.2329280376434326 secs\n",
      "\n",
      "Epoch 558 batch 0 train Loss 60.8423 test Loss 0.0000 with MSE metric 4296.2561\n",
      "Time taken for 1 epoch: 2.1787819862365723 secs\n",
      "\n",
      "Epoch 559 batch 0 train Loss 60.7430 test Loss 0.0000 with MSE metric 4298.8344\n",
      "Time taken for 1 epoch: 2.151796817779541 secs\n",
      "\n",
      "Epoch 560 batch 0 train Loss 60.6434 test Loss 0.0000 with MSE metric 4295.8212\n",
      "Time taken for 1 epoch: 2.204406976699829 secs\n",
      "\n",
      "Epoch 561 batch 0 train Loss 60.5446 test Loss 0.0000 with MSE metric 4295.6400\n",
      "Time taken for 1 epoch: 2.1637399196624756 secs\n",
      "\n",
      "Epoch 562 batch 0 train Loss 60.4458 test Loss 0.0000 with MSE metric 4293.3157\n",
      "Time taken for 1 epoch: 2.138408899307251 secs\n",
      "\n",
      "Epoch 563 batch 0 train Loss 60.3478 test Loss 0.0000 with MSE metric 4295.2190\n",
      "Time taken for 1 epoch: 2.154430866241455 secs\n",
      "\n",
      "Epoch 564 batch 0 train Loss 60.2496 test Loss 0.0000 with MSE metric 4293.3843\n",
      "Time taken for 1 epoch: 2.1550750732421875 secs\n",
      "\n",
      "Epoch 565 batch 0 train Loss 60.1514 test Loss 0.0000 with MSE metric 4290.5801\n",
      "Time taken for 1 epoch: 2.1289353370666504 secs\n",
      "\n",
      "Epoch 566 batch 0 train Loss 60.0541 test Loss 0.0000 with MSE metric 4288.5103\n",
      "Time taken for 1 epoch: 2.1731069087982178 secs\n",
      "\n",
      "Epoch 567 batch 0 train Loss 59.9571 test Loss 0.0000 with MSE metric 4286.7799\n",
      "Time taken for 1 epoch: 2.1331708431243896 secs\n",
      "\n",
      "Epoch 568 batch 0 train Loss 59.8607 test Loss 0.0000 with MSE metric 4286.3078\n",
      "Time taken for 1 epoch: 2.5973470211029053 secs\n",
      "\n",
      "Epoch 569 batch 0 train Loss 59.7642 test Loss 0.0000 with MSE metric 4283.7050\n",
      "Time taken for 1 epoch: 2.3745458126068115 secs\n",
      "\n",
      "Epoch 570 batch 0 train Loss 59.6685 test Loss 0.0000 with MSE metric 4283.2230\n",
      "Time taken for 1 epoch: 2.282912015914917 secs\n",
      "\n",
      "Epoch 571 batch 0 train Loss 59.5726 test Loss 0.0000 with MSE metric 4279.5161\n",
      "Time taken for 1 epoch: 2.2468008995056152 secs\n",
      "\n",
      "Epoch 572 batch 0 train Loss 59.4776 test Loss 0.0000 with MSE metric 4279.7658\n",
      "Time taken for 1 epoch: 2.177577257156372 secs\n",
      "\n",
      "Epoch 573 batch 0 train Loss 59.3828 test Loss 0.0000 with MSE metric 4279.5248\n",
      "Time taken for 1 epoch: 2.174414873123169 secs\n",
      "\n",
      "Epoch 574 batch 0 train Loss 59.2880 test Loss 0.0000 with MSE metric 4277.7710\n",
      "Time taken for 1 epoch: 2.1260550022125244 secs\n",
      "\n",
      "Epoch 575 batch 0 train Loss 59.1935 test Loss 0.0000 with MSE metric 4275.4423\n",
      "Time taken for 1 epoch: 2.1146481037139893 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576 batch 0 train Loss 59.0995 test Loss 0.0000 with MSE metric 4273.6963\n",
      "Time taken for 1 epoch: 2.1393589973449707 secs\n",
      "\n",
      "Epoch 577 batch 0 train Loss 59.0059 test Loss 0.0000 with MSE metric 4272.6245\n",
      "Time taken for 1 epoch: 2.1505792140960693 secs\n",
      "\n",
      "Epoch 578 batch 0 train Loss 58.9130 test Loss 0.0000 with MSE metric 4273.8697\n",
      "Time taken for 1 epoch: 2.1019508838653564 secs\n",
      "\n",
      "Epoch 579 batch 0 train Loss 58.8202 test Loss 0.0000 with MSE metric 4274.7011\n",
      "Time taken for 1 epoch: 2.1025660037994385 secs\n",
      "\n",
      "Epoch 580 batch 0 train Loss 58.7280 test Loss 0.0000 with MSE metric 4275.7119\n",
      "Time taken for 1 epoch: 2.093026638031006 secs\n",
      "\n",
      "Epoch 581 batch 0 train Loss 58.6357 test Loss 0.0000 with MSE metric 4274.0007\n",
      "Time taken for 1 epoch: 2.2002313137054443 secs\n",
      "\n",
      "Epoch 582 batch 0 train Loss 58.5437 test Loss 0.0000 with MSE metric 4272.5940\n",
      "Time taken for 1 epoch: 2.1981348991394043 secs\n",
      "\n",
      "Epoch 583 batch 0 train Loss 58.4517 test Loss 0.0000 with MSE metric 4269.4436\n",
      "Time taken for 1 epoch: 2.216625928878784 secs\n",
      "\n",
      "Epoch 584 batch 0 train Loss 58.3601 test Loss 0.0000 with MSE metric 4267.5348\n",
      "Time taken for 1 epoch: 2.198272943496704 secs\n",
      "\n",
      "Epoch 585 batch 0 train Loss 58.2687 test Loss 0.0000 with MSE metric 4264.7309\n",
      "Time taken for 1 epoch: 2.170545816421509 secs\n",
      "\n",
      "Epoch 586 batch 0 train Loss 58.1799 test Loss 0.0000 with MSE metric 4267.7389\n",
      "Time taken for 1 epoch: 2.3071351051330566 secs\n",
      "\n",
      "Epoch 587 batch 0 train Loss 58.0894 test Loss 0.0000 with MSE metric 4264.9564\n",
      "Time taken for 1 epoch: 2.6164450645446777 secs\n",
      "\n",
      "Epoch 588 batch 0 train Loss 58.0002 test Loss 0.0000 with MSE metric 4263.4343\n",
      "Time taken for 1 epoch: 2.239811897277832 secs\n",
      "\n",
      "Epoch 589 batch 0 train Loss 57.9113 test Loss 0.0000 with MSE metric 4260.6944\n",
      "Time taken for 1 epoch: 2.2404489517211914 secs\n",
      "\n",
      "Epoch 590 batch 0 train Loss 57.8238 test Loss 0.0000 with MSE metric 4261.0745\n",
      "Time taken for 1 epoch: 2.256465196609497 secs\n",
      "\n",
      "Epoch 591 batch 0 train Loss 57.7361 test Loss 0.0000 with MSE metric 4258.8635\n",
      "Time taken for 1 epoch: 2.255324125289917 secs\n",
      "\n",
      "Epoch 592 batch 0 train Loss 57.6493 test Loss 0.0000 with MSE metric 4258.7226\n",
      "Time taken for 1 epoch: 2.3018808364868164 secs\n",
      "\n",
      "Epoch 593 batch 0 train Loss 57.5627 test Loss 0.0000 with MSE metric 4259.6681\n",
      "Time taken for 1 epoch: 2.3419930934906006 secs\n",
      "\n",
      "Epoch 594 batch 0 train Loss 57.4747 test Loss 0.0000 with MSE metric 4256.2380\n",
      "Time taken for 1 epoch: 2.265651226043701 secs\n",
      "\n",
      "Epoch 595 batch 0 train Loss 57.3871 test Loss 0.0000 with MSE metric 4256.1480\n",
      "Time taken for 1 epoch: 2.4010119438171387 secs\n",
      "\n",
      "Epoch 596 batch 0 train Loss 57.2995 test Loss 0.0000 with MSE metric 4255.1795\n",
      "Time taken for 1 epoch: 2.294708013534546 secs\n",
      "\n",
      "Epoch 597 batch 0 train Loss 57.2126 test Loss 0.0000 with MSE metric 4253.0726\n",
      "Time taken for 1 epoch: 2.1759631633758545 secs\n",
      "\n",
      "Epoch 598 batch 0 train Loss 57.1269 test Loss 0.0000 with MSE metric 4252.5948\n",
      "Time taken for 1 epoch: 2.212898015975952 secs\n",
      "\n",
      "Epoch 599 batch 0 train Loss 57.0404 test Loss 0.0000 with MSE metric 4253.2218\n",
      "Time taken for 1 epoch: 2.155951738357544 secs\n",
      "\n",
      "Epoch 600 batch 0 train Loss 56.9545 test Loss 0.0000 with MSE metric 4253.6532\n",
      "Time taken for 1 epoch: 2.222465991973877 secs\n",
      "\n",
      "Epoch 601 batch 0 train Loss 56.8694 test Loss 0.0000 with MSE metric 4253.4792\n",
      "Time taken for 1 epoch: 2.1320700645446777 secs\n",
      "\n",
      "Epoch 602 batch 0 train Loss 56.7843 test Loss 0.0000 with MSE metric 4251.4904\n",
      "Time taken for 1 epoch: 2.1518139839172363 secs\n",
      "\n",
      "Epoch 603 batch 0 train Loss 56.6997 test Loss 0.0000 with MSE metric 4249.8544\n",
      "Time taken for 1 epoch: 2.1608681678771973 secs\n",
      "\n",
      "Epoch 604 batch 0 train Loss 56.6155 test Loss 0.0000 with MSE metric 4250.5755\n",
      "Time taken for 1 epoch: 2.1574180126190186 secs\n",
      "\n",
      "Epoch 605 batch 0 train Loss 56.5309 test Loss 0.0000 with MSE metric 4249.1797\n",
      "Time taken for 1 epoch: 2.1843698024749756 secs\n",
      "\n",
      "Epoch 606 batch 0 train Loss 56.4462 test Loss 0.0000 with MSE metric 4248.8164\n",
      "Time taken for 1 epoch: 2.228203058242798 secs\n",
      "\n",
      "Epoch 607 batch 0 train Loss 56.3614 test Loss 0.0000 with MSE metric 4246.4130\n",
      "Time taken for 1 epoch: 2.210114002227783 secs\n",
      "\n",
      "Epoch 608 batch 0 train Loss 56.2772 test Loss 0.0000 with MSE metric 4243.7713\n",
      "Time taken for 1 epoch: 2.1677069664001465 secs\n",
      "\n",
      "Epoch 609 batch 0 train Loss 56.1944 test Loss 0.0000 with MSE metric 4242.5169\n",
      "Time taken for 1 epoch: 2.2259740829467773 secs\n",
      "\n",
      "Epoch 610 batch 0 train Loss 56.1107 test Loss 0.0000 with MSE metric 4242.1018\n",
      "Time taken for 1 epoch: 2.134605884552002 secs\n",
      "\n",
      "Epoch 611 batch 0 train Loss 56.0275 test Loss 0.0000 with MSE metric 4240.6795\n",
      "Time taken for 1 epoch: 2.1824779510498047 secs\n",
      "\n",
      "Epoch 612 batch 0 train Loss 55.9449 test Loss 0.0000 with MSE metric 4238.3852\n",
      "Time taken for 1 epoch: 2.188610076904297 secs\n",
      "\n",
      "Epoch 613 batch 0 train Loss 55.8632 test Loss 0.0000 with MSE metric 4238.4078\n",
      "Time taken for 1 epoch: 2.0835180282592773 secs\n",
      "\n",
      "Epoch 614 batch 0 train Loss 55.7822 test Loss 0.0000 with MSE metric 4237.6934\n",
      "Time taken for 1 epoch: 2.081608772277832 secs\n",
      "\n",
      "Epoch 615 batch 0 train Loss 55.7009 test Loss 0.0000 with MSE metric 4236.0767\n",
      "Time taken for 1 epoch: 2.1029460430145264 secs\n",
      "\n",
      "Epoch 616 batch 0 train Loss 55.6195 test Loss 0.0000 with MSE metric 4234.3073\n",
      "Time taken for 1 epoch: 2.0753979682922363 secs\n",
      "\n",
      "Epoch 617 batch 0 train Loss 55.5376 test Loss 0.0000 with MSE metric 4230.8787\n",
      "Time taken for 1 epoch: 2.0961849689483643 secs\n",
      "\n",
      "Epoch 618 batch 0 train Loss 55.4561 test Loss 0.0000 with MSE metric 4229.6012\n",
      "Time taken for 1 epoch: 2.0856378078460693 secs\n",
      "\n",
      "Epoch 619 batch 0 train Loss 55.3752 test Loss 0.0000 with MSE metric 4230.7028\n",
      "Time taken for 1 epoch: 2.093449115753174 secs\n",
      "\n",
      "Epoch 620 batch 0 train Loss 55.2946 test Loss 0.0000 with MSE metric 4229.7622\n",
      "Time taken for 1 epoch: 2.071302890777588 secs\n",
      "\n",
      "Epoch 621 batch 0 train Loss 55.2142 test Loss 0.0000 with MSE metric 4229.2521\n",
      "Time taken for 1 epoch: 2.0932371616363525 secs\n",
      "\n",
      "Epoch 622 batch 0 train Loss 55.1335 test Loss 0.0000 with MSE metric 4227.1364\n",
      "Time taken for 1 epoch: 2.0592668056488037 secs\n",
      "\n",
      "Epoch 623 batch 0 train Loss 55.0527 test Loss 0.0000 with MSE metric 4223.6306\n",
      "Time taken for 1 epoch: 2.095266103744507 secs\n",
      "\n",
      "Epoch 624 batch 0 train Loss 54.9729 test Loss 0.0000 with MSE metric 4222.6135\n",
      "Time taken for 1 epoch: 2.0872111320495605 secs\n",
      "\n",
      "Epoch 625 batch 0 train Loss 54.8931 test Loss 0.0000 with MSE metric 4220.2290\n",
      "Time taken for 1 epoch: 2.0497701168060303 secs\n",
      "\n",
      "Epoch 626 batch 0 train Loss 54.8139 test Loss 0.0000 with MSE metric 4220.0227\n",
      "Time taken for 1 epoch: 2.119810104370117 secs\n",
      "\n",
      "Epoch 627 batch 0 train Loss 54.7349 test Loss 0.0000 with MSE metric 4220.1265\n",
      "Time taken for 1 epoch: 2.057478189468384 secs\n",
      "\n",
      "Epoch 628 batch 0 train Loss 54.6562 test Loss 0.0000 with MSE metric 4221.7101\n",
      "Time taken for 1 epoch: 2.094956874847412 secs\n",
      "\n",
      "Epoch 629 batch 0 train Loss 54.5779 test Loss 0.0000 with MSE metric 4224.2601\n",
      "Time taken for 1 epoch: 2.0634331703186035 secs\n",
      "\n",
      "Epoch 630 batch 0 train Loss 54.4997 test Loss 0.0000 with MSE metric 4224.2878\n",
      "Time taken for 1 epoch: 2.070913076400757 secs\n",
      "\n",
      "Epoch 631 batch 0 train Loss 54.4216 test Loss 0.0000 with MSE metric 4224.6933\n",
      "Time taken for 1 epoch: 2.0582730770111084 secs\n",
      "\n",
      "Epoch 632 batch 0 train Loss 54.3434 test Loss 0.0000 with MSE metric 4223.1393\n",
      "Time taken for 1 epoch: 2.054415702819824 secs\n",
      "\n",
      "Epoch 633 batch 0 train Loss 54.2653 test Loss 0.0000 with MSE metric 4220.6640\n",
      "Time taken for 1 epoch: 2.066632032394409 secs\n",
      "\n",
      "Epoch 634 batch 0 train Loss 54.1878 test Loss 0.0000 with MSE metric 4220.1596\n",
      "Time taken for 1 epoch: 2.085405111312866 secs\n",
      "\n",
      "Epoch 635 batch 0 train Loss 54.1107 test Loss 0.0000 with MSE metric 4221.0586\n",
      "Time taken for 1 epoch: 2.1118569374084473 secs\n",
      "\n",
      "Epoch 636 batch 0 train Loss 54.0333 test Loss 0.0000 with MSE metric 4218.4866\n",
      "Time taken for 1 epoch: 2.0986759662628174 secs\n",
      "\n",
      "Epoch 637 batch 0 train Loss 53.9567 test Loss 0.0000 with MSE metric 4219.9836\n",
      "Time taken for 1 epoch: 2.0716419219970703 secs\n",
      "\n",
      "Epoch 638 batch 0 train Loss 53.8804 test Loss 0.0000 with MSE metric 4222.2027\n",
      "Time taken for 1 epoch: 2.090816020965576 secs\n",
      "\n",
      "Epoch 639 batch 0 train Loss 53.8038 test Loss 0.0000 with MSE metric 4219.3271\n",
      "Time taken for 1 epoch: 2.0921618938446045 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640 batch 0 train Loss 53.7272 test Loss 0.0000 with MSE metric 4215.7425\n",
      "Time taken for 1 epoch: 2.089808702468872 secs\n",
      "\n",
      "Epoch 641 batch 0 train Loss 53.6512 test Loss 0.0000 with MSE metric 4215.0159\n",
      "Time taken for 1 epoch: 2.079240083694458 secs\n",
      "\n",
      "Epoch 642 batch 0 train Loss 53.5755 test Loss 0.0000 with MSE metric 4214.1241\n",
      "Time taken for 1 epoch: 2.087961196899414 secs\n",
      "\n",
      "Epoch 643 batch 0 train Loss 53.4999 test Loss 0.0000 with MSE metric 4212.1755\n",
      "Time taken for 1 epoch: 2.0876362323760986 secs\n",
      "\n",
      "Epoch 644 batch 0 train Loss 53.4252 test Loss 0.0000 with MSE metric 4213.7628\n",
      "Time taken for 1 epoch: 2.0877230167388916 secs\n",
      "\n",
      "Epoch 645 batch 0 train Loss 53.3503 test Loss 0.0000 with MSE metric 4212.7380\n",
      "Time taken for 1 epoch: 2.0604920387268066 secs\n",
      "\n",
      "Epoch 646 batch 0 train Loss 53.2756 test Loss 0.0000 with MSE metric 4211.3296\n",
      "Time taken for 1 epoch: 2.086854934692383 secs\n",
      "\n",
      "Epoch 647 batch 0 train Loss 53.2012 test Loss 0.0000 with MSE metric 4209.3081\n",
      "Time taken for 1 epoch: 2.0694310665130615 secs\n",
      "\n",
      "Epoch 648 batch 0 train Loss 53.1269 test Loss 0.0000 with MSE metric 4207.2438\n",
      "Time taken for 1 epoch: 2.077181100845337 secs\n",
      "\n",
      "Epoch 649 batch 0 train Loss 53.0529 test Loss 0.0000 with MSE metric 4207.3270\n",
      "Time taken for 1 epoch: 2.0595579147338867 secs\n",
      "\n",
      "Epoch 650 batch 0 train Loss 52.9793 test Loss 0.0000 with MSE metric 4208.0990\n",
      "Time taken for 1 epoch: 2.0792479515075684 secs\n",
      "\n",
      "Epoch 651 batch 0 train Loss 52.9056 test Loss 0.0000 with MSE metric 4206.3420\n",
      "Time taken for 1 epoch: 2.116131067276001 secs\n",
      "\n",
      "Epoch 652 batch 0 train Loss 52.8325 test Loss 0.0000 with MSE metric 4206.6451\n",
      "Time taken for 1 epoch: 2.076263189315796 secs\n",
      "\n",
      "Epoch 653 batch 0 train Loss 52.7593 test Loss 0.0000 with MSE metric 4205.8184\n",
      "Time taken for 1 epoch: 2.07129168510437 secs\n",
      "\n",
      "Epoch 654 batch 0 train Loss 52.6863 test Loss 0.0000 with MSE metric 4203.9064\n",
      "Time taken for 1 epoch: 2.0762228965759277 secs\n",
      "\n",
      "Epoch 655 batch 0 train Loss 52.6139 test Loss 0.0000 with MSE metric 4205.9010\n",
      "Time taken for 1 epoch: 2.0939571857452393 secs\n",
      "\n",
      "Epoch 656 batch 0 train Loss 52.5413 test Loss 0.0000 with MSE metric 4203.7101\n",
      "Time taken for 1 epoch: 2.077165126800537 secs\n",
      "\n",
      "Epoch 657 batch 0 train Loss 52.4689 test Loss 0.0000 with MSE metric 4201.4279\n",
      "Time taken for 1 epoch: 2.1221182346343994 secs\n",
      "\n",
      "Epoch 658 batch 0 train Loss 52.3967 test Loss 0.0000 with MSE metric 4200.0199\n",
      "Time taken for 1 epoch: 2.298779010772705 secs\n",
      "\n",
      "Epoch 659 batch 0 train Loss 52.3250 test Loss 0.0000 with MSE metric 4199.5957\n",
      "Time taken for 1 epoch: 2.3103830814361572 secs\n",
      "\n",
      "Epoch 660 batch 0 train Loss 52.2532 test Loss 0.0000 with MSE metric 4198.0657\n",
      "Time taken for 1 epoch: 2.2572999000549316 secs\n",
      "\n",
      "Epoch 661 batch 0 train Loss 52.1816 test Loss 0.0000 with MSE metric 4196.4022\n",
      "Time taken for 1 epoch: 2.260582208633423 secs\n",
      "\n",
      "Epoch 662 batch 0 train Loss 52.1100 test Loss 0.0000 with MSE metric 4193.5032\n",
      "Time taken for 1 epoch: 2.1359059810638428 secs\n",
      "\n",
      "Epoch 663 batch 0 train Loss 52.0390 test Loss 0.0000 with MSE metric 4192.5615\n",
      "Time taken for 1 epoch: 2.082382917404175 secs\n",
      "\n",
      "Epoch 664 batch 0 train Loss 51.9683 test Loss 0.0000 with MSE metric 4192.5377\n",
      "Time taken for 1 epoch: 2.1013450622558594 secs\n",
      "\n",
      "Epoch 665 batch 0 train Loss 51.8979 test Loss 0.0000 with MSE metric 4192.5945\n",
      "Time taken for 1 epoch: 2.0897419452667236 secs\n",
      "\n",
      "Epoch 666 batch 0 train Loss 51.8275 test Loss 0.0000 with MSE metric 4191.5106\n",
      "Time taken for 1 epoch: 2.0922958850860596 secs\n",
      "\n",
      "Epoch 667 batch 0 train Loss 51.7573 test Loss 0.0000 with MSE metric 4190.4418\n",
      "Time taken for 1 epoch: 2.104351043701172 secs\n",
      "\n",
      "Epoch 668 batch 0 train Loss 51.6871 test Loss 0.0000 with MSE metric 4188.1987\n",
      "Time taken for 1 epoch: 2.0956709384918213 secs\n",
      "\n",
      "Epoch 669 batch 0 train Loss 51.6175 test Loss 0.0000 with MSE metric 4188.1073\n",
      "Time taken for 1 epoch: 2.067528009414673 secs\n",
      "\n",
      "Epoch 670 batch 0 train Loss 51.5482 test Loss 0.0000 with MSE metric 4189.0384\n",
      "Time taken for 1 epoch: 2.0865070819854736 secs\n",
      "\n",
      "Epoch 671 batch 0 train Loss 51.4789 test Loss 0.0000 with MSE metric 4188.3277\n",
      "Time taken for 1 epoch: 2.068416118621826 secs\n",
      "\n",
      "Epoch 672 batch 0 train Loss 51.4098 test Loss 0.0000 with MSE metric 4187.1747\n",
      "Time taken for 1 epoch: 2.092482805252075 secs\n",
      "\n",
      "Epoch 673 batch 0 train Loss 51.3410 test Loss 0.0000 with MSE metric 4186.8246\n",
      "Time taken for 1 epoch: 2.1025710105895996 secs\n",
      "\n",
      "Epoch 674 batch 0 train Loss 51.2723 test Loss 0.0000 with MSE metric 4185.7293\n",
      "Time taken for 1 epoch: 2.1266708374023438 secs\n",
      "\n",
      "Epoch 675 batch 0 train Loss 51.2036 test Loss 0.0000 with MSE metric 4183.6752\n",
      "Time taken for 1 epoch: 2.0887889862060547 secs\n",
      "\n",
      "Epoch 676 batch 0 train Loss 51.1351 test Loss 0.0000 with MSE metric 4181.6750\n",
      "Time taken for 1 epoch: 2.0752391815185547 secs\n",
      "\n",
      "Epoch 677 batch 0 train Loss 51.0666 test Loss 0.0000 with MSE metric 4178.3552\n",
      "Time taken for 1 epoch: 2.0831499099731445 secs\n",
      "\n",
      "Epoch 678 batch 0 train Loss 50.9992 test Loss 0.0000 with MSE metric 4178.3113\n",
      "Time taken for 1 epoch: 2.097012996673584 secs\n",
      "\n",
      "Epoch 679 batch 0 train Loss 50.9315 test Loss 0.0000 with MSE metric 4177.4511\n",
      "Time taken for 1 epoch: 2.09755802154541 secs\n",
      "\n",
      "Epoch 680 batch 0 train Loss 50.8641 test Loss 0.0000 with MSE metric 4175.7852\n",
      "Time taken for 1 epoch: 2.09470534324646 secs\n",
      "\n",
      "Epoch 681 batch 0 train Loss 50.7969 test Loss 0.0000 with MSE metric 4173.7509\n",
      "Time taken for 1 epoch: 2.0992541313171387 secs\n",
      "\n",
      "Epoch 682 batch 0 train Loss 50.7300 test Loss 0.0000 with MSE metric 4171.4213\n",
      "Time taken for 1 epoch: 2.0915639400482178 secs\n",
      "\n",
      "Epoch 683 batch 0 train Loss 50.6633 test Loss 0.0000 with MSE metric 4170.5107\n",
      "Time taken for 1 epoch: 2.1115660667419434 secs\n",
      "\n",
      "Epoch 684 batch 0 train Loss 50.5964 test Loss 0.0000 with MSE metric 4168.9000\n",
      "Time taken for 1 epoch: 2.1483678817749023 secs\n",
      "\n",
      "Epoch 685 batch 0 train Loss 50.5300 test Loss 0.0000 with MSE metric 4168.3786\n",
      "Time taken for 1 epoch: 2.354652166366577 secs\n",
      "\n",
      "Epoch 686 batch 0 train Loss 50.4639 test Loss 0.0000 with MSE metric 4167.3780\n",
      "Time taken for 1 epoch: 2.5449159145355225 secs\n",
      "\n",
      "Epoch 687 batch 0 train Loss 50.3991 test Loss 0.0000 with MSE metric 4173.1840\n",
      "Time taken for 1 epoch: 2.3877828121185303 secs\n",
      "\n",
      "Epoch 688 batch 0 train Loss 50.3337 test Loss 0.0000 with MSE metric 4173.3526\n",
      "Time taken for 1 epoch: 2.2351691722869873 secs\n",
      "\n",
      "Epoch 689 batch 0 train Loss 50.2691 test Loss 0.0000 with MSE metric 4172.1479\n",
      "Time taken for 1 epoch: 2.1653976440429688 secs\n",
      "\n",
      "Epoch 690 batch 0 train Loss 50.2053 test Loss 0.0000 with MSE metric 4171.1377\n",
      "Time taken for 1 epoch: 2.1254189014434814 secs\n",
      "\n",
      "Epoch 691 batch 0 train Loss 50.1429 test Loss 0.0000 with MSE metric 4171.7753\n",
      "Time taken for 1 epoch: 2.3247480392456055 secs\n",
      "\n",
      "Epoch 692 batch 0 train Loss 50.0793 test Loss 0.0000 with MSE metric 4170.0679\n",
      "Time taken for 1 epoch: 2.156554937362671 secs\n",
      "\n",
      "Epoch 693 batch 0 train Loss 50.0163 test Loss 0.0000 with MSE metric 4170.0070\n",
      "Time taken for 1 epoch: 2.126473903656006 secs\n",
      "\n",
      "Epoch 694 batch 0 train Loss 49.9524 test Loss 0.0000 with MSE metric 4168.3686\n",
      "Time taken for 1 epoch: 2.183807849884033 secs\n",
      "\n",
      "Epoch 695 batch 0 train Loss 49.8884 test Loss 0.0000 with MSE metric 4168.9180\n",
      "Time taken for 1 epoch: 2.1900370121002197 secs\n",
      "\n",
      "Epoch 696 batch 0 train Loss 49.8239 test Loss 0.0000 with MSE metric 4167.4415\n",
      "Time taken for 1 epoch: 2.2320659160614014 secs\n",
      "\n",
      "Epoch 697 batch 0 train Loss 49.7607 test Loss 0.0000 with MSE metric 4165.3752\n",
      "Time taken for 1 epoch: 2.210516929626465 secs\n",
      "\n",
      "Epoch 698 batch 0 train Loss 49.6966 test Loss 0.0000 with MSE metric 4163.1274\n",
      "Time taken for 1 epoch: 2.1652450561523438 secs\n",
      "\n",
      "Epoch 699 batch 0 train Loss 49.6326 test Loss 0.0000 with MSE metric 4162.1434\n",
      "Time taken for 1 epoch: 2.158109188079834 secs\n",
      "\n",
      "Epoch 700 batch 0 train Loss 49.5693 test Loss 0.0000 with MSE metric 4162.5121\n",
      "Time taken for 1 epoch: 2.2101361751556396 secs\n",
      "\n",
      "Epoch 701 batch 0 train Loss 49.5064 test Loss 0.0000 with MSE metric 4162.5543\n",
      "Time taken for 1 epoch: 2.142591953277588 secs\n",
      "\n",
      "Epoch 702 batch 0 train Loss 49.4436 test Loss 0.0000 with MSE metric 4161.8194\n",
      "Time taken for 1 epoch: 2.1970250606536865 secs\n",
      "\n",
      "Epoch 703 batch 0 train Loss 49.3807 test Loss 0.0000 with MSE metric 4160.5958\n",
      "Time taken for 1 epoch: 2.1135480403900146 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704 batch 0 train Loss 49.3179 test Loss 0.0000 with MSE metric 4159.9947\n",
      "Time taken for 1 epoch: 2.1718289852142334 secs\n",
      "\n",
      "Epoch 705 batch 0 train Loss 49.2552 test Loss 0.0000 with MSE metric 4160.1883\n",
      "Time taken for 1 epoch: 2.1464309692382812 secs\n",
      "\n",
      "Epoch 706 batch 0 train Loss 49.1926 test Loss 0.0000 with MSE metric 4158.9464\n",
      "Time taken for 1 epoch: 2.08197021484375 secs\n",
      "\n",
      "Epoch 707 batch 0 train Loss 49.1304 test Loss 0.0000 with MSE metric 4158.3161\n",
      "Time taken for 1 epoch: 2.098510980606079 secs\n",
      "\n",
      "Epoch 708 batch 0 train Loss 49.0684 test Loss 0.0000 with MSE metric 4158.7097\n",
      "Time taken for 1 epoch: 2.077913284301758 secs\n",
      "\n",
      "Epoch 709 batch 0 train Loss 49.0064 test Loss 0.0000 with MSE metric 4158.0071\n",
      "Time taken for 1 epoch: 2.303518056869507 secs\n",
      "\n",
      "Epoch 710 batch 0 train Loss 48.9445 test Loss 0.0000 with MSE metric 4155.4872\n",
      "Time taken for 1 epoch: 2.1376078128814697 secs\n",
      "\n",
      "Epoch 711 batch 0 train Loss 48.8830 test Loss 0.0000 with MSE metric 4154.5512\n",
      "Time taken for 1 epoch: 2.1099891662597656 secs\n",
      "\n",
      "Epoch 712 batch 0 train Loss 48.8216 test Loss 0.0000 with MSE metric 4152.0907\n",
      "Time taken for 1 epoch: 2.0977418422698975 secs\n",
      "\n",
      "Epoch 713 batch 0 train Loss 48.7603 test Loss 0.0000 with MSE metric 4151.1128\n",
      "Time taken for 1 epoch: 2.118340253829956 secs\n",
      "\n",
      "Epoch 714 batch 0 train Loss 48.6988 test Loss 0.0000 with MSE metric 4148.2707\n",
      "Time taken for 1 epoch: 2.205451011657715 secs\n",
      "\n",
      "Epoch 715 batch 0 train Loss 48.6376 test Loss 0.0000 with MSE metric 4146.3001\n",
      "Time taken for 1 epoch: 2.1406562328338623 secs\n",
      "\n",
      "Epoch 716 batch 0 train Loss 48.5774 test Loss 0.0000 with MSE metric 4147.0750\n",
      "Time taken for 1 epoch: 2.326946973800659 secs\n",
      "\n",
      "Epoch 717 batch 0 train Loss 48.5170 test Loss 0.0000 with MSE metric 4147.5656\n",
      "Time taken for 1 epoch: 2.179208993911743 secs\n",
      "\n",
      "Epoch 718 batch 0 train Loss 48.4564 test Loss 0.0000 with MSE metric 4145.5962\n",
      "Time taken for 1 epoch: 2.231208086013794 secs\n",
      "\n",
      "Epoch 719 batch 0 train Loss 48.3962 test Loss 0.0000 with MSE metric 4145.0713\n",
      "Time taken for 1 epoch: 2.2439279556274414 secs\n",
      "\n",
      "Epoch 720 batch 0 train Loss 48.3361 test Loss 0.0000 with MSE metric 4143.1483\n",
      "Time taken for 1 epoch: 2.5353550910949707 secs\n",
      "\n",
      "Epoch 721 batch 0 train Loss 48.2762 test Loss 0.0000 with MSE metric 4141.5903\n",
      "Time taken for 1 epoch: 2.2969918251037598 secs\n",
      "\n",
      "Epoch 722 batch 0 train Loss 48.2166 test Loss 0.0000 with MSE metric 4140.9597\n",
      "Time taken for 1 epoch: 2.2033803462982178 secs\n",
      "\n",
      "Epoch 723 batch 0 train Loss 48.1572 test Loss 0.0000 with MSE metric 4141.5599\n",
      "Time taken for 1 epoch: 2.2026870250701904 secs\n",
      "\n",
      "Epoch 724 batch 0 train Loss 48.0974 test Loss 0.0000 with MSE metric 4139.8312\n",
      "Time taken for 1 epoch: 2.1921961307525635 secs\n",
      "\n",
      "Epoch 725 batch 0 train Loss 48.0379 test Loss 0.0000 with MSE metric 4137.7629\n",
      "Time taken for 1 epoch: 2.1572582721710205 secs\n",
      "\n",
      "Epoch 726 batch 0 train Loss 47.9786 test Loss 0.0000 with MSE metric 4136.0142\n",
      "Time taken for 1 epoch: 2.134218692779541 secs\n",
      "\n",
      "Epoch 727 batch 0 train Loss 47.9199 test Loss 0.0000 with MSE metric 4135.2180\n",
      "Time taken for 1 epoch: 2.2742037773132324 secs\n",
      "\n",
      "Epoch 728 batch 0 train Loss 47.8609 test Loss 0.0000 with MSE metric 4133.7260\n",
      "Time taken for 1 epoch: 2.167590856552124 secs\n",
      "\n",
      "Epoch 729 batch 0 train Loss 47.8022 test Loss 0.0000 with MSE metric 4133.5628\n",
      "Time taken for 1 epoch: 2.1863558292388916 secs\n",
      "\n",
      "Epoch 730 batch 0 train Loss 47.7436 test Loss 0.0000 with MSE metric 4131.7850\n",
      "Time taken for 1 epoch: 2.1538543701171875 secs\n",
      "\n",
      "Epoch 731 batch 0 train Loss 47.6853 test Loss 0.0000 with MSE metric 4130.3093\n",
      "Time taken for 1 epoch: 2.206542730331421 secs\n",
      "\n",
      "Epoch 732 batch 0 train Loss 47.6271 test Loss 0.0000 with MSE metric 4128.0417\n",
      "Time taken for 1 epoch: 2.2184078693389893 secs\n",
      "\n",
      "Epoch 733 batch 0 train Loss 47.5692 test Loss 0.0000 with MSE metric 4127.5552\n",
      "Time taken for 1 epoch: 2.2739920616149902 secs\n",
      "\n",
      "Epoch 734 batch 0 train Loss 47.5111 test Loss 0.0000 with MSE metric 4125.5521\n",
      "Time taken for 1 epoch: 2.1237518787384033 secs\n",
      "\n",
      "Epoch 735 batch 0 train Loss 47.4532 test Loss 0.0000 with MSE metric 4124.7808\n",
      "Time taken for 1 epoch: 2.1757640838623047 secs\n",
      "\n",
      "Epoch 736 batch 0 train Loss 47.3955 test Loss 0.0000 with MSE metric 4123.1281\n",
      "Time taken for 1 epoch: 2.1690187454223633 secs\n",
      "\n",
      "Epoch 737 batch 0 train Loss 47.3388 test Loss 0.0000 with MSE metric 4124.1662\n",
      "Time taken for 1 epoch: 2.139124870300293 secs\n",
      "\n",
      "Epoch 738 batch 0 train Loss 47.2816 test Loss 0.0000 with MSE metric 4124.3601\n",
      "Time taken for 1 epoch: 2.108687162399292 secs\n",
      "\n",
      "Epoch 739 batch 0 train Loss 47.2246 test Loss 0.0000 with MSE metric 4123.4155\n",
      "Time taken for 1 epoch: 2.586225986480713 secs\n",
      "\n",
      "Epoch 740 batch 0 train Loss 47.1680 test Loss 0.0000 with MSE metric 4123.1941\n",
      "Time taken for 1 epoch: 2.177748918533325 secs\n",
      "\n",
      "Epoch 741 batch 0 train Loss 47.1115 test Loss 0.0000 with MSE metric 4122.0155\n",
      "Time taken for 1 epoch: 2.2095859050750732 secs\n",
      "\n",
      "Epoch 742 batch 0 train Loss 47.0553 test Loss 0.0000 with MSE metric 4121.5060\n",
      "Time taken for 1 epoch: 2.147081136703491 secs\n",
      "\n",
      "Epoch 743 batch 0 train Loss 46.9989 test Loss 0.0000 with MSE metric 4120.1949\n",
      "Time taken for 1 epoch: 2.1801233291625977 secs\n",
      "\n",
      "Epoch 744 batch 0 train Loss 46.9424 test Loss 0.0000 with MSE metric 4118.7807\n",
      "Time taken for 1 epoch: 2.171977996826172 secs\n",
      "\n",
      "Epoch 745 batch 0 train Loss 46.8861 test Loss 0.0000 with MSE metric 4117.4061\n",
      "Time taken for 1 epoch: 2.1491668224334717 secs\n",
      "\n",
      "Epoch 746 batch 0 train Loss 46.8310 test Loss 0.0000 with MSE metric 4118.7155\n",
      "Time taken for 1 epoch: 2.2640469074249268 secs\n",
      "\n",
      "Epoch 747 batch 0 train Loss 46.7750 test Loss 0.0000 with MSE metric 4117.8285\n",
      "Time taken for 1 epoch: 2.107815980911255 secs\n",
      "\n",
      "Epoch 748 batch 0 train Loss 46.7191 test Loss 0.0000 with MSE metric 4116.1805\n",
      "Time taken for 1 epoch: 2.118551015853882 secs\n",
      "\n",
      "Epoch 749 batch 0 train Loss 46.6635 test Loss 0.0000 with MSE metric 4114.2343\n",
      "Time taken for 1 epoch: 2.0897531509399414 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = tf.summary.create_file_writer(save_dir + '/logs/')\n",
    "    optimizer_c = tf.keras.optimizers.Adam()\n",
    "    decoder = fox_model.Decoder(16)\n",
    "    EPOCHS = 1500\n",
    "    batch_s  = 15\n",
    "    run = 0; step = 0\n",
    "    num_batches = int(tar_tr.shape[0] / batch_s)\n",
    "    tf.random.set_seed(1)    \n",
    "    checkpoint = tf.train.Checkpoint(optimizer = optimizer_c, model = decoder)\n",
    "    main_folder = \"/Users/omernivron/Downloads/GPT_fox/ckpt/check_\"\n",
    "    folder = main_folder + str(run); helpers.mkdir(folder)\n",
    "\n",
    "    with writer.as_default():\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "\n",
    "            for batch_n in range(num_batches):\n",
    "                batch_tok_pos_tr, batch_tim_pos_tr, batch_tar_tr , batch_pos_mask, _ = batch_creator.create_batch_foxes(token_tr, pad_pos_tr, tar_tr, pp)\n",
    "                # batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                # batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                tar_inp, tar_real, pred, pred_sig, combined_mask_tar = train_step(batch_tok_pos_tr, batch_tim_pos_tr, batch_tar_tr, batch_pos_mask)\n",
    "\n",
    "                if batch_n % 50 == 0:\n",
    "#                     batch_tok_pos_te, batch_tim_pos_te, batch_tar_te , batch_pos_mask_te, _ = batch_creator.create_batch_foxes(token_te, pad_pos_te, tar_te, pp_te)\n",
    "#                     tar_real_te, pred, pred_sig = test_step(batch_tok_pos_te, batch_tim_pos_te, batch_tar_te, batch_pos_mask_te)\n",
    "                    helpers.print_progress(epoch, batch_n, train_loss.result(), test_loss.result(), m_tr.result())\n",
    "#                     helpers.tf_summaries(run, step, train_loss.result(), test_loss.result(), m_tr.result(), m_te.result())\n",
    "#                     checkpoint.save(folder + '/')\n",
    "                step += 1\n",
    "\n",
    "            print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_pos_tr[6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = decoder.e1\n",
    "weights = e.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([23.84272654, 24.17451531, 24.50822531, 24.84380031, 25.18118373,\n",
       "       25.52031876, 25.86114843, 26.20361569, 26.5476635 , 26.89323492,\n",
       "       27.24027319, 27.58872182, 27.93852465, 28.2896259 , 28.64197031,\n",
       "       28.99550315, 29.3501703 , 29.3338399 , 29.33422543, 29.34318017,\n",
       "       29.36300396, 29.39202324, 29.42885157, 29.4723305 , 29.52148456,\n",
       "       29.57548654, 29.63363044, 29.69531019, 29.7600027 , 29.82725433,\n",
       "       29.89666989, 29.96790375, 30.0406525 , 30.11464894, 30.18965701,\n",
       "       30.26546766, 30.34189531, 30.41877483, 30.49595909, 30.57331675,\n",
       "       30.65073046, 30.40816779, 29.93889317, 29.46667307, 29.00188682,\n",
       "       28.57246277, 28.17545528, 27.781603  , 27.37361636, 26.9439041 ,\n",
       "       26.70652619, 26.48007823, 26.26382102, 26.05708063, 25.85924133,\n",
       "       25.66973948, 25.48805809, 25.3137221 , 25.14629422, 24.98537123,\n",
       "       24.83058072, 24.68157821, 24.53804459, 24.3996838 , 24.26622078,\n",
       "       24.13739968, 24.01298216, 23.89274594, 23.7764835 , 23.66400079,\n",
       "       23.55511624, 23.44965974, 23.34747172, 23.24840238, 23.15231097,\n",
       "       23.05906506, 22.96853998, 22.88061823, 22.79518901, 22.7121477 ,\n",
       "       22.63139547, 22.55283888, 22.47638949, 22.40196358, 22.32948178,\n",
       "       22.25886885, 22.19005335, 22.12296748, 22.05754677, 21.99372995,\n",
       "       21.9314587 , 21.87067751, 21.81133348, 21.7533762 , 21.6967576 ,\n",
       "       21.64143178, 21.58735494, 21.53448524, 21.48278266, 21.43220896,\n",
       "       21.38272755, 21.3343034 , 21.28690295, 21.24049406, 21.19504593,\n",
       "       21.15052901, 21.10691494, 21.06417654, 21.02228766, 20.98122323,\n",
       "       20.94095911, 20.90147214, 20.86274   , 20.82474126, 20.78745527,\n",
       "       20.75086214, 20.71494274, 20.67967862, 20.64505201, 20.61104575,\n",
       "       20.57764332, 20.54482878, 20.51258672, 20.4809023 , 20.44976115,\n",
       "       20.41914943, 20.38905374, 20.35946114, 20.3303591 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 ])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mask_tar[1, :, 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([53.        , 53.7314    , 54.4575573 , 55.17807577, 55.89257113,\n",
       "       56.60067168, 57.30201906, 57.99626881, 58.68309099, 59.36217067,\n",
       "       60.03320836, 60.69592045, 61.35003944, 61.99531426, 62.63151042,\n",
       "       63.25841015, 63.87581247, 64.48353318, 65.08140481, 65.66927651,\n",
       "       66.24701391, 66.81449891, 67.37162937, 67.91831891, 68.45449649,\n",
       "       68.98010607, 69.4951062 , 69.99946958, 70.49318263, 70.97624493,\n",
       "       71.4486688 , 71.91047871, 72.3617108 , 72.8024123 , 73.232641  ,\n",
       "       73.65246466, 74.0619605 , 74.46121461, 74.8503214 , 75.22938304,\n",
       "       75.59850895, 75.95781523, 53.        , 50.        , 48.        ,\n",
       "       49.        , 50.        , 48.        , 44.        , 42.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_inp[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([170.5377    , 158.71284099, 147.52172089, 136.95626314,\n",
       "       127.00456081, 117.65142542, 108.87892606, 100.66690691,\n",
       "        92.99347403,  85.83544469,  79.16875492,  72.96882289,\n",
       "        67.21086754,  61.87018312,  56.92237156,  52.34353511,\n",
       "        48.11043257,  44.2006024 ,  40.59245631,  37.26534692,\n",
       "       183.        ,  23.        ,   5.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_real[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([-0.03583945, -0.03630679, -0.03658146, -0.03666347, -0.03655284,\n",
       "       -0.0362496 , -0.03575379, -0.03506542, -0.03418455, -0.0331112 ,\n",
       "       -0.03184543, -0.03038729, -0.02873682, -0.02689408, -0.02485913,\n",
       "       -0.02263204, -0.02021287, -0.01760169, -0.01479858, -0.01180361,\n",
       "       -0.01453558, -0.01682202, -0.01887398, -0.02066269, -0.02222955,\n",
       "       -0.02360825, -0.02482641, -0.02590686, -0.02686857, -0.02772741,\n",
       "       -0.02849675, -0.02918788, -0.02981041, -0.03037256, -0.03088137,\n",
       "       -0.03134291, -0.03176244, -0.03214451, -0.0324931 , -0.0328117 ,\n",
       "       -0.03310334, -0.03337072, -0.0336162 , -0.03384188, -0.03404962,\n",
       "       -0.03424107, -0.0344177 , -0.03458083, -0.03473165, -0.03487121,\n",
       "       -0.03500047, -0.03512027, -0.0352314 , -0.03533456, -0.03543038,\n",
       "       -0.03551943, -0.03560224, -0.03567929, -0.03575101, -0.03581778,\n",
       "       -0.03587999, -0.03593796, -0.03589755, -0.03584261, -0.03577452,\n",
       "       -0.03569451, -0.03560371, -0.03550316, -0.03539379, -0.03527648,\n",
       "       -0.03515199, -0.03502106, -0.03488429, -0.03474237, -0.03406015,\n",
       "       -0.00215294, -0.00192335, -0.00169419, -0.00146565, -0.0012379 ,\n",
       "       -0.00101107, -0.00078531, -0.00056072, -0.00033742, -0.0001155 ,\n",
       "        0.00010497,  0.0003239 ,  0.00054124,  0.00075692,  0.0009709 ,\n",
       "        0.00118314,  0.00139359,  0.00160224,  0.00180905,  0.00201399,\n",
       "        0.00221706,  0.00241825,  0.00261753,  0.0028149 ,  0.00301036,\n",
       "        0.0032039 ,  0.00339554,  0.00358526,  0.00377307,  0.00395899,\n",
       "        0.00414301,  0.00432515,  0.00450541,  0.00468382,  0.00486037,\n",
       "        0.00503509,  0.00520798,  0.00537907,  0.00554837,  0.00571589,\n",
       "        0.00588165,  0.00604567,  0.00620797,  0.00636855,  0.00652745,\n",
       "        0.00668468,  0.00684025,  0.00699419,  0.00714651,  0.00729723,\n",
       "        0.00744637,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 148, 149, 149)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pos_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_real_te[30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([-0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sig[2, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
