{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import fox_model, losses, dot_prod_attention\n",
    "from data import data_generation, batch_creator, gp_kernels\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from helpers import helpers, masks\n",
    "from inference import infer\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/omernivron/Downloads/GPT_fox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load('/Users/omernivron/Downloads/fnr.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = foxes\n",
    "# 1 = rabbits\n",
    "# 2 = time\n",
    "# 3 = foxes_tokens\n",
    "# 4 = rabbits_tokens (token id 3 means rabbit_ode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df[2::5]\n",
    "f = df[0::5]; r = df[1::5]\n",
    "f_token = df[3::5]; r_token = df[4::5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr = t[:80]; f_tr = f[:80]; r_tr = r[:80]; f_token_tr = f_token[:80]; r_token_tr = r_token[:80]\n",
    "pad_pos_te = t[80:]; f_te = f[80:]; r_te = r[80:]; f_token_te = f_token[80:]; r_token_te = r_token[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr = np.repeat(pad_pos_tr, 2, axis = 0)\n",
    "pad_pos_te = np.repeat(pad_pos_te, 2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tr = np.concatenate((f_tr, r_tr), axis = 0); tar_te = np.concatenate((f_te, r_te), axis = 0)\n",
    "token_tr = np.concatenate((f_token_tr, r_token_tr), axis = 0); token_te = np.concatenate((f_token_te, r_token_te), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = masks.position_mask(pad_pos_tr)\n",
    "pp_te = masks.position_mask(pad_pos_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "m_tr = tf.keras.metrics.Mean()\n",
    "m_te = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(token_pos, time_pos, tar, pos_mask):\n",
    "    '''\n",
    "    A typical train step function for TF2. Elements which we wish to track their gradient\n",
    "    has to be inside the GradientTape() clause. see (1) https://www.tensorflow.org/guide/migrate \n",
    "    (2) https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask (np array): see description in position_mask function\n",
    "    ------------------    \n",
    "    '''\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    combined_mask_tar = masks.create_masks(tar_inp)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        pred, pred_sig = decoder(token_pos, time_pos, tar_inp, True, pos_mask, combined_mask_tar)\n",
    "#         print('pred: ')\n",
    "#         tf.print(pred_sig)\n",
    "\n",
    "        loss, mse, mask = losses.loss_function(tar_real, pred, pred_sig)\n",
    "\n",
    "\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "#     tf.print(gradients)\n",
    "# Ask the optimizer to apply the processed gradients.\n",
    "    optimizer_c.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    m_tr.update_state(mse, mask)\n",
    "#     b = decoder.trainable_weights[0]\n",
    "#     tf.print(tf.reduce_mean(b))\n",
    "    return tar_inp, tar_real, pred, pred_sig, combined_mask_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(token_pos_te, time_pos_te, tar_te, pos_mask_te):\n",
    "    '''\n",
    "    \n",
    "    ---------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask_te (np array): see description in position_mask function\n",
    "    ---------------\n",
    "    \n",
    "    '''\n",
    "    tar_inp_te = tar_te[:, :-1]\n",
    "    tar_real_te = tar_te[:, 1:]\n",
    "    combined_mask_tar_te = masks.create_masks(tar_inp_te)\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "    pred, pred_sig = decoder(token_pos_te, time_pos_te, tar_inp_te, False, pos_mask_te, combined_mask_tar_te)\n",
    "#     tf.print(tf.math.reduce_max(pred_sig))\n",
    "    t_loss, t_mse, t_mask = losses.loss_function(tar_real_te, pred, pred_sig)\n",
    "    tf.print(t_loss)\n",
    "    test_loss(t_loss)\n",
    "    m_te.update_state(t_mse, t_mask)\n",
    "    return tar_real_te, pred, pred_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists\n",
      "Epoch 0 batch 0 train Loss 601.5988 test Loss 0.0000 with MSE metric 5679.6123\n",
      "Time taken for 1 epoch: 149.25540828704834 secs\n",
      "\n",
      "Epoch 1 batch 0 train Loss 189.5434 test Loss 0.0000 with MSE metric 6058.0791\n",
      "Time taken for 1 epoch: 149.5448489189148 secs\n",
      "\n",
      "Epoch 2 batch 0 train Loss 105.0678 test Loss 0.0000 with MSE metric 6041.6445\n",
      "Time taken for 1 epoch: 142.45593404769897 secs\n",
      "\n",
      "Epoch 3 batch 0 train Loss 73.0988 test Loss 0.0000 with MSE metric 5971.8579\n",
      "Time taken for 1 epoch: 157.56733798980713 secs\n",
      "\n",
      "Epoch 4 batch 0 train Loss 56.6541 test Loss 0.0000 with MSE metric 6039.2402\n",
      "Time taken for 1 epoch: 153.1128089427948 secs\n",
      "\n",
      "Epoch 5 batch 0 train Loss 46.6552 test Loss 0.0000 with MSE metric 6091.9624\n",
      "Time taken for 1 epoch: 140.58529090881348 secs\n",
      "\n",
      "Epoch 6 batch 0 train Loss 39.9267 test Loss 0.0000 with MSE metric 6013.5962\n",
      "Time taken for 1 epoch: 141.0576012134552 secs\n",
      "\n",
      "Epoch 7 batch 0 train Loss 35.0920 test Loss 0.0000 with MSE metric 5994.8862\n",
      "Time taken for 1 epoch: 144.4371907711029 secs\n",
      "\n",
      "Epoch 8 batch 0 train Loss 31.4497 test Loss 0.0000 with MSE metric 5983.4180\n",
      "Time taken for 1 epoch: 149.81669807434082 secs\n",
      "\n",
      "Epoch 9 batch 0 train Loss 28.6068 test Loss 0.0000 with MSE metric 5971.3521\n",
      "Time taken for 1 epoch: 143.89530205726624 secs\n",
      "\n",
      "Epoch 10 batch 0 train Loss 26.3232 test Loss 0.0000 with MSE metric 5916.0107\n",
      "Time taken for 1 epoch: 139.8022997379303 secs\n",
      "\n",
      "Epoch 11 batch 0 train Loss 24.4554 test Loss 0.0000 with MSE metric 5933.7227\n",
      "Time taken for 1 epoch: 147.98149609565735 secs\n",
      "\n",
      "Epoch 12 batch 0 train Loss 22.8924 test Loss 0.0000 with MSE metric 5908.3979\n",
      "Time taken for 1 epoch: 151.64314913749695 secs\n",
      "\n",
      "Epoch 13 batch 0 train Loss 21.5693 test Loss 0.0000 with MSE metric 5911.0977\n",
      "Time taken for 1 epoch: 147.12519192695618 secs\n",
      "\n",
      "Epoch 14 batch 0 train Loss 20.4328 test Loss 0.0000 with MSE metric 5912.7524\n",
      "Time taken for 1 epoch: 152.61500477790833 secs\n",
      "\n",
      "Epoch 15 batch 0 train Loss 19.4464 test Loss 0.0000 with MSE metric 5905.7637\n",
      "Time taken for 1 epoch: 148.24405884742737 secs\n",
      "\n",
      "Epoch 16 batch 0 train Loss 18.5819 test Loss 0.0000 with MSE metric 5900.7827\n",
      "Time taken for 1 epoch: 142.93965005874634 secs\n",
      "\n",
      "Epoch 17 batch 0 train Loss 17.8159 test Loss 0.0000 with MSE metric 5871.8364\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = tf.summary.create_file_writer(save_dir + '/logs/')\n",
    "    optimizer_c = tf.keras.optimizers.Adam()\n",
    "    decoder = fox_model.Decoder(16)\n",
    "    EPOCHS = 1500\n",
    "    batch_s  = 15\n",
    "    run = 0; step = 0\n",
    "    num_batches = int(tar_tr.shape[0] / batch_s)\n",
    "    tf.random.set_seed(1)    \n",
    "    checkpoint = tf.train.Checkpoint(optimizer = optimizer_c, model = decoder)\n",
    "    main_folder = \"/Users/omernivron/Downloads/GPT_fox/ckpt/check_\"\n",
    "    folder = main_folder + str(run); helpers.mkdir(folder)\n",
    "\n",
    "    with writer.as_default():\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "\n",
    "            for batch_n in range(num_batches):\n",
    "                batch_tok_pos_tr, batch_tim_pos_tr, batch_tar_tr , batch_pos_mask, _ = batch_creator.create_batch_foxes(token_tr, pad_pos_tr, tar_tr, pp)\n",
    "                # batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                # batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                tar_inp, tar_real, pred, pred_sig, combined_mask_tar = train_step(batch_tok_pos_tr, batch_tim_pos_tr, batch_tar_tr, batch_pos_mask)\n",
    "\n",
    "                if batch_n % 50 == 0:\n",
    "#                     batch_tok_pos_te, batch_tim_pos_te, batch_tar_te , batch_pos_mask_te, _ = batch_creator.create_batch_foxes(token_te, pad_pos_te, tar_te, pp_te)\n",
    "#                     tar_real_te, pred, pred_sig = test_step(batch_tok_pos_te, batch_tim_pos_te, batch_tar_te, batch_pos_mask_te)\n",
    "                    helpers.print_progress(epoch, batch_n, train_loss.result(), test_loss.result(), m_tr.result())\n",
    "#                     helpers.tf_summaries(run, step, train_loss.result(), test_loss.result(), m_tr.result(), m_te.result())\n",
    "#                     checkpoint.save(folder + '/')\n",
    "                step += 1\n",
    "\n",
    "            print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 2., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_pos_tr[6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = decoder.e1\n",
    "weights = e.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([23.84272654, 24.17451531, 24.50822531, 24.84380031, 25.18118373,\n",
       "       25.52031876, 25.86114843, 26.20361569, 26.5476635 , 26.89323492,\n",
       "       27.24027319, 27.58872182, 27.93852465, 28.2896259 , 28.64197031,\n",
       "       28.99550315, 29.3501703 , 29.3338399 , 29.33422543, 29.34318017,\n",
       "       29.36300396, 29.39202324, 29.42885157, 29.4723305 , 29.52148456,\n",
       "       29.57548654, 29.63363044, 29.69531019, 29.7600027 , 29.82725433,\n",
       "       29.89666989, 29.96790375, 30.0406525 , 30.11464894, 30.18965701,\n",
       "       30.26546766, 30.34189531, 30.41877483, 30.49595909, 30.57331675,\n",
       "       30.65073046, 30.40816779, 29.93889317, 29.46667307, 29.00188682,\n",
       "       28.57246277, 28.17545528, 27.781603  , 27.37361636, 26.9439041 ,\n",
       "       26.70652619, 26.48007823, 26.26382102, 26.05708063, 25.85924133,\n",
       "       25.66973948, 25.48805809, 25.3137221 , 25.14629422, 24.98537123,\n",
       "       24.83058072, 24.68157821, 24.53804459, 24.3996838 , 24.26622078,\n",
       "       24.13739968, 24.01298216, 23.89274594, 23.7764835 , 23.66400079,\n",
       "       23.55511624, 23.44965974, 23.34747172, 23.24840238, 23.15231097,\n",
       "       23.05906506, 22.96853998, 22.88061823, 22.79518901, 22.7121477 ,\n",
       "       22.63139547, 22.55283888, 22.47638949, 22.40196358, 22.32948178,\n",
       "       22.25886885, 22.19005335, 22.12296748, 22.05754677, 21.99372995,\n",
       "       21.9314587 , 21.87067751, 21.81133348, 21.7533762 , 21.6967576 ,\n",
       "       21.64143178, 21.58735494, 21.53448524, 21.48278266, 21.43220896,\n",
       "       21.38272755, 21.3343034 , 21.28690295, 21.24049406, 21.19504593,\n",
       "       21.15052901, 21.10691494, 21.06417654, 21.02228766, 20.98122323,\n",
       "       20.94095911, 20.90147214, 20.86274   , 20.82474126, 20.78745527,\n",
       "       20.75086214, 20.71494274, 20.67967862, 20.64505201, 20.61104575,\n",
       "       20.57764332, 20.54482878, 20.51258672, 20.4809023 , 20.44976115,\n",
       "       20.41914943, 20.38905374, 20.35946114, 20.3303591 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 , 19.8566076 ,\n",
       "       19.8566076 , 19.8566076 , 19.8566076 ])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float32, numpy=\n",
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mask_tar[1, :, 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([53.        , 53.7314    , 54.4575573 , 55.17807577, 55.89257113,\n",
       "       56.60067168, 57.30201906, 57.99626881, 58.68309099, 59.36217067,\n",
       "       60.03320836, 60.69592045, 61.35003944, 61.99531426, 62.63151042,\n",
       "       63.25841015, 63.87581247, 64.48353318, 65.08140481, 65.66927651,\n",
       "       66.24701391, 66.81449891, 67.37162937, 67.91831891, 68.45449649,\n",
       "       68.98010607, 69.4951062 , 69.99946958, 70.49318263, 70.97624493,\n",
       "       71.4486688 , 71.91047871, 72.3617108 , 72.8024123 , 73.232641  ,\n",
       "       73.65246466, 74.0619605 , 74.46121461, 74.8503214 , 75.22938304,\n",
       "       75.59850895, 75.95781523, 53.        , 50.        , 48.        ,\n",
       "       49.        , 50.        , 48.        , 44.        , 42.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_inp[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([170.5377    , 158.71284099, 147.52172089, 136.95626314,\n",
       "       127.00456081, 117.65142542, 108.87892606, 100.66690691,\n",
       "        92.99347403,  85.83544469,  79.16875492,  72.96882289,\n",
       "        67.21086754,  61.87018312,  56.92237156,  52.34353511,\n",
       "        48.11043257,  44.2006024 ,  40.59245631,  37.26534692,\n",
       "       183.        ,  23.        ,   5.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,   0.        ])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_real[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(148,), dtype=float64, numpy=\n",
       "array([-0.03583945, -0.03630679, -0.03658146, -0.03666347, -0.03655284,\n",
       "       -0.0362496 , -0.03575379, -0.03506542, -0.03418455, -0.0331112 ,\n",
       "       -0.03184543, -0.03038729, -0.02873682, -0.02689408, -0.02485913,\n",
       "       -0.02263204, -0.02021287, -0.01760169, -0.01479858, -0.01180361,\n",
       "       -0.01453558, -0.01682202, -0.01887398, -0.02066269, -0.02222955,\n",
       "       -0.02360825, -0.02482641, -0.02590686, -0.02686857, -0.02772741,\n",
       "       -0.02849675, -0.02918788, -0.02981041, -0.03037256, -0.03088137,\n",
       "       -0.03134291, -0.03176244, -0.03214451, -0.0324931 , -0.0328117 ,\n",
       "       -0.03310334, -0.03337072, -0.0336162 , -0.03384188, -0.03404962,\n",
       "       -0.03424107, -0.0344177 , -0.03458083, -0.03473165, -0.03487121,\n",
       "       -0.03500047, -0.03512027, -0.0352314 , -0.03533456, -0.03543038,\n",
       "       -0.03551943, -0.03560224, -0.03567929, -0.03575101, -0.03581778,\n",
       "       -0.03587999, -0.03593796, -0.03589755, -0.03584261, -0.03577452,\n",
       "       -0.03569451, -0.03560371, -0.03550316, -0.03539379, -0.03527648,\n",
       "       -0.03515199, -0.03502106, -0.03488429, -0.03474237, -0.03406015,\n",
       "       -0.00215294, -0.00192335, -0.00169419, -0.00146565, -0.0012379 ,\n",
       "       -0.00101107, -0.00078531, -0.00056072, -0.00033742, -0.0001155 ,\n",
       "        0.00010497,  0.0003239 ,  0.00054124,  0.00075692,  0.0009709 ,\n",
       "        0.00118314,  0.00139359,  0.00160224,  0.00180905,  0.00201399,\n",
       "        0.00221706,  0.00241825,  0.00261753,  0.0028149 ,  0.00301036,\n",
       "        0.0032039 ,  0.00339554,  0.00358526,  0.00377307,  0.00395899,\n",
       "        0.00414301,  0.00432515,  0.00450541,  0.00468382,  0.00486037,\n",
       "        0.00503509,  0.00520798,  0.00537907,  0.00554837,  0.00571589,\n",
       "        0.00588165,  0.00604567,  0.00620797,  0.00636855,  0.00652745,\n",
       "        0.00668468,  0.00684025,  0.00699419,  0.00714651,  0.00729723,\n",
       "        0.00744637,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474,  0.01036474,  0.01036474,\n",
       "        0.01036474,  0.01036474,  0.01036474])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 148, 149, 149)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pos_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_real_te[30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([-0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568, -0.04683568,\n",
       "       -0.04683568, -0.04683568, -0.04683568, -0.04683568])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(189,), dtype=float64, numpy=\n",
       "array([2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801, 2.79753801,\n",
       "       2.79753801, 2.79753801, 2.79753801, 2.79753801])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sig[2, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
