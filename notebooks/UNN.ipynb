{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omernivron/opt/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import classic_model_mh, classic_model, losses, dot_prod_attention\n",
    "from data import data_generation, batch_creator, gp_kernels, gp_priors\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from helpers import helpers, masks, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "from inference import infer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import time\n",
    "import keras\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/Users/omernivron/Downloads/GPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pos_tr, pad_pos_te, pad_y_fren_tr, pad_y_fren_te, _, df_te = data_generation.data_generator_for_gp_mimick_gpt(150000, ordered = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m = np.mean(pad_pos_tr)\n",
    "std = np.std(pad_pos_tr)\n",
    "m_y = np.mean(pad_y_fren_tr)\n",
    "std_y = np.std(pad_y_fren_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_pos_tr = (pad_pos_tr - m) / std\n",
    "pad_pos_te = (pad_pos_te - m) / std\n",
    "pad_y_fren_tr = (pad_y_fren_tr - m_y) / std_y\n",
    "pad_y_fren_te = (pad_y_fren_te - m_y) / std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "m_tr = tf.keras.metrics.Mean()\n",
    "m_te = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(decoder, optimizer_c, train_loss, m_tr, pos, curr_pos, tar):\n",
    "    '''\n",
    "    A typical train step function for TF2. Elements which we wish to track their gradient\n",
    "    has to be inside the GradientTape() clause. see (1) https://www.tensorflow.org/guide/migrate \n",
    "    (2) https://www.tensorflow.org/tutorials/quickstart/advanced\n",
    "    ------------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask (np array): see description in position_mask function\n",
    "    ------------------    \n",
    "    '''\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    combined_mask_pos = masks.create_masks(pos)\n",
    "    combined_mask_tar = masks.create_masks(tar_inp)\n",
    "\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "#         pred, pred_log_sig = decoder(pos, tar_inp, True, pos_mask, combined_mask_tar)\n",
    "        # starting from 9 means we want to have the first 10 traget r.v y as static \n",
    "        # and they are not going to be part of the loss calculation\n",
    "        pred = decoder(pos, curr_pos, tar_inp, True, combined_mask_pos , combined_mask_tar)\n",
    "\n",
    "\n",
    "# \n",
    "#         loss, mse, mask = losses.loss_function(tar_real, pred, pred_log_sig)\n",
    "        loss, mse, mask = losses.loss_function(tar_real[:, 9:], pred = pred[:, 9:, 0], pred_log_sig = pred[:, 9:, 1])\n",
    "\n",
    "\n",
    "\n",
    "    gradients = tape.gradient(loss, decoder.trainable_variables)\n",
    "    # Ask the optimizer to apply the processed gradients.\n",
    "    optimizer_c.apply_gradients(zip(gradients, decoder.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    m_tr.update_state(mse, mask)\n",
    "    return pred[:, 9:, 0], pred[:, 9:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(decoder, test_loss, m_te, pos_te, curr_pos_te, tar_te):\n",
    "    '''\n",
    "    \n",
    "    ---------------\n",
    "    Parameters:\n",
    "    pos (np array): array of positions (x values) - the 1st/2nd output from data_generator_for_gp_mimick_gpt\n",
    "    tar (np array): array of targets. Notice that if dealing with sequnces, we typically want to have the targets go from 0 to n-1. The 3rd/4th output from data_generator_for_gp_mimick_gpt  \n",
    "    pos_mask_te (np array): see description in position_mask function\n",
    "    ---------------\n",
    "    \n",
    "    '''\n",
    "    tar_inp_te = tar_te[:, :-1]\n",
    "    tar_real_te = tar_te[:, 1:]\n",
    "    combined_mask_pos_te = masks.create_masks(pos_te)\n",
    "    combined_mask_tar_te = masks.create_masks(tar_inp_te)    \n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "#   pred = decoder(pos_te, tar_inp_te, False, pos_mask_te, combined_mask_tar_te)\n",
    "\n",
    "\n",
    "#     pred, pred_log_sig = decoder(pos_te, tar_inp_te, False, pos_mask_te, combined_mask_tar_te)\n",
    "    pred_te = decoder(pos_te, curr_pos_te, tar_inp_te, False, combined_mask_pos_te, combined_mask_tar_te)\n",
    "\n",
    "\n",
    "#     t_loss, t_mse, t_mask = losses.loss_function(tar_real_te, pred, pred_log_sig)\n",
    "    t_loss, t_mse, t_mask = losses.loss_function(tar_real_te[:, 9:], pred = pred_te[:, 9:, 0], pred_log_sig = pred_te[:, 9:, 1])\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    m_te.update_state(t_mse, t_mask)\n",
    "    return pred_te[:, 9:, 0], pred_te[:, 9:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists\n",
      "Restored from /Users/omernivron/Downloads/GPT/ckpt/check_1/ckpt-162\n",
      "Epoch 0 batch 0 train Loss 0.3668 test Loss 0.4020 with MSE metric 0.8643\n",
      "Epoch 0 batch 50 train Loss 0.3545 test Loss 0.3650 with MSE metric 0.7921\n",
      "Epoch 0 batch 100 train Loss 0.3442 test Loss 0.3708 with MSE metric 0.8108\n",
      "Epoch 0 batch 150 train Loss 0.3840 test Loss 0.4007 with MSE metric 0.9127\n",
      "Epoch 0 batch 200 train Loss 0.3807 test Loss 0.3834 with MSE metric 0.8519\n",
      "Epoch 0 batch 250 train Loss 0.3656 test Loss 0.3705 with MSE metric 0.8031\n",
      "Epoch 0 batch 300 train Loss 0.3747 test Loss 0.4144 with MSE metric 0.9268\n",
      "Epoch 0 batch 350 train Loss 0.3966 test Loss 0.4034 with MSE metric 0.9156\n",
      "Epoch 0 batch 400 train Loss 0.3676 test Loss 0.4112 with MSE metric 0.9479\n",
      "Epoch 0 batch 450 train Loss 0.3343 test Loss 0.3944 with MSE metric 0.8825\n",
      "Epoch 0 batch 500 train Loss 0.3635 test Loss 0.3876 with MSE metric 0.8562\n",
      "Epoch 0 batch 550 train Loss 0.3511 test Loss 0.4061 with MSE metric 0.8975\n",
      "Epoch 0 batch 600 train Loss 0.3963 test Loss 0.3865 with MSE metric 0.8605\n",
      "Epoch 0 batch 650 train Loss 0.3951 test Loss 0.3955 with MSE metric 0.8943\n",
      "Epoch 0 batch 700 train Loss 0.3468 test Loss 0.4030 with MSE metric 0.8785\n",
      "Epoch 0 batch 750 train Loss 0.3679 test Loss 0.3922 with MSE metric 0.8811\n",
      "Epoch 0 batch 800 train Loss 0.3346 test Loss 0.3939 with MSE metric 0.8859\n",
      "Epoch 0 batch 850 train Loss 0.3663 test Loss 0.3957 with MSE metric 0.8952\n",
      "Epoch 0 batch 900 train Loss 0.3770 test Loss 0.4067 with MSE metric 0.9136\n",
      "Epoch 0 batch 950 train Loss 0.3448 test Loss 0.3803 with MSE metric 0.8419\n",
      "Epoch 0 batch 1000 train Loss 0.3633 test Loss 0.4076 with MSE metric 0.9194\n",
      "Epoch 0 batch 1050 train Loss 0.3406 test Loss 0.3817 with MSE metric 0.8462\n",
      "Epoch 0 batch 1100 train Loss 0.3552 test Loss 0.4059 with MSE metric 0.9312\n",
      "Epoch 0 batch 1150 train Loss 0.3461 test Loss 0.4135 with MSE metric 0.9459\n",
      "Epoch 0 batch 1200 train Loss 0.3464 test Loss 0.3911 with MSE metric 0.8753\n",
      "Epoch 0 batch 1250 train Loss 0.3347 test Loss 0.3893 with MSE metric 0.8674\n",
      "Epoch 0 batch 1300 train Loss 0.3730 test Loss 0.3935 with MSE metric 0.8728\n",
      "Epoch 0 batch 1350 train Loss 0.3783 test Loss 0.4097 with MSE metric 0.9250\n",
      "Epoch 0 batch 1400 train Loss 0.4149 test Loss 0.3986 with MSE metric 0.8971\n",
      "Epoch 0 batch 1450 train Loss 0.3532 test Loss 0.3916 with MSE metric 0.8772\n",
      "Epoch 0 batch 1500 train Loss 0.3738 test Loss 0.3841 with MSE metric 0.8491\n",
      "Epoch 0 batch 1550 train Loss 0.3606 test Loss 0.3889 with MSE metric 0.8680\n",
      "Epoch 0 batch 1600 train Loss 0.3479 test Loss 0.4244 with MSE metric 0.9432\n",
      "Epoch 0 batch 1650 train Loss 0.3404 test Loss 0.4026 with MSE metric 0.9144\n",
      "Epoch 0 batch 1700 train Loss 0.3813 test Loss 0.3694 with MSE metric 0.8057\n",
      "Epoch 0 batch 1750 train Loss 0.3532 test Loss 0.4011 with MSE metric 0.9038\n",
      "Epoch 0 batch 1800 train Loss 0.3654 test Loss 0.3971 with MSE metric 0.8918\n",
      "Epoch 0 batch 1850 train Loss 0.3530 test Loss 0.4033 with MSE metric 0.9225\n",
      "Time taken for 1 epoch: 66.83143401145935 secs\n",
      "\n",
      "Epoch 1 batch 0 train Loss 0.3788 test Loss 0.4407 with MSE metric 1.0139\n",
      "Epoch 1 batch 50 train Loss 0.3589 test Loss 0.4259 with MSE metric 0.9576\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-39c24df02484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mm_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mm_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mbatch_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_tar_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batch_gp_mim_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_y_fren_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mbatch_pos_tr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_pos_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mbatch_pos_tr_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_pos_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/studies/Cambridge/Damon/attention/data/batch_creator.py\u001b[0m in \u001b[0;36mcreate_batch_gp_mim_2\u001b[0;34m(pos, tar, batch_s)\u001b[0m\n\u001b[1;32m     51\u001b[0m     '''\n\u001b[1;32m     52\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mbatch_idx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mbatch_tar_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mbatch_pos_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    writer = tf.summary.create_file_writer(save_dir + '/logs/')\n",
    "    optimizer_c = tf.keras.optimizers.Adam()\n",
    "    decoder = classic_model.Decoder(64)\n",
    "    EPOCHS = 750\n",
    "    batch_s  = 64\n",
    "    run = 1; step = 0\n",
    "    num_batches = int(pad_y_fren_tr.shape[0] / batch_s)\n",
    "    tf.random.set_seed(1)   \n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer = optimizer_c, net = decoder)\n",
    "    main_folder = \"/Users/omernivron/Downloads/GPT/ckpt/check_\"\n",
    "    folder = main_folder + str(run); helpers.mkdir(folder)\n",
    "    manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=3)\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "    \n",
    "    with writer.as_default():\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "\n",
    "            for batch_n in range(num_batches):\n",
    "                m_tr.reset_states(); train_loss.reset_states()\n",
    "                m_te.reset_states(); test_loss.reset_states()\n",
    "                batch_pos_tr, batch_tar_tr, _ = batch_creator.create_batch_gp_mim_2(pad_pos_tr, pad_y_fren_tr, batch_s=64)\n",
    "                batch_pos_tr1 = batch_pos_tr[:, :-1]\n",
    "                batch_pos_tr_current = batch_pos_tr[:, 1:]\n",
    "                # batch_tar_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "                # batch_pos_tr shape := 128 X 59 = (batch_size, max_seq_len)\n",
    "#                 batch_pos_mask = masks.position_mask(batch_pos_tr)\n",
    "#                 print(batch_pos_mask.shape)\n",
    "#                 print(batch_pos_mask)\n",
    "                pred, pred_log = train_step(decoder, optimizer_c, train_loss, m_tr, batch_pos_tr1, batch_pos_tr_current, batch_tar_tr)\n",
    "                \n",
    "                if batch_n % 50 == 0:\n",
    "                    batch_pos_te, batch_tar_te, _ = batch_creator.create_batch_gp_mim_2(pad_pos_te, pad_y_fren_te, batch_s=64)\n",
    "                    batch_pos_te1 = batch_pos_te[:, :-1]\n",
    "                    batch_pos_te_current = batch_pos_te[:, 1:]\n",
    "                    pred_te, pred_log_te = test_step(decoder, test_loss, m_te, batch_pos_te1, batch_pos_te_current, batch_tar_te)\n",
    "                    helpers.print_progress(epoch, batch_n, train_loss.result(), test_loss.result(), m_te.result())\n",
    "                    helpers.tf_summaries(run, step, train_loss.result(), test_loss.result(), m_tr.result(), m_te.result())\n",
    "                    manager.save()\n",
    "                step += 1\n",
    "                ckpt.step.assign_add(1)\n",
    "\n",
    "            print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<model.classic_model.Decoder at 0x7fc30801ee10>,\n",
       " array([[11.20296855,  8.3711938 ,  7.48517354,  7.49641115,  6.76599838,\n",
       "         12.76817202,  7.27290089,  6.52875587, 13.91882685,  7.07107552]]),\n",
       " <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[ 0.01873204, -0.4244775 ,  1.2823803 ,  1.2612942 ,  1.8032377 ,\n",
       "         -0.11894997,  1.621971  ,  1.5701907 , -0.4642492 ,  1.0219529 ]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer.inference(decoder, pos = batch_pos_tr[1, :10].reshape(1, -1), tar = batch_tar_tr[1, :9].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_arr = np.argsort(batch_pos_tr[1, :])\n",
    "plt.scatter(batch_pos_tr[1, :9], batch_tar_tr[1, :9])\n",
    "plt.plot(batch_pos_tr[1, sorted_arr], batch_tar_tr[1, sorted_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_pos_tr.shape[0]):\n",
    "    plt.plot(batch_pos_tr[i, :], batch_tar_tr[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrapo = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extrapo:\n",
    "    x = np.load('/Users/omernivron/Downloads/GPT_data_goldstandard/x_extra.npy')\n",
    "    y = np.load('/Users/omernivron/Downloads/GPT_data_goldstandard/y_extra.npy')\n",
    "else:\n",
    "    x = np.load('/Users/omernivron/Downloads/GPT_data_goldstandard/x_interpol.npy')\n",
    "    y = np.load('/Users/omernivron/Downloads/GPT_data_goldstandard/y_interpol.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_metric = 0; r_sq_metric = 0; kuee_metric = 0;\n",
    "μ = []; σ = []\n",
    "m = int(x.shape[0] / 10)\n",
    "y_mean = np.mean(y[:m, :40])\n",
    "y_te = y[:m, 40]\n",
    "for j in range(0, m):\n",
    "    x_tr = x[j, :41].reshape(1, -1)\n",
    "    y_tr = y[j, :40].reshape(1, -1)\n",
    "    μ_te = infer.inference(decoder, x_tr, y_tr)\n",
    "#     μ_te, log_σ_te = infer.inference(decoder, x_tr, y_tr, mh=True)\n",
    "\n",
    "\n",
    "    μ.append(μ_te[0][-1].numpy()); \n",
    "#     σ.append(log_σ_te[-1])\n",
    "#     kuee_metric += metrics.KUEE(y_te[j], μ_te[-1], np.exp(log_σ_te[-1]))\n",
    "#     if (j % 400 == 0): \n",
    "#         print('J: ', j)\n",
    "#         axes = plt.gca()\n",
    "#         axes.set_ylim([-2, 2])\n",
    "#         plt.scatter(x_tr[:, :-1], y_tr, c = 'black')\n",
    "#         plt.scatter(x_tr[:, 1:], μ_te, c='navy')\n",
    "#         plt.scatter(x_tr[:, -1], y_te[j], c='purple')\n",
    "#         plt.scatter(x_tr[:, -1], μ_te[-1], c='red')\n",
    "# #         plt.errorbar(x = x_tr[:, 40], y = (μ_te[-1]), yerr = 2 * np.exp(log_σ_te[-1]), fmt='o', ecolor='g', capthick=2)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# #         plt.fill_between(x_tr[:, 1:].squeeze(), μ_te -2 * np.exp(log_σ_te), μ_te  + 2 * np.exp(log_σ_te), alpha=.2)\n",
    "\n",
    "#         plt.show()\n",
    "    \n",
    "mse_metric = metrics.mse(y_te, μ) \n",
    "r_sq_metric = metrics.r_squared(y_te, μ, y_mean)  \n",
    "mse_metric *= (1 / m)\n",
    "# kuee_metric *= (1 / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mse_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1, 1, 1]])\n",
    "t1 = tf.constant([[2, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.create_look_ahead_mask(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.linalg.band_part(tf.ones((5, 5)), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.multiply(t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.repeat((1,1), 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(tf.repeat(0, 9), shape=(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = tf.repeat(tf.concat([tf.constant(tf.repeat(0, 10), shape=(1, 10)), tf.constant(tf.repeat(1, 21), shape=(1, 21))], axis = 1), 64, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transpose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
