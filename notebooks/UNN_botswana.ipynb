{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "from model import experimental_model, experimental2d_model, grapher, exp2d_model_tr\n",
    "from data import batch_creator, loader, data_generation\n",
    "from helpers import helpers, plotter, metrics\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = \"botswana\"\n",
    "d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana = np.load(\"/Users/omernivron/Downloads/GFDL_botswana.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_dim = np.load(\"/Users/omernivron/Downloads/GFDL_botswana_dimensions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_t = np.load(\"/Users/omernivron/Downloads/GFDL_botswana_times.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc =  np.load(\"/Users/omernivron/Downloads/GFDL_botswana_lat_lon.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_win = np.load(\"/Users/omernivron/Downloads/GFDL_within_bots_lat_lon.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = sns.color_palette(\"rocket\")\n",
    "plt.scatter(bots_loc[:, 1], bots_loc[:, 0], c=botswana[0, :, 500], cmap=\"seismic\")\n",
    "plt.colorbar()\n",
    "plt.scatter(bots_win[:, 1], bots_win[:, 0], c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.expanduser('~/Downloads/' + kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(bots_t, botswana[1, 0, :])\n",
    "ax.plot(bots_t, botswana[1, 470, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = botswana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = list(itertools.combinations(np.arange(n), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botswana[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.concatenate((botswana[pair[0]].reshape(528, -1), botswana[pair[1]].reshape(528, -1)), axis = -1) if (pair[1] < 30) else np.zeros((528, 2040)) for pair in combos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.concatenate((bots_t, bots_t))\n",
    "t = t - np.mean(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_y = np.array([np.concatenate((y[i][:, j:j+205], y[i][:, 1020+j:1225 +j]), axis = -1) for i in range(len(y)) for j in range(0, 815, 163) ])\n",
    "t_y = np.array([np.concatenate((t[j:j+205], t[1020+j:1225 +j])) for i in range(len(y)) for j in range(0, 815, 163)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = np.mean(y)\n",
    "d_y = d_y - μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_position(t, d, TΔmin, Tmax):  # return.shape=(T,B,d)\n",
    "    # t.shape=(T,B)   T=sequence_length, B=batch_size\n",
    "    \"\"\"A position-embedder, similar to the Attention paper, but tweaked to account for\n",
    "    floating point positions, rather than integer.\n",
    "    \"\"\"\n",
    "    R = Tmax / TΔmin * 100\n",
    "    drange_even = TΔmin * R**(np.arange(0,d,2)/d)\n",
    "    drange_odd = TΔmin * R**((np.arange(1,d,2) - 1)/d)\n",
    "    x = np.concatenate([np.sin(t[:,:,None] / drange_even), np.cos(t[:,:,None] / drange_odd)], 2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.concatenate([np.zeros(205, dtype=int), np.ones(205, dtype=int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([embed_position((t_y[i, :])[:, None], d=94, TΔmin= 0.8, Tmax=200) for i in range(len(t_y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.repeat(tf.one_hot(k, 2)[None, :, None, :],  2175, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc = bots_loc[None, :, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc = np.repeat(bots_loc,  2175, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc = np.repeat(bots_loc,  410, axis =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bots_loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, x2), axis =-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.repeat(x, 410, axis =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Paired', 2)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(t_y[261, :205], d_y[261,1, :205])\n",
    "ax.plot(t_y[261, 205:], d_y[261,1, 205:])\n",
    "# ax.plot(t_y[3, :205], d_y[3,1, :205])\n",
    "# ax.plot(t_y[3, 205:], d_y[3,1, 205:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step, test_step, train_loss, test_loss, m_tr, m_te = grapher.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_data = batch_creator.create_batch(em_x = data[1], em_y=data[3], x = data[5], y = data[-1], batch_s=2, d=d)\n",
    "# b_data_te = b_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the two lines below for one batch to overfit on\n",
    "# np.random.seed(443)\n",
    "# b_data, c = batch_creator.create_batch_2d(data[2], data[-3], data[-1], batch_s=20, em_2 = data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    step = 0\n",
    "    # change to run 9 if you want to overfit\n",
    "    EPOCHS = 575; batch_s  = 32; run = 1; tr_regime ='shuffle'\n",
    "    l= [96, 64, 32]; heads = 12; e = 96; context = 70; c=70\n",
    "    name_comp = 'run_' + str(run)\n",
    "    logdir = save_dir + '/logs/' + name_comp\n",
    "    writer = tf.summary.create_file_writer(logdir)\n",
    "    folder = save_dir + '/ckpt/check_' + name_comp\n",
    "    optimizer_c = tf.keras.optimizers.Adam(3e-4)\n",
    "    helpers.mkdir(folder)\n",
    "    decoder = exp2d_model_tr.Decoder(e, l[0], l[1], l[2], num_heads=heads)\n",
    "    num_batches = int(x.shape[0] / batch_s)\n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer_c, net=decoder)\n",
    "    manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=3)\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "    with writer.as_default():\n",
    "        for epoch in range(EPOCHS):\n",
    "            start = time.time()\n",
    "            for batch_n in range(100):\n",
    "                m_tr.reset_states(); train_loss.reset_states()\n",
    "                if d:\n",
    "                    idxs = np.random.choice(np.arange(4000), 32)\n",
    "                    permute_idx = np.arange(100)\n",
    "                    y_tr = aa[idxs, :][:, permute_idx] \n",
    "                    x_tr = x[idxs, :, :]\n",
    "                    to_gather = helpers.gather_idx(c,  l=100, b=32)\n",
    "                    temp = np.zeros((32, 100))\n",
    "                    temp[to_gather[:, 0], to_gather[:, 1]] = 1\n",
    "#                   b_data, c = batch_creator.batch_regime_2d(x = data[-3], y = data[-1], em = data[2] , em_2 =  data[3], batch_s=64, context_p=50, kind='shuffle')\n",
    "                    # add parameter b=20 to helpers.gather_idx if you want to overfit and comment line above\n",
    "                    pred, pred_log, weights, names, shapes, y_real, g = train_step(decoder, optimizer_c, train_loss, m_tr, x_tr, y_tr, d = True, to_gather=temp)\n",
    "                else:\n",
    "#                     b_data = batch_creator.create_batch(em_x = data[1], x = data[3], y = data[-1], batch_s=64, d=d)\n",
    "                    to_gather = helpers.gather_idx(context, l=200, b=2)\n",
    "                    temp = np.zeros((b_data[0].shape[0], b_data[0].shape[1]))\n",
    "                    temp[to_gather[:, 0], to_gather[:, 1]] = 1\n",
    "                    pred, pred_log, weights, names, shapes, y_real, g = train_step(decoder, optimizer_c, train_loss, m_tr, x = b_data[2], y = b_data[0], y2=b_data[3], to_gather = temp)\n",
    "                if (epoch == 0) & (batch_n == 0): helpers.write_speci(folder, names, shapes, context, heads)\n",
    "                if batch_n % 1 == 0:\n",
    "                    m_te.reset_states(); test_loss.reset_states()\n",
    "                    if d:\n",
    "                        idxs_te = np.random.choice(np.arange(4000, 4877), 32)\n",
    "                        permute_idx_te = np.arange(100)\n",
    "                        to_gather_te = helpers.gather_idx(c, l=100, b=32)\n",
    "                        temp_te = np.zeros((32, 100))\n",
    "                        temp_te[to_gather_te[:, 0], to_gather_te[:, 1]] = 1\n",
    "                        y_te = aa[idxs_te, :][:, permute_idx_te] \n",
    "                        x_te = x[idxs_te, :, :]\n",
    "                        pred_te, pred_log_te = test_step(decoder, test_loss, m_te, x_te = x_te, y_te = y_te, to_gather=temp_te, d=True)\n",
    "                        fig,ax = plt.subplots()\n",
    "                        \n",
    "                        ax.plot(t_yy[idxs_te[1], 70:] , y_te[1][70:], c='blue')\n",
    "                        ax.plot(t_yy[idxs_te[1], :50], y_te[1][:50], c='red')\n",
    "                        ax.plot(t_yy[idxs_te[1], 50:70], y_te[1][50:70], c='red')\n",
    "                        ax.plot(t_yy[idxs_te[1], 70:], pred_te[1, 69:], c='goldenrod') \n",
    "                        plt.show()\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "#                         b_data_te, c_te = batch_creator.batch_regime_2d(x = data[-4], y = data[-2], em = data[0] , em_2 =  data[1], batch_s=64, context_p=context, kind=tr_regime)\n",
    "#                         to_gather_te = helpers.gather_idx(c_te)\n",
    "#                         temp_te = np.zeros((b_data_te[0].shape[0], b_data_te[0].shape[1]))\n",
    "#                         temp_te[to_gather_te[:, 0], to_gather_te[:, 1]] = 1\n",
    "#                         pred_te, pred_log_te = test_step(decoder, test_loss, m_te, x_te = b_data_te[2], y_te = b_data_te[0], x2_te = b_data_te[3], to_gather=temp_te, d=True)\n",
    "#                         ## Plotting progress by looking at a random test case. Erase _te from the six lines below if you rather observe training\n",
    "\n",
    "#                         if to_gather_te is not None:\n",
    "#                             # change 64 to 20 if you are overfitting\n",
    "#                             idd = np.random.choice(np.arange(0, 64))\n",
    "#                             seq_l = to_gather_te[to_gather_te[:, 0] == idd][0, 1]\n",
    "#                             plt.scatter(b_data_te[1][idd, :seq_l], b_data_te[0][idd, :seq_l] , c = 'blue', label = 'context')\n",
    "#                             plt.scatter(b_data_te[1][idd, seq_l:], b_data_te[0][idd, seq_l:], c = 'black', label = 'observed func.', alpha=0.5)\n",
    "#                             plt.scatter(b_data_te[1][idd, seq_l:], pred_te[idd][(seq_l - 1):], label = 'predicted func.')\n",
    "#                             plt.legend()\n",
    "#                             plt.show()\n",
    "#                         else:\n",
    "#                             plotter.follow_training_plot2d(x_tr = b_data[1], y_tr = b_data[0], em_2_tr = b_data[3] , pred = pred, x_te = b_data_te[2], y_te = b_data_te[0], em_2_te = b_data_te[3] ,pred_te = pred_te, num_context = context)\n",
    "                    else:\n",
    "                        pred_te, pred_log_te = test_step(decoder, test_loss, m_te, x_te = b_data_te[2], y_te = b_data_te[0], y2_te=b_data_te[3], to_gather = temp)\n",
    "                        plotter.follow_training_plot(x_tr = b_data[1], y_tr = b_data[0], pred = pred, x_te = b_data_te[2], y_te = b_data_te[0], pred_te = pred_te, num_context = context)\n",
    "                    helpers.print_progress(epoch, batch_n, train_loss.result(), test_loss.result(), m_tr.result(), m_te.result())\n",
    "                    helpers.tf_summaries(run, step, train_loss.result(), test_loss.result(), m_tr.result(), m_te.result(), weights, names)\n",
    "                    print('learning rate is {}'.format(optimizer_c._decayed_lr('float32').numpy()))\n",
    "#                     if d:\n",
    "#                         m0, m1 = metrics.r_sq_2d(b_data[0][:, 1:], pred.numpy(), b_data[3][:, 1:], context_p = context)\n",
    "#                         m0_te, m1_te = metrics.r_sq_2d(b_data_te[0][:, 1:], pred_te.numpy(), b_data_te[3][:, 1:], context_p = context)\n",
    "#                         print('r squared training, series 0: {}, series 1: {}'.format(m0, m1))\n",
    "#                         print('r squared testing, series 0: {}, series 1: {}'.format(m0_te, m1_te))\n",
    "                    manager.save()\n",
    "                step += 1\n",
    "                ckpt.step.assign_add(1)\n",
    "            print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.tensorboard_embeddings(decoder, layer_num = 0, meta_data = np.concatenate(([0, 1], np.unique(b_data[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = aa[idd, :70] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = np.random.choice(np.arange(4000, 4877), 1)[0]\n",
    "fig,ax = plt.subplots()\n",
    "for j in range(100):\n",
    "    y_s = aa[idd, :70] \n",
    "    y_s = y_s[:-1][None, :]\n",
    "    for i in range(29):\n",
    "        x_s = x[idd, :(70 + i), :][None, :, :]\n",
    "        _, _, sample_y = evaluate(decoder, x_s, y_s, d=d, sample=True)\n",
    "        y_s = tf.concat((y_s, tf.reshape(sample_y, [1, 1])), axis=1)\n",
    "    ax.plot(t_yy[idd, :50], aa[idd][:50], c='red')\n",
    "    ax.plot(t_yy[idd, 50:70], aa[idd][50:70], c='red')\n",
    "    \n",
    "    ax.plot(t_yy[idd, 70:-1], (y_s.numpy()[:, 69:].reshape(-1)), c='lightblue')\n",
    "y_s = aa[idd, :70] \n",
    "y_s = y_s[:-1][None, :]\n",
    "for i in range(29):\n",
    "    x_s = x[idd, :(70 + i), :][None, :, :]\n",
    "    _, _, sample_y = evaluate(decoder, x_s, y_s, d=d, sample=False)\n",
    "    y_s = tf.concat((y_s, tf.reshape(sample_y, [1, 1])), axis=1)\n",
    "ax.plot(t_yy[idd, :50], aa[idd][:50], c='red')\n",
    "ax.plot(t_yy[idd, 50:70], aa[idd][50:70], c='red')\n",
    "ax.plot(t_yy[idd, 70:-1], (y_s.numpy()[:, 69:].reshape(-1)), c='goldenrod')\n",
    "ax.plot(t_yy[idd, 70:], aa[idd][70:], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, sample=True, d=False):\n",
    "\n",
    "    combined_mask_x = masks.create_masks(x[:, :, 0])\n",
    "    pred = model(x, y, False, combined_mask_x[:, :-1, :-1])\n",
    "    if sample:\n",
    "        sample_y = np.random.normal(pred[-1, 0], np.exp(pred[-1, 1]))\n",
    "    else:\n",
    "        sample_y = pred[-1, 0]\n",
    "\n",
    "    return pred[:, 0], pred[:, 1], sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
