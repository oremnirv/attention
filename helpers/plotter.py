import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from inference import infer
plt.style.use('ggplot')


def sample_plot_w_training(positions, targets, predictions, num_context=50, num_samples=1, title=''):
    real_x = positions
    real_y = targets
    samples = np.zeros((num_samples, len(real_x)))
    samples[0, :(num_context - 1)] = targets[:(num_context - 1)]
    samples[0, (num_context - 1):] = predictions[(num_context - 1):]
    sorted_arr = np.argsort(real_x)
    plt.plot(real_x[sorted_arr], real_y[sorted_arr], 'black')
    plt.scatter(real_x[:num_context], real_y[:num_context],
                c='black', marker="o", zorder=1, s=25)
    plt.plot(real_x[sorted_arr], samples[0, sorted_arr],
             c='lightskyblue', alpha=0.6)
    plt.title(title)
    plt.show()

# Show few graphs of how the data looks like


def plot_examples(x, y):
    idx = np.random.choice(np.arange(0, len(x)), 5, replace=False)
    for i in idx:
        sorted_idx = np.argsort(x[i, :])
        plt.plot(x[i, sorted_idx], y[i, sorted_idx])
    plt.title(
        'Five examples from the dataset generated by a GP \n with RBF kernel with σ = 1')


def plot_2d_examples(x, y, em_2):

    fig, axs = plt.subplots(2, 2, figsize=(12, 8))
    custom_xlim = (4, 16)
    custom_ylim = (-8, 8)
    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim)
    idxs = np.random.choice(x.shape[0], 4)
    fig.suptitle('Four examples from the dataset generated by a 2D GP \n with RBF kernel with σ = 1', fontsize = 16)
    for i, idd in enumerate(idxs):
        row = i // 2; col = i % 2 
        f_x = x[idd, :][np.where(em_2[idd, :] == 1)[0]]
        f_y = y[idd, :][np.where(em_2[idd, :] == 1)[0]]
        axs[row, col].plot(np.sort(f_x), f_y[np.argsort(f_x)])
        s_x = x[idd, :][np.where(em_2[idd, :] == 0)[0]]
        s_y = y[idd, :][np.where(em_2[idd, :] == 0)[0]]
        axs[row, col].plot(np.sort(s_x), s_y[np.argsort(s_x)])
    for ax in axs.flat:
        ax.label_outer()


    plt.show()


def infer_plot(model, em, x, y, num_steps, samples=10, mean=True, context_p=50, order = False):
    fig, axs = plt.subplots(1, 1, figsize=(10, 6))
    custom_xlim = (4, 16)
    custom_ylim = (-10, 10)
    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim)

    maxi = num_steps + context_p
    sorted_idx = np.argsort(x)

    if order:
        x = x[sorted_idx]
        sorted_idx = np.argsort(x)
        y = y[sorted_idx]
        em = em[sorted_idx]

    # true graph
    axs.plot(x[ :maxi][0][sorted_idx][0], y[:maxi][0][sorted_idx][0], c='black', zorder=1, linewidth=3)
    
    # context points:
    axs.scatter(x[ :context_p][0],
                y[ :context_p][0], c='red')

    for inf in range(samples):
        _, _, tar_inf = infer.inference(model, em[ :maxi].reshape(1, -1), y[ :context_p].reshape(1, -1), num_steps=num_steps)


        axs.plot(x.reshape(-1)[sorted_idx], tar_inf.numpy().reshape(-1)[sorted_idx][0], c='lightskyblue')

    if mean:

        _, _, tar_inf = infer.inference(model, em[ :maxi].reshape(1, -1), y[ :context_p].reshape(1, -1), num_steps=num_steps, sample=False)

        axs.plot(x.reshape(-1)[sorted_idx], tar_inf.numpy().reshape(-1)[sorted_idx], c='goldenrod')

    plt.show()


def choose_random_ex_n_sort(x, num_samples):

    idx = np.random.choice(np.arange(0, len(x)), num_samples, replace=False)
    samples = np.zeros((num_samples, x.shape[1]))
    sorted_idx_samples = pd.DataFrame(x[idx, :]).apply(
        lambda x: np.argsort(x), axis=1)
    # print(np.array(sorted_idx_samples)[0, :])
    return idx, samples, sorted_idx_samples


def assign_context_points_to_preds(idx, samples, y, pred, num_context):
    samples[:, :num_context] = y[idx, :num_context]
    samples[:, num_context:] = pred.numpy()[idx, (num_context - 1):]
    return samples


def follow_training_plot(x_tr, y_tr, pred,
                         x_te, y_te, pred_te, num_context=50, num_samples=2):
    fig, axs = plt.subplots(2, 2, figsize=(10, 6))
    custom_xlim = (4, 16)
    custom_ylim = (-4, 4)

# Setting the values for all axes.
    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim)
    idx_tr, samples_train, sorted_idx_tr = choose_random_ex_n_sort(x_tr, 2)
    idx_te, samples_test, sorted_idx_te = choose_random_ex_n_sort(x_te, 2)
    samples_tr = assign_context_points_to_preds(
        idx_tr, samples_train, y_tr, pred, num_context)
    samples_te = assign_context_points_to_preds(
        idx_te, samples_test, y_te, pred_te, num_context)
    axs = plot_subplot_training(axs, x_tr, x_te, y_tr, y_te, samples_tr, samples_te, idx_tr, idx_te, np.array(
        sorted_idx_tr), np.array(sorted_idx_te), num_context)
    for ax in axs.flat:
        ax.label_outer()

    plt.show()


def plot_subplot_training(params, x, x_te, y, y_te, pred_y, pred_y_te, tr_idx, te_idx, sorted_idx_tr, sorted_idx_te, num_context):

    for row in range(params.shape[0]):
        if (row == 1):
            x = x_te
            y = y_te
            pred_y = pred_y_te
            tr_idx = te_idx
            sorted_idx_tr = sorted_idx_te
        for col in range(params.shape[1]):

            params[row, col].plot(x[tr_idx[col], sorted_idx_tr[col, :]],
                                  y[tr_idx[col], sorted_idx_tr[col, :]], c='black', label='true function')
            params[row, col].scatter(x[tr_idx[col], :num_context], y[tr_idx[col], :num_context],
                                     c='black', marker="o", zorder=1, s=25, label='context points')
            params[row, col].plot(x[tr_idx[col], sorted_idx_tr[col, :]], pred_y[col,
                                                                                sorted_idx_tr[col, :]], c='lightskyblue', label='reconstructed function')
            if (row == 0):
                params[row, col].set_title('Training ex. {}'.format(col + 1))
            else:
                params[row, col].set_title('Test ex. {}'.format(col + 1))
            if ((row == 0) and (col == 1)):
                params[row, col].legend()
    return params



def follow_training_plot2d(x_tr, y_tr, em_2_tr, pred,
                         x_te, y_te, em_2_te , pred_te, num_context=50):
    fig, axs = plt.subplots(2, 1, figsize=(10, 6))
    custom_xlim = (4, 16)
    custom_ylim = (-8, 8)

# Setting the values for all axes.
    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim)
    idx_tr, samples_train, sorted_idx_tr = choose_random_ex_n_sort(x_tr, 1)
    idx_te, samples_test, sorted_idx_te = choose_random_ex_n_sort(x_te, 1)
    samples_tr = assign_context_points_to_preds(
        idx_tr, samples_train, y_tr, pred, num_context)
    samples_te = assign_context_points_to_preds(
        idx_te, samples_test, y_te, pred_te, num_context)
    
    sorted_em = (em_2_tr[idx_tr]).reshape(-1)[np.array(sorted_idx_tr).reshape(-1)]
    sorted_em_te = (em_2_te[:500][idx_te]).reshape(-1)[np.array(sorted_idx_te).reshape(-1)]
    
    idx_f1 = sorted_idx_tr[np.where(sorted_em == 1)[0]]
    idx_f2 = sorted_idx_tr[np.where(sorted_em == 0)[0]]
    idx_f1_te = sorted_idx_te[np.where(sorted_em_te == 1)[0]]
    idx_f2_te = sorted_idx_te[np.where(sorted_em_te == 0)[0]]
    
    samples_tr1 = samples_tr.reshape(-1)[np.array(idx_f1).reshape(-1)]
    samples_tr2 = samples_tr.reshape(-1)[np.array(idx_f2).reshape(-1)]
    
    samples_te1 = samples_te.reshape(-1)[np.array(idx_f1_te).reshape(-1)]
    samples_te2 = samples_te.reshape(-1)[np.array(idx_f2_te).reshape(-1)]
    
    axs = plot_subplot_training2d(axs, x_tr, x_te, y_tr, y_te, samples_tr1, samples_tr2, samples_te1, samples_te2, idx_tr, idx_te, idx_f1, idx_f2, idx_f1_te, idx_f2_te, num_context)
    for ax in axs.flat:
        ax.label_outer()

    plt.show()



def plot_subplot_training2d(params, x, x_te, y, y_te, pred_y, pred_y_2, pred_y_te, pred_y_te_2, idx_tr, idx_te, idx_f1, idx_f2, idx_f1_te, idx_f2_te, num_context):

    for row in range(params.shape[0]):
        if (row == 1):
            x = x_te
            y = y_te
            pred_y = pred_y_te
            pred_y_2 = pred_y_te_2
            idx_tr = idx_te
            idx_f1 = idx_f1_te
            idx_f2 = idx_f2_te
            
        params[row].plot(x[idx_tr[0], np.array(idx_f1)[0]],
                                          y[idx_tr[0], np.array(idx_f1)[0]], c='black', label='true function')

        params[row].plot(x[idx_tr[0], np.array(idx_f2)[0]],
                                          y[idx_tr[0], np.array(idx_f2)[0]], c='blue', label='true function II')

        params[row].scatter(x[idx_tr[0], :50], y[idx_tr[0], :50],
                                             c='black', marker="o", zorder=1, s=25, label='context points')


        params[row].plot(x[idx_tr[0], np.array(idx_f1)[0]], pred_y.reshape(-1), c='gray', label='reconstructed function')

        params[row].plot(x[idx_tr[0], np.array(idx_f2)[0]], pred_y_2.reshape(-1), c='lightskyblue', label='reconstructed function II')




        if (row == 0):
            params[row].set_title('Training ex. I')
            leg = params[row].legend()
            bb = leg.get_bbox_to_anchor().inverse_transformed(params[row].transAxes)

            # Change to location of the legend. 
            xOffset = .5
            bb.x0 += xOffset
            bb.x1 += xOffset
            leg.set_bbox_to_anchor(bb, transform = params[row].transAxes)
            
        else:
            params[row].set_title('Test ex. I')
            
    return params

def concat_n_rearange(x, y, em, em_2, cond_arr, context_p, series = 1):
    cond_arr_pre = cond_arr[:context_p]
    cond_arr_pos = cond_arr[context_p:]
    cond = []
    cond.append(np.where([cond_arr_pre == series])[1])
    cond.append(np.where([cond_arr_pos == series])[1])
    cond.append(np.where(~(cond_arr_pre == series)))
    cond.append(np.where(~ (cond_arr_pos == series)))
    
    # create the two series that will be used as context points
    y_pre = y[:context_p]; y_post = y[context_p:]
    tar_1 = np.concatenate((y_pre[cond[0]], y_post[cond[1]])).reshape(1, -1)
    tar_0 = y_pre[cond[2]]
    
    # generate rearanged target for inference
    y_infer = np.concatenate((y_pre, y_post[cond[1]])).reshape(1, -1)
    
    
    # generate rearanged input for infer
    em_pre = em[:context_p]; em_post = em[context_p:]
    em2_pre = em_2[:context_p]; em2_post = em_2[context_p:]
    
    em_infer = np.concatenate((em_pre, em_post[cond[1]]))
    em_infer = np.concatenate((em_infer, em_post[cond[3]]))
    em2_infer = np.concatenate((em2_pre, em2_post[cond[1]]))
    em2_infer = np.concatenate((em2_infer, em2_post[cond[3]]))
    
    # rearange x
    x_pre = x[:context_p]; x_post = x[context_p:]
    x_1 = np.concatenate((x_pre[cond[0]], x_post[cond[1]]))
    x_0_part = x_pre[cond[2]]
    xx_0 = np.concatenate((x_pre, x_post[cond[1]]))
    xx_0 = np.concatenate((xx_0, x_post[cond[3]]))
    
    
    sorted_x_1 = np.argsort(x_1)
    sorted_x_0_p = np.argsort(x_0_part)
    sorted_xx_0 = np.argsort(xx_0)
    sorted_x = np.argsort(x)
    
    # sort 1's and 0's according to sorted x's
    sorted_em = em_2.reshape(-1)[sorted_x.reshape(-1)]

    return sorted_xx_0[np.where(sorted_em == 0)], xx_0[sorted_xx_0[np.where(sorted_em == 0)]], x_1[sorted_x_1.reshape(-1)], tar_1[0][sorted_x_1.reshape(-1)], x_0_part[sorted_x_0_p.reshape(-1)], tar_0[sorted_x_0_p.reshape(-1)], em_infer, em2_infer, y_infer




def infer_plot2D(decoder, x, y, em, em_2, samples = 10, order = True, context_p = 50, mean = True):
    fig, axs = plt.subplots(1, 1, figsize=(10, 6))
    custom_xlim = (4, 16)
    custom_ylim = (-8, 8)
    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim)

    if order:
        sorted_idx = np.argsort(x)
        x = x[sorted_idx]
        y = y[sorted_idx]
        em = em[sorted_idx]
        em_2 = em_2[sorted_idx]


    sorted_infer, x_infer, x_1, tar_1, x_0_part, tar_0, em_infer, em2_infer, y_infer = concat_n_rearange(x, y, em, em_2, em_2, context_p)
    steps = 400 - y_infer.shape[1]

    
    axs.scatter(x_0_part, tar_0, c = 'red')
    axs.plot(x_1, tar_1, c = 'black')
    for inf in range(samples): 
        _, _, tar_inf = infer.inference(decoder, em_te = em_infer.reshape(1, -1), tar = y_infer, num_steps=steps, sample=True, d = True, em_te_2 = em2_infer.reshape(1, -1), series = 1)
        axs.plot(x_infer, tar_inf.numpy().reshape(-1)[sorted_infer], c='lightskyblue')
    if mean:
        _, _, tar_inf = infer.inference(decoder, em_te = em_infer.reshape(1, -1), tar = y_infer, num_steps=steps, sample=False, d = True, em_te_2 = em2_infer.reshape(1, -1), series = 1)
        axs.plot(x_infer, tar_inf.numpy().reshape(-1)[sorted_infer], c='goldenrod')

    plt.show()


